var tipuesearch = {"pages":[{"text":"#rokiframe { display: inline-block; /* box-shadow: 0px 0px 20px -5px rgba(0, 0, 0, 0.8);*/ } .fonticon { margin-right: 4px; } .abouth2 { margin-top: 40px; } .titleicon { margin-right: 7px; } .entry-title { text-align: center; margin-bottom: 0px; font-size: 23.0pt; } en / ja Author : Roki Mail : <!-- function converter(M){ var str=\"\", str_as=\"\"; for(var i=0;i<M.length;i++){ str_as = M.charCodeAt(i); str += String.fromCharCode(str_as + 1); } return str; } function mail_to(k_1,k_2) {eval(String.fromCharCode(108,111,99,97,116,105,111,110,46,104,114,101,102,32, 61,32,39,109,97,105,108,116,111,58) + escape(k_1) + converter(String.fromCharCode(101,96,107,102,110,109,52,50,63,120,96,103,110,110,45,98,110,45,105,111, 62,114,116,97,105,100,98,115,60)) + escape(k_2) + \"'\");} document.write('<a href=JavaScript:mail_to(\"\",\"\")>To inquire<\\/a>'); //--> About Content : This is roki blog of learning. I write articles on this blog mainly on technical content. All opinions expressed by Author on this blog is solely Author's opinions and do not reflect the opinions of the company to which I belong. For information on various links and accounts that I own, see my website \" Roki Profile \". This blog is made up of static site generator pelican . For the development environment of this blog, see the next article \" ハローワールド \". If you want to write indications or comments please write them in Github issues or DISQUS . Browsing environment This blog is confirmed the display with the following browser: Google Chrome (latest) Firefox (latest stable version, nightly) Kinza (latest) Privacy policy This blog collects access logs using Google Analytics and First-Party Cookies for analyzing and improving information. Therefore the web browser you are using this blog will automatically send certain information to Google (for example, web address or IP address of the page you visited). Also in order to collect that data, Google may set cookies in your browser or read existing cookies. The information (statistical information such as the number of accesses, visitor's browser, OS information etc.) obtained by this can be published on this blog and on my social networking account. Change log YY / MM Content 20/03 Japanese version added to About page, Disclaimer added 19/05 Change the profile image from the Tux image 18/03 Moved from Hatena blog to this blog 16/05 Start the blog on Hatena blog Tweets Tweets by 530506","loc":"pages/about/","tags":"Uncategorized","url":"pages/about/","title":"About this blog"},{"text":"#rokiframe { display: inline-block; /* box-shadow: 0px 0px 20px -5px rgba(0, 0, 0, 0.8);*/ } .fonticon { margin-right: 4px; } .abouth2 { margin-top: 40px; } .titleicon { margin-right: 7px; } .entry-title { text-align: center; margin-bottom: 0px; font-size: 23.0pt; } en / ja 著者 : Roki メール : <!-- function converter(M){ var str=\"\", str_as=\"\"; for(var i=0;i<M.length;i++){ str_as = M.charCodeAt(i); str += String.fromCharCode(str_as + 1); } return str; } function mail_to(k_1,k_2) {eval(String.fromCharCode(108,111,99,97,116,105,111,110,46,104,114,101,102,32, 61,32,39,109,97,105,108,116,111,58) + escape(k_1) + converter(String.fromCharCode(101,96,107,102,110,109,52,50,63,120,96,103,110,110,45,98,110,45,105,111, 62,114,116,97,105,100,98,115,60)) + escape(k_2) + \"'\");} document.write('<a href=JavaScript:mail_to(\"\",\"\")>問い合わせる<\\/a>'); //--> コンテンツについて : このブログは著者の学習ログを残すブログです. このブログには, 技術的な内容を中心とした記事を執筆します. このブログで著者が表明したすべての意見は, 著者自身による見解であり, 所属する団体の意見を反映するものではありません. 私に関連する様々なリンクやアカウントに関する情報は, 私のウェブサイト \" Roki Profile \" を参照してください. このブログは静的サイト生成器 pelican によって作られています. このブログの開発環境に関しては, 次の記事 \" ハローワールド \" をご覧ください. ご指摘やコメントを記入する場合は, Github issues または各記事の DISQUS にお願いします. ブラウザ環境 このブログは, 以下のブラウザで表示の確認をしています: Google Chrome (latest) Firefox (latest stable version, nightly) Kinza (latest) プライバシーポリシー このブログは, 情報の分析と改善のために, Google Analytics とファーストパーティクッキーを使用して, アクセスログを収集します. 従って, このブログを使用している Web ブラウザは特定の情報 (例えば, アクセスしたページの Web アドレスや IP アドレス) を自動的に Google に送信します. また, そのデータを収集するために, Google はブラウザにクッキーを設定するか, 既存のクッキーを読み取ることがあります. これによって取得された情報 (アクセス数, 訪問者のブラウザ, OS 情報などの統計情報) は, このブログと著者のソーシャルネットワーキングアカウントで公開することがあります. 経歴/更新履歴 YY / MM コンテンツ 20/03 アバウトページに日本語版を追加, 免責事項を新規追加 19/05 プロフィール画像を Tux 画像から変更 18/03 はてなブログから引っ越し 16/05 はてなブログで ブログ を開始 ツイート Tweets by 530506","loc":"pages/about_ja/","tags":"Uncategorized","url":"pages/about_ja/","title":"このブログについて"},{"text":"本エントリ投稿の 2, 3 ヶ月前に Haskell でスクラッチから x86-64 向けの C コンパイラを作った. 本エントリは, その記録である. 動機/背景 動機としては, 私は 2020 年度の新卒として, とある会社に技術者として入社することとなっており, コンパイラの自作は, 社会人になる前に, 前々から一度はやっておきたいと思っていた事柄の一つであったこと, また関数プログラミングとの関係性について探求したかったこと, さらに, 一部には, 関数プログラミングはコンパイラ開発を容易にする 1 という認識があるが, 数学的構造の実用化の一つとも言える関数プログラミングに関する考察においては, 圏論的な理由付けによりその有用性を言うことができるはずであろうという, 私の中での何となくの予想が本当であるのかどうか, 確認したかったことから, 実際に Haskell で C コンパイラを作るに至った. なお, 圏論の話題は再度別のエントリとしてまとめ, その後, さらに別のエントリにそれと関連付いた話題としてまとめようと考えているため, 本エントリでは特に立ち入らず, あくまでも, Haskell で C コンパイラを作ってみたという単なる取り組みへの記録程度に止める. 成果 プロジェクトは, 次のリポジトリにて管理している. falgon/htcc - A tiny C language compiler (x86-64) ( WIP ) 執筆時最新のコミット 2301374 におけるコンパイル可能なコードは構文は, テストコードに記されている通りである. より実用的な (コンパイル可能な) サンプルコードは example 配下にある (ナップザック問題, 連結リストのマージソート, Fisher–Yates シャッフルとクイックソート, ライフゲームシミュレータ等). htcc は標準 C 言語 2 の構文の他に, 一部の GNU 拡張の構文を実装している. 例えば, Statement Expression はそのうちの一つである. 近年, Rust のような多くの\"現代的な\"言語は, 文の構文を式として捉えている 3 が, Statement Expression はそれと同様の機能, すなわち, C の compound-statement を式として捉える機能を提供する. また, Conditionals with Omitted Operands もそのうちの一つである. 条件演算子は N1570 において次のように定義されているが \\begin{array}{llllll} \\text{conditional-expression}:\\\\ &\\text{logical-OR-expression}\\\\ &\\text{logical-OR-expression}&?&\\text{expression}&:&\\text{conditional-expression} \\end{array} この expression オペランドが省略された次の構文 \\begin{array}{lll} \\text{logical-OR-expression}&?:&\\text{conditional-expression} \\end{array} をサポートする. htcc の機能そのものの説明は, 基本的に上記リポジトリの README .md に書かれている通りであるが, ここにコミット 2301374 時点での説明を再掲することとする. htcc の実行イメージ コマンドラインオプションは次のようになっている. $ stack exec htcc -- -h Usage: htcc [ --visualize-ast ] [ --img-resolution RESOLUTION ] file [ -o | --out file ] [ -w | --supress-warns ] Available options: -h,--help Show this help text --visualize-ast Visualize an AST built from source code --img-resolution RESOLUTION Specify the resolution of the AST graph to be generated ( default: 640x480 ) file Specify the input file name -o,--out file Specify the output destination file name, supported only svg ( default: ./out.svg ) -w,--supress-warns Disable all warning messages 例えば, 標準出力に hello world を出力する C ソースコードのコンパイルは, 次のように実行できる. $ echo 'int printf(); int main() { printf(\"hello world!\\n\"); }' | stack exec htcc -- /dev/stdin | gcc -xassembler -no-pie -o out - htcc には, 内部で構築した構文木をベクタ画像として視覚化し, 出力する機能を実装してある 4 . 次の表は, 実行されるコマンドと出力されるベクタ画像の対応を示したものである. コマンド 出力画像 htcc の構築した構文木のベクタ画像出力例 $ echo 'int main() { return 1 * 2 + 4; }' |\\ stack exec htcc -- /dev/stdin\\ --visualize-ast\\ --img-resolution 640x480\\ --out calc.svg $ echo 'int printf(); void fizzbuzz(int n) { for (int i = 1; i < n; ++i) { if (!(i % 15)) printf(\"fizzbuzz\\n\"); else if (!(i % 3)) printf(\"fizz\\n\"); else if (!(i % 5)) printf(\"buzz\\n\"); else printf(\"%d\\n\", i); } } int main() { fizzbuzz(50); }' |\\ stack exec htcc -- /dev/stdin\\ --visualize-ast\\ --img-resolution 1280x720\\ --out fizzbuzz.svg 開発様相 コンパイラの開発には, 『 低レイヤを知りたい人のためのCコンパイラ作成入門 』を参考とさせて頂いており, この内容から習うようにして, インクリメンタルなテスト駆動開発の手段をとることとした. 今回は, 動機に示された理由により, とくに Haskell での実装を進めたかったため, セルフホストコンパイラの開発という目的には一致していなかったが, 同文書は, 具体的な開発順序や手段の詳細に関する, 多くの知見を与えてくださった. 同書の他に, コンパイラの構成には References -4 を参考とした. 言語仕様は同書同様 N1570 に従い, ABI 等の仕様確認には References -1 を用いた. また, より理論的な参考としては, Benjamin C. Pierce. (2002). Types and Programming Languages . The MIT Press 中田育男. (2009). コンパイラの構成と最適化 . 朝倉書店 が挙げられる. また, 今回は, gitmoji のガイドラインに従って, コミットメッセージに絵文字を含めてみた. これに大した理由はないが, やってみた結果としては, 後にコミットを見返した際に, 視覚的な印象により, 多少はその概要をより素早く見直すことができるような気はした. まとめ これは, 字句解析器や構文解析器の自動生成ツールを用いずに x86-64 アセンブラを出力する C コンパイラを作ってみるという目的の他, 私自身が関数プログラミングと圏論の関係性を学び, それをコンパイラ開発という一つの用途にあてはめたときに発見できる明確な有用性について, 私自身が議論できるようになる, という目的で行った取り組みであったが, C コンパイラはそれなりに動くところまで作れ, またモナドを利用した言語内 DSL による文脈の強制は, コンパイラ開発の場面でも強力な機能であり, その結果として, 生成されるコードの安全性を保証するに至るということも身を以て分かり, 新たな興味や疑問も多く湧いたので, 私自身にとっては非常に有意義な取り組みであった. 今後は, 生成コードの最適化, 質の良いエラーと警告情報の提供, アドレスサニタイザに関して深掘りしていきたい. また, いわゆるプログラム論理として言われる分野の応用による, マルチステージプログラミング 5 や, 定理証明支援等の分野には非常に興味があるため, そのような方向へ広げていきたい. Why is writing a compiler in a functional language easier? - stack overflow より. なお, 同質問は opnion-based とされているため文中ではこれを一部の認識としている. ↩ 本エントリでいう C 言語とは厳密に言えば C11 の最終ドラフトである N1570 のことを指す. ↩ 例えば, C の if , else は文であるが, Rust では三項式である. また, C の \\(\\text{compound-statement}\\) は, Rust において ; で区切られた一連の式に対応する. ↩ Special thanks to diagrams-lib , diagrams-svg and diagrams-contrib ↩ マルチステージプログラミングに関する記事は別途記述予定. 著者の興味としてまず目を引いたものとしては, Oleg Kiselyov. (2014). \" The Design and Imple-mentation of BER MetaOCaml System Descrip-tion \", FLOPS 2014 であった. これは, 単刀直入に言えば, C++14 でマルチステージプログラミングを可能とするための言語拡張に関する研究である. 論文にはその理論のほかに, clang (というか LLVM コンパイラインフラストラクチャ) を用いた処理系の実装までもが示されているが, この実装に対して著者は以前 ほんの軽微なコントリビュート をした. ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2020/ 3月/18/SelfMadeCCompiler/","tags":"Haskell","url":"posts/2020/ 3月/18/SelfMadeCCompiler/","title":"Haskell で C コンパイラを作ってみた"},{"text":"ブール代数は古典論理における命題論理と密接に関連している. 結論からいえば, 両者の違いは歴史的な背景ぐらいであり, 殆どの場合は同等の理論であるということができる 1 . ブール代数はその応用として論理回路の構築に直接役立つことから, 計算機科学, とくにハードウェアの分野において重宝される代数系の 1 つである. ブール代数の公理とその定理 次に示すのはブール代数の公理系である. 公理系に関する詳細は証明理論 ( TODO ) の冒頭を参照のこと. ブール代数 半順序集合 \\(\\left(B,\\lor,\\land,',0,1\\right)\\) が可補分配 束 ならば, \\(\\left(B,\\lor,\\land,',0,1\\right)\\) はブール代数である. すなわち, \\(x,y,z\\in B\\) に対して, 次のすべての公理を満たした \\(\\left(B,\\lor,\\land,',0,1\\right)\\) はブール代数である. 可換律 : \\(x\\land y=y\\land x,x\\lor y=y\\lor x\\) 分配律 : \\(\\left(x\\lor y\\right)\\land z=\\left(x\\land z\\right)\\lor\\left(y\\land z\\right),\\left(x\\land y\\right)\\lor z=\\left(x\\lor z\\right)\\land\\left(y\\lor z\\right)\\) 同一律 : \\(&#94;\\forall x\\in L\\) に対して \\(x\\land 1=x,x\\lor 0=x\\). ここで \\(1\\) は最大限, 単位元である. \\(0\\) は最小限, 零元である. 補元律 : \\(&#94;\\exists x'\\in L\\ {\\rm s.t.}\\ &#94;\\forall x\\in L, x\\lor x'=1, x\\land x'=0\\) また, この \\(1,0\\) からのみ成る集合をブール領域, ブール代数の下に書かれた式をブール式, \\(n\\in\\mathbb{N}\\) 個のブール領域の引数をとり, 1 個のブール領域の値となる関数 \\(f:B&#94;n\\to B\\) をブール関数という. 例えば, 2 変数ブール関数 \\(f\\left(x_1,x_2\\right)\\) では \\(x_1,x_2\\) がそれぞれ \\(1,0\\) のいずれかとなるので, \\(2&#94;4=16\\) 通りの 2 変数ブール式が存在することとなる. 以下, 演算の優先順序は左結合性で \\(‘,\\land,\\lor\\) の順とする. ただし, 括弧内の演算はより優先される. さてブール代数の公理における乗法 \\(\\land\\) と加法 \\(\\lor \\), および \\(1, 0\\) をそれぞれ入れ替えると, 再びブール代数の公理である. これは 双対 の原理という公理である. 双対の原理 ブール代数で成立する文/式は, そこに現れるすべての \\(\\lor ,\\land,0,1\\) をそれぞれ \\(\\land,\\lor ,1,0\\) で置き換えても成立する. これらの公理から 補元の一意性 , べき等律 , 有界律 , 吸収律 , 結合律 , 対合律 , ド・モルガンの法則 , シャノンの展開定理 が導出可能である. \\(x,y,z\\in B\\) のとき 補元の一意性 2 つの \\(x\\) の補元 \\(x'_1,x'_2\\) を仮定する. \\begin{eqnarray} x'_1&=&x'_1\\land1&\\left(\\because {\\rm \\href{#boolean_algebra3}{公理 3}:同一律}\\right)\\\\ &=&x'_1\\land\\left(x\\lor x'_2\\right)&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}:補元律}\\right)\\\\ &=&\\left(x'_1\\land x\\right)\\lor \\left(x'_1\\land x'_2\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理 2}:分配律}\\right)\\\\ &=&0\\lor \\left(x'_1\\land x'_2\\right)&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}:補元律}\\right)\\\\ &=&\\left(x\\land x'_2\\right)\\lor \\left(x'_1\\land x'_2\\right)&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}:補元律}\\right)\\\\ &=&x'_2\\land\\left(x\\lor x'_1\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理 2}:分配律}\\right)\\\\ &=&x'_2\\land1&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}:補元律}\\right)\\\\ &=&x'_2&\\left(\\because {\\rm \\href{#boolean_algebra3}{公理 3}:同一律}\\right) \\end{eqnarray} より \\(x\\) の補元が一意であることは明らか. \\(\\square\\) べき等律 束の定理 より自明. \\(\\square\\) 有界律 \\begin{eqnarray} x\\lor 1&=&\\left(x\\lor 1\\right)\\land1&\\left(\\because {\\rm \\href{#boolean_algebra3}{公理 3}:同一律}\\right)\\\\ &=&\\left(x\\lor 1\\right)\\left(x\\lor x'\\right)&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}:補元律}\\right)\\\\ &=&x\\lor \\left(1\\land x'\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理 2}:分配律}\\right)\\\\ &=&x\\lor x'&\\left(\\because {\\rm \\href{#boolean_algebra1}{公理1}, \\href{#boolean_algebra3}{公理3}:可換律, 同一律}\\right)\\\\ &=&1\\\\ x\\land0&=&x\\land x\\land x'&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}:補元律}\\right)\\\\ &=&x\\land x'&\\left(\\because {\\rm 定理:\\href{#idempotence}{べき等律}}\\right)\\\\ &=&0&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}:補元律}\\right) \\end{eqnarray} \\(\\square\\) 吸収律 \\begin{eqnarray} x\\lor x\\land y&=&\\left(x\\land1\\right)\\lor \\left(x\\land y\\right)&\\left(\\because {\\rm \\href{#boolean_algebra3}{公理3}: 同一律}\\right)\\\\ &=&x\\land\\left(1\\lor y\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理2}:分配律}\\right)\\\\ &=&x\\land1&\\left(\\because {\\rm \\href{#boolean_algebra1}{公理 1}: 可換律, 定理: \\href{#bounded}{有界律}} \\right)\\\\ &=&x&\\left(\\because {\\rm\\href{#boolean_algebra3}{公理 3}: 同一律}\\right)\\\\ x\\land\\left(x\\lor y\\right)&=&\\left(x\\lor 0\\right)\\left(x\\lor y\\right)&\\left(\\because {\\rm \\href{#boolean_algebra3}{公理3}: 同一律}\\right)\\\\ &=&\\left(0\\land y\\right)\\lor x&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理2}: 分配律}\\right)\\\\ &=&x\\lor 0&\\left(\\because \\rm{\\href{#boolean_algebra1}{公理1}: 可換律,定理: \\href{#bounded}{有界律}}\\right)\\\\ &=&x&\\left(\\because \\rm{\\href{#boolean_algebra3}{公理3}: 同一律}\\right) \\end{eqnarray} \\(\\square\\) 結合律 \\(A=x\\lor \\left(y\\lor z\\right), B=\\left(x\\lor y\\right)\\lor z\\) とおく. このとき, \\begin{eqnarray} x\\land A&=&x\\land\\left(x\\lor \\left(y\\lor z\\right)\\right)\\\\ &=&x&\\left(\\because {\\rm 定理: \\href{#absorption}{吸収律}}\\right)\\\\ x\\land B&=&x\\land\\left(\\left(x\\lor y\\right)\\lor z\\right)\\\\ &=&x\\land\\left(x\\lor y\\right)\\lor x\\land z&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理2}: 分配律}\\right)\\\\ &=&x\\lor x\\land z&\\left(\\because {\\rm 定理: \\href{#absorption}{吸収律}}\\right)\\\\ &=&x&\\left(\\because {\\rm 定理: \\href{#absorption}{吸収律}}\\right) \\end{eqnarray} ゆえに \\[x\\land A=x\\land B=x\\label{eq:assl1}\\tag{L1}\\] また, \\begin{eqnarray} x'\\land A&=&x'\\land\\left(x\\lor \\left(y\\lor z\\right)\\right)\\\\ &=&x'\\land x\\lor x'\\land\\left(y\\lor z\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理2}: 分配律}\\right)\\\\ &=&x'\\land\\left(y\\lor z\\right)\\lor 0&\\left(\\because {\\rm \\href{#boolean_algebra1}{公理1}, \\href{#boolean_algebra4}{公理 4}: 可換律, 補元律}\\right)\\\\ &=&x'\\land\\left(y\\lor z\\right)&\\left(\\because {\\rm \\href{#boolean_algebra3}{公理3}: 同一律}\\right)\\\\ x'\\land B&=&x'\\land\\left(\\left(x\\lor y\\right)\\lor z\\right)\\\\ &=&x'\\land\\left(x\\lor y\\right)\\lor x'\\land z&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理2}: 分配律}\\right)\\\\ &=&\\left(x'\\land x\\lor x'\\land y\\right)\\lor x'\\land z&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理2}: 分配律}\\right)\\\\ &=&\\left(0\\lor x'\\land y\\right)\\lor x'\\land z&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}:補元律}\\right)\\\\ &=&x'\\land y\\lor x'\\land z&\\left(\\because {\\rm \\href{#boolean_algebra3}{公理3}: 同一律}\\right)\\\\ &=&x'\\land\\left(y\\lor z\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理2}: 分配律}\\right) \\end{eqnarray} ゆえに \\[x'\\land A=x'\\land B=x'\\land\\left(y\\lor z\\right)\\label{eq:assl2}\\tag{L2}\\] 従って, \\begin{eqnarray} A&=&A\\land1&\\left(\\because {\\rm \\href{#boolean_algebra3}{公理3}: 同一律}\\right)\\\\ &=&A\\land\\left(x\\lor x'\\right)&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}:補元律}\\right)\\\\ &=&A\\land x\\lor A\\land x'&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理2}: 分配律}\\right)\\\\ &=&x\\land A\\lor x'\\land A&\\left(\\because {\\rm \\href{#boolean_algebra1}{公理1}: 可換律}\\right)\\\\ &=&x\\land B\\lor x'\\land B&\\left(\\because\\eqref{eq:assl1},\\eqref{eq:assl2}\\ {\\rm より}\\right)\\\\ &=&B\\left(x\\lor x'\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理2}: 分配律}\\right)\\\\ &=&B\\land1&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}:補元律}\\right)\\\\ &=&B&\\left(\\because {\\rm \\href{#boolean_algebra3}{公理3}: 同一律}\\right) \\end{eqnarray} また, 双対の原理より \\(x\\left(y\\land z\\right)=\\left(x\\land y\\right)\\land z\\). \\(\\square\\) 対合律 \\begin{eqnarray} \\left(x'\\right)'&=&\\left(x'\\right)'\\lor 0&\\left(\\because \\rm{\\href{#boolean_algebra3}{公理3}: 同一律}\\right)\\\\ &=&\\left(x'\\right)'\\lor x\\land x'&\\left(\\because {\\href{#boolean_algebra4}{公理 4}:補元律}\\right)\\\\ &=&\\left(\\left(x'\\right)'\\lor x\\right)\\left(\\left(x'\\right)'\\lor x'\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理 2}:分配律}\\right)\\\\ &=&\\left(x\\lor \\left(x'\\right)'\\right)\\land1&\\left(\\because {\\rm \\href{#boolean_algebra1}{公理1}, \\href{#boolean_algebra4}{公理 4}:可換律, 補元律}\\right)\\\\ &=&\\left(x\\lor \\left(x'\\right)'\\right)\\left(x\\lor x'\\right)&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}: 補元律}\\right)\\\\ &=&x\\lor \\left(\\left(x'\\right)'\\land x'\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理2}:分配律}\\right)\\\\ &=&x\\lor 0&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}:補元律}\\right)\\\\ &=&x&\\left(\\because {\\rm \\href{#boolean_algebra3}{公理3}: 同一律}\\right) \\end{eqnarray} \\(\\square\\) ド・モルガンの法則 \\(\\left(x\\lor y\\right)'=x'\\land y'\\) を示す. これが成り立つためには, 式の通り, \\(x'\\land y'\\) が \\(\\left(x\\lor y\\right)\\) の補元でなければならない. すなわち, 公理4 : 補元律より \\(\\left(x\\lor y\\right)\\lor \\left(x'\\land y'\\right)=1\\) および \\(\\left(x\\lor y\\right)\\land\\left(x'\\land y'\\right)=0\\) が同時に成り立つことを示せばよい. \\begin{eqnarray} \\left(x\\lor y\\right)\\lor \\left(x'\\land y'\\right)&=&\\left(\\left(x\\lor y\\right)\\lor x'\\right)\\left(\\left(x\\lor y\\right)\\lor y'\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理2}:分配律}\\right)\\\\ &=&\\left(y\\lor \\left(x\\lor x'\\right)\\right)\\left(x\\lor \\left(y\\lor y'\\right)\\right)&\\left(\\because {\\rm \\href{#boolean_algebra1}{公理1}: 可換律, 定理: \\href{#associative}{結合律}}\\right)\\\\ &=&\\left(y\\lor 1\\right)\\left(x\\lor 1\\right)&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}:補元律}\\right)\\\\ &=&1\\land1&\\left(\\because {\\rm 定理: \\href{#bounded}{有界律}} \\right)\\\\ &=&1&\\left(\\because {\\rm 定理:\\href{#idempotence}{べき等律}}\\right)\\\\ \\left(x\\lor y\\right)\\land\\left(x'\\land y'\\right)&=&\\left(x'\\land y'\\right)\\land\\left(x\\lor y\\right)&\\left(\\because {\\rm \\href{#boolean_algebra1}{公理1}: 可換律}\\right)\\\\ &=&\\left(\\left(x'\\land y'\\right)\\land x\\right)\\lor \\left(\\left(x'\\land y'\\right)\\land y\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理 2}:分配律}\\right)\\\\ &=&\\left(y'\\land\\left(x\\land x'\\right)\\right)\\lor \\left(x'\\land\\left(y\\land y'\\right)\\right)&\\left(\\because {\\rm \\href{#boolean_algebra1}{公理1}: 可換律, 定理: \\href{#associative}{結合律}}\\right)\\\\ &=&\\left(y'\\lor 0\\right)\\lor \\left(x'\\land1\\right)&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}: 補元律}\\right)\\\\ &=&0\\lor 0&\\left(\\because {\\rm 定理: \\href{#bounded}{有界律}} \\right)\\\\ &=&0&\\left(\\because {\\rm 定理:\\href{#idempotence}{べき等律}}\\right) \\end{eqnarray} また, 双対の原理 より \\(\\left(x\\land y\\right)'=x'\\lor y'\\). \\(\\square\\) シャノンの展開定理 任意の \\(n\\) 変数ブール関数 \\(f\\left(x_1,x_2,\\cdots,x_n\\right)\\) を \\(x_1\\) について, 次のように展開できる. \\begin{eqnarray} f\\left(x_1,x_2,\\cdots,x_n\\right)&=&\\left(x'_1\\lor x_1\\right)\\land f\\left(x_1,x_2,\\cdots,x_n\\right)&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}, \\href{#boolean_algebra3}{公理 3} :補元律, 同一律}\\right)\\\\ &=&x'_1\\land f\\left(x_1,x_2,\\cdots,x_n\\right)\\lor x_1\\land f\\left(x_1,x_2,\\cdots,x_n\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理 2}:分配律}\\right)\\\\ &=&x'_1\\land f\\left(0,x_2,\\cdots,x_n\\right)\\lor x_1\\land f\\left(1,x_2,\\cdots,x_n\\right)&\\left(\\because \\href{#chanon_theorem_proof}{以下に証明}\\right) \\end{eqnarray} この展開をシャノン展開という. 証明 : \\(x_1=0\\) のとき, \\[f\\left(0,x_2,\\cdots,x_n\\right)=1\\land f\\left(0,x_2,\\cdots,x_n\\right)\\lor 0\\land f\\left(1,x_2,\\cdots,x_n\\right)=f\\left(0,x_2,\\cdots,x_n\\right)\\] \\(x_1=1\\) のとき, \\[f\\left(1,x_2,\\cdots,x_n\\right)=0\\land f\\left(0,x_2,\\cdots,x_n\\right)\\lor 1\\land f\\left(1,x_2,\\cdots,x_n\\right)=f\\left(1,x_2,\\cdots,x_n\\right)\\] \\(\\square\\) 例として, \\(f\\left(x_1,x_2,x_3\\right)=x_1\\land x_2\\lor x_2\\land x_3\\lor x_1\\land x_3\\) を \\(x_1\\) について展開すると, \\begin{eqnarray} f\\left(x_1,x_2,x_3\\right)&=&x_1\\land x_2\\lor x_2\\land x_3\\lor x_1\\land x_3\\\\ &=&\\left(x'_1\\lor x_1\\right)\\land f\\left(x_1,x_2,x_3\\right)&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}, \\href{#boolean_algebra3}{公理 3} :補元律, 同一律}\\right)\\\\ &=&x'_1\\land f\\left(x_1,x_2,x_3\\right)\\lor x_1\\land f\\left(x_1,x_2,x_3\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理 2}:分配律}\\right)\\\\ &=&x'_1\\land f\\left(0,x_2,x_3\\right)\\lor x_1\\land f\\left(1,x_2,x_3\\right)&\\left(\\because {\\rm 定理: \\href{#chanon_theorem}{シャノンの展開定理}}\\right)\\\\ &=&x'_1\\land x_2\\land x_3\\lor x_1\\land x_2\\lor x_2\\land x_3\\lor x_3&\\left(\\because {\\rm \\href{#boolean_algebra3}{公理 3}:同一律}\\right)\\\\ &=&x'_1\\land x_2\\land x_3\\lor x_1\\land x_2\\lor x_3&\\left(\\because {\\rm \\href{#boolean_algebra1}{公理1}: 可換律, 定理: \\href{#absorption}{吸収律}}\\right)\\\\ \\end{eqnarray} となる. また 双対の原理 より, \\begin{eqnarray} f\\left(x_1,x_2,\\cdots,x_n\\right)&=&\\left(x_1\\land x'_1\\right)\\lor f\\left(x_1,x_2,\\cdots,x_n\\right)&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}, \\href{#boolean_algebra3}{公理 3} :補元律, 同一律}\\right)\\\\ &=&\\left(x_1\\lor f\\left(x_1,x_2,\\cdots,x_n\\right)\\right)\\land\\left(x'_1\\lor f\\left(x_1,x_2,\\cdots,x_n\\right)\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理 2}:分配律}\\right)\\\\ &=&\\left(x_1\\lor f\\left(0,x_2,\\cdots,x_n\\right)\\right)\\land\\left(x'_1\\lor f\\left(1,x_2,\\cdots,x_n\\right)\\right)&\\left(\\because {\\rm \\href{#chanon_theorem_proof}{上記証明}の\\href{#dual_def}{双対}}\\right) \\end{eqnarray} この展開をシャノン双対展開という. 標準形 異なる表現のなされたブール式が同値であるかを即座に断定することは, 一般的に困難であることが多い 2 . ここで, ブール式を一意に表す方法が決まっていれば, 即座に同値であるか判断がしやすく, 便利である. ブール代数では主に 2 つの形式が決められており, その形式への変形を標準化, また正規化という. 以下, \\(n\\) 変数ブール関数 \\(f\\left(x_1,x_2,\\cdots,x_n\\right)\\) において, \\(x_1,x_2,\\cdots,x_n\\) を入力変数, また入力変数およびその否定をリテラルという. さらに \\(n\\) 個の入力変数に対し, \\(k\\) 番目のリテラル \\(x_k&#94;{e_k}\\ \\left(1\\leq k\\leq n\\right)\\) を次のように表す. \\begin{eqnarray} x&#94;{e_k}_k=\\begin{cases} x_k&\\left(=x&#94;1_k\\right)&e_k=1{\\rm\\ のとき}\\\\ x'_k&\\left(=x&#94;0_k\\right)&e_k=0{\\rm\\ のとき} \\end{cases} \\end{eqnarray} 加法標準形, 主加法標準形 \\(f\\left(x_1,x_2,\\cdots,x_n\\right)\\) を \\(x_1,x_2\\) について シャノン展開 すると, \\begin{eqnarray} f\\left(x_1,x_2,\\cdots,x_n\\right)&=&x'_1\\land x'_2\\land f\\left(0,0,\\cdots,x_n\\right)\\\\ &&\\lor x'_1\\land x_2\\land f\\left(0,1,\\cdots,x_n\\right)\\\\ &&\\lor x_1\\land x'_2\\land f\\left(1,0,\\cdots,x_n\\right)\\\\ &&\\lor x_1\\land x_2\\land f\\left(1,1,\\cdots,x_n\\right) \\end{eqnarray} となる. 従って, 全入力変数 \\(x_1,x_2,\\cdots,x_n\\) について シャノン展開 すると, \\begin{eqnarray} f\\left(x_1,x_2,\\cdots,x_n\\right)&=&x'_1\\land x'_2\\land\\cdots\\land x'_n\\land f\\left(0,0,\\cdots,0\\right)\\\\ &&\\lor x'_1\\land x'_2\\land\\cdots\\land x_n\\land f\\left(0,0,\\cdots, 1\\right)\\\\ &&\\lor\\cdots\\\\ &&\\lor x_1\\land x_2\\land\\cdots\\land x'_n\\land f\\left(1,1,\\cdots,0\\right)\\\\ &&\\lor x_1\\land x_2\\land\\cdots\\land x_n\\land f\\left(1,1,\\cdots,1\\right) \\end{eqnarray} となる ( シャノンの定理 より数学的帰納法により証明できるが, 省略). 形式的に書けば, すなわち 最小項展開 \\(n\\) 変数ブール関数 \\(f\\left(x_1,x_2,\\cdots,x_n\\right)\\) のすべての入力変数 \\(x_1,x_2,\\cdots,x_n\\) について, シャノン展開 した形式 \\[f\\left(x_1,x_2,\\cdots,x_n\\right)=\\bigvee_{\\left(e_1,e_2,\\cdots,e_n\\right)\\in B&#94;n}f\\left(e_1,e_2,\\cdots,e_n\\right)\\land\\bigwedge_{i=1}&#94;{n}x_i&#94;{e_i}\\label{eq:first}\\tag{1}\\] は \\(f\\left(x_1,x_2,\\cdots,x_n\\right)\\) の最小項展開である 3 . なお, このときの項数は \\(2&#94;n\\) となる. これを踏まえ, 加法標準形および主加法標準形を導入する. 加法標準形, 主加法標準形 加法標準形 (以下 DNF ) は, ブール式のリテラル, または 2 つ以上のリテラルの積の和のことをいう. ここで, 2 つ以上のリテラルの積で同じ入力変数を 2 度以上含まない論理式を基本積, また標準項という. 基本積のうち, すべての入力変数を含むブール式を最小項という. すなわち, 式 \\(\\eqref{eq:first}\\) における \\(\\displaystyle\\bigwedge_{i=1}&#94;nx&#94;{e_i}_i\\) は最小項である. 主加法標準形 (principal disjunctive normal form: PDNF ) は, ブール関数を 最小項展開 した形式, すなわち式 \\(\\eqref{eq:first}\\) の形式である. 例えば, 否定論理積 \\(\\mid\\) を PDNF で表すとしよう. 否定論理和は 2 項演算子なので, その PDNF は 2 変数ブール関数を最小項展開した形となる. \\[f\\left(x_1,x_2\\right)=f\\left(0,0\\right)\\land x'_1\\land x'_2\\lor f\\left(0,1\\right)x'_1\\land x_2\\lor f\\left(1,0\\right)\\land x_1\\land x'_2\\lor f\\left(1,1\\right)\\land x_1\\land x_2\\] 便宜上, 2 項演算子 \\(\\mid\\) を最小項展開した形を \\(f_\\mid\\left(x_1,x_2\\right)\\) で表すこととする. あとは 真理値表 2 の \\(\\mid\\) の列のとおりに \\(f_\\mid\\left(x_1,x_2\\right)\\) の値を決めてやればよいので \\begin{eqnarray} f_\\mid\\left(x_1,x_2\\right)&=&1\\land x'_1\\land x'_2\\lor 1\\land x'_1\\land x_2\\lor 1\\land x_1\\land x'_2\\lor 0\\land x_1\\land x_2\\\\ &=&x'_1\\land x'_2\\lor x'_1\\land x_2\\lor x_1\\land x'_2 \\end{eqnarray} 従って, 否定論理積の PDNF は \\(x'_1\\land x'_2\\lor x'_1\\land x_2\\lor x_1\\land x'_2\\) となる. この操作を振り返ると, 真理値表から PDNF を書くためには, 結果が \\(1\\) となっている入力変数の全パターンに対して, 元の入力変数の値が \\(1\\) ならそのまま, \\(0\\) ならその補元をとり, それらすべての和を取ればよいことがわかる. 何故ならば, 結果が \\(0\\) となる部分は, シャノンの展開定理の証明 でも示したように消えてしまうからである. 同じようにして, 否定論理和, 排他的論理和も 真理値表 2 の \\(\\downarrow,\\oplus\\) の列をみると, \\(1\\) となる入力のパターンから \\begin{eqnarray} f_{\\downarrow}\\left(x_1,x_2\\right)&=&x'_1\\land x'_2\\\\ f_{\\oplus}\\left(x_1,x_2\\right)&=&x_1\\land x'_2\\lor x'_1\\land x_2\\\\ \\end{eqnarray} となる. すなわち, 真理値表で表現できるブール式は PDNF で表せるということである 5 . 次に, 任意の論理式から PDNF に変換することを考える. 結論からいうと, 次の手順に従えば PDNF へ機械的に変換できることが知られている. ブール式全体を基本項による積の和の形にする (分配律等を利用) 最小項でない基本項に対し, その基本項に含まれないすべてのリテラル \\(x_i\\) について \\(\\left(x_i\\land x'_i\\right)\\) を乗ずる 分配律等に従い展開して, 冗長な項を除去する 以下, PDNF で表されたブール式を \\(f\\left(x_1,x_2,\\cdots,x_n\\right)_{\\rm P D N F}\\) と書くこととする. 例えば, ブール式 \\(f\\left(x_1,x_2\\right)=x_1\\land x_2\\land x_1\\lor x_2\\) を PDNF で表すとすると, \\begin{eqnarray} f\\left(x_1,x_2\\right)&=&x_1\\land x_2\\land x_1\\lor x_2\\\\ &=&x_1\\land x_1\\land x_2\\lor x_2&\\left(\\because {\\rm\\href{#boolean_algebra1}{公理1}: 可換律}\\right)\\\\ &=&x_1\\land x_2\\lor x_2&\\left(\\because {\\rm 定理:\\href{#idempotence}{べき等律}}\\right)\\\\ &=&x_1\\land x_2\\lor 1\\land x_2&\\left(\\because {\\rm \\href{#boolean_algebra3}{公理 3}:同一律}\\right)\\\\ &=&x_1\\land x_2\\lor \\left(x_1\\lor x_1'\\right)\\land x_2&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}:補元律}\\right)\\\\ &=&x_1\\land x_2\\lor x_1\\land x_2\\lor x_1'\\land x_2&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理 2}:分配律}\\right)\\\\ &=&x_1\\land x_2\\lor x_1'\\land x_2&\\left(\\because {\\rm 定理:\\href{#idempotence}{べき等律}}\\right) \\end{eqnarray} 従って \\[f\\left(x_1,x_2\\right)_{\\rm P D N F}=x_1\\land x_2\\lor x_1'\\land x_2\\] となる. 例としてもう 1 つ, \\(f\\left(x_1,x_2,x_3\\right)=x_1\\land x_2'\\land x_3\\lor x_1\\land x'_3\\lor x_2\\land x'_3\\) としたときの PDNF は \\begin{eqnarray} f\\left(x_1,x_2,x_3\\right)&=&x_1\\land x'_2\\land x_3\\lor x\\land x'_3\\lor x_2\\land x'_3\\\\ &=&x_1\\land x'_2\\land x_3\\lor x_1\\land\\left(x_2\\lor x'_2\\right)\\land x'_3\\lor \\left(x_1\\lor x_1'\\right)\\land x_2\\land x'_3&\\left(\\because {\\rm \\href{#boolean_algebra3}{公理 3}, \\href{#boolean_algebra4}{公理 4}: 同一律, 補元律} \\right)\\\\ &=&x_1\\land x'_2\\land x_3\\lor x_1\\land x_2\\land x'_3\\lor x_1\\land x'_2\\land x'_3\\lor x_1\\land x_2\\land x'_3\\lor x'_1\\land x_2\\land x'_3&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理 2}:分配律}\\right)\\\\ &=&x_1\\land x'_2\\land x_3\\lor x_1\\land x_2\\land x'_3\\lor x_1\\land x'_2\\land x'_3\\lor x'_1\\land x_2\\land x'_3&\\left(\\because {\\rm 定理: \\href{#idempotence}{べき等律}}\\right) \\end{eqnarray} 従って \\[f\\left(x_1,x_2,x_3\\right)_{\\rm P D N F}=x_1\\land x'_2\\land x_3\\lor x_1\\land x_2\\land x'_3\\lor x_1\\land x'_2\\land x'_3\\lor x'_1\\land x_2\\land x'_3\\] となる. 乗法標準形, 主乗法標準形 \\(f\\left(x_1,x_2,\\cdots,x_n\\right)\\) を \\(x_1,x_2\\) について シャノン双対展開 すると, \\begin{eqnarray} f\\left(x_1,x_2,\\cdots,x_n\\right)&=&\\left(x_1\\lor x_2\\lor f\\left(0,0,\\cdots,x_n\\right)\\right)\\\\ &&\\land \\left(x_1\\lor x'_2\\lor f\\left(0,1,\\cdots,x_n\\right)\\right)\\\\ &&\\land \\left(x'_1\\lor x_2\\lor f\\left(1,0,\\cdots,x_n\\right)\\right)\\\\ &&\\land \\left(x'_1\\lor x'_2\\lor f\\left(1,1,\\cdots,x_n\\right)\\right) \\end{eqnarray} となる. 従って, 全入力変数 \\(x_1,x_2,\\cdots,x_n\\) について シャノン双対展開 すると, \\begin{eqnarray} f\\left(x_1,x_2,\\cdots,x_n\\right)&=&\\left(x_1\\lor x_2\\lor\\cdots\\lor x_n\\lor f\\left(0,0,\\cdots,0\\right)\\right)\\\\ &&\\land\\left(x_1\\lor x_2\\lor\\cdots\\lor x'_n\\lor f\\left(1,0,\\cdots,0\\right)\\right)\\\\ &&\\land\\cdots\\\\ &&\\land\\left(x'_1\\lor x'_2\\lor\\cdots x_n\\lor f\\left(1,1,\\cdots,0\\right)\\right)\\\\ &&\\land\\left(x'_1\\lor x'_2\\lor\\cdots x'_n\\lor f\\left(1,1,\\cdots,1\\right)\\right) \\end{eqnarray} となる ( シャノンの定理 より数学的帰納法により証明できるが, 省略). 形式的に書けば, すなわち 最大項展開 \\(n\\) 変数ブール関数 \\(f\\left(x_1,x_2,\\cdots,x_n\\right)\\) のすべての入力変数 \\(x_1,x_2,\\cdots,x_n\\) について, シャノン双対展開 した形式 \\[f\\left(x_1,x_2,\\cdots,x_n\\right)=\\bigwedge_{\\left(e_1,e_2,\\cdots,e_n\\right)\\in B&#94;n}\\left(f\\left(e_1,e_2,\\cdots,e_n\\right)\\lor\\bigvee_{i=1}&#94;{n}x_i&#94;{e'_i}\\right)\\label{eq:second}\\tag{2}\\] は \\(f\\left(x_1,x_2,\\cdots,x_n\\right)\\) の最大項展開である. なお, このときの項数は \\(2&#94;n\\) となる. これを踏まえ, 乗法標準形, 主乗法標準形を導入する. 乗法標準形, 主乗法標準形 乗法標準形 (以下 CNF ) は, ブール式のリテラル, または 2 つ以上のリテラルの和の積のことをいう. ここで, 2 つ以上のリテラルの和で同じ入力変数を 2 度以上含まないブール式を基本和, また標準項という. 基本和のうち, すべての入力変数を含むブール式を最大項という. すなわち, 式 \\(\\eqref{eq:second}\\) における \\(\\displaystyle\\bigvee_{i=1}&#94;{n}x_i&#94;{e'_i}\\) は最大項である. 主乗法標準形 (principal conjunctive normal form: PCNF ) は, ブール関数を 最大項展開 した形式, すなわち式 \\(\\eqref{eq:second}\\) の形式である. 例えば, 否定論理積 \\(\\mid\\) を PCNF で表すとしよう. 否定論理積は 2 項演算子なので, その PCNF は 2 変数ブール関数を最大項展開した形となる. \\[f\\left(x_1,x_2\\right)=\\left(x_1\\lor x_2\\lor f\\left(0,0\\right)\\right)\\land \\left(x_1\\lor x'_2\\lor f\\left(0,1\\right)\\right)\\land\\left(x'_1\\lor x_2\\lor f\\left(1,0\\right)\\right)\\land\\left(x'_1\\lor x'_2\\lor f\\left(1,1\\right)\\right)\\] 2 項演算子 \\(\\mid\\) を最大項展開した式 \\(f_{\\mid}\\left(x_1,x_2\\right)\\) は, 真理値表 2 の \\(\\mid\\) の列のとおりに \\(f_{\\mid}\\left(x_1,x_2\\right)\\) の値を決めてやればよいので \\begin{eqnarray} f_{\\mid}\\left(x_1,x_2\\right)&=&\\left(x_1\\lor x_2\\lor 1\\right)\\land \\left(x_1\\lor x'_2\\lor 1\\right)\\land\\left(x'_1\\lor x_2\\lor 1\\right)\\land\\left(x'_1\\lor x'_2\\lor 0\\right)\\\\ &=&x'_1\\lor x'_2 \\end{eqnarray} 従って, 否定論理積の PCNF は \\(x'_1\\lor x'_2\\) となる. この操作を振り返ると, 真理値表から PCNF を書くためには, 結果が \\(0\\) となっている入力変数の全パターンに対して, 元の入力変数の値が \\(1\\) なら補元をとり, \\(0\\) ならそのままで和を取り, それらすべての積を取ればよいことがわかる. 何故ならば, 結果が \\(1\\) となる部分は, 和の性質, すなわち 公理 2: 同一律 より消えてしまうからである. 同じようにして, 否定論理和, 排他的論理和も 真理値表 2 の \\(\\downarrow,\\oplus\\) の列をみると, \\(0\\) となる入力のパターンから \\begin{eqnarray} f_{\\downarrow}\\left(x_1,x_2\\right)&=&\\left(x'_1\\lor x'_2\\right)\\land\\left(x'_1\\lor x_2\\right)\\land\\left(x_1\\lor x'_2\\right)\\\\ f_{\\oplus}\\left(x_1,x_2\\right)&=&\\left(x'_1\\lor x'_2\\right)\\land\\left(x_1\\lor y_1\\right) \\end{eqnarray} となる. すなわち, 真理値表で表現できるブール式は, PCNF で表せるということである 5 . 次に, 任意の論理式から PCNF に変換することを考える. 結論からいうと, 次の手順に従えば PCNF へ機械的に変換できることが知られている. ブール式全体を基本項による和の積の形にする (分配律等を利用) 最大項でない基本項に対し, その基本項に含まれないすべてのリテラル \\(x_i\\) について \\(x_i\\land x'_i\\) を乗ずる 分配律等に従い展開して, 冗長な項を除去する 以下, PCNF で表されたブール式を \\(f\\left(x_1,x_2,\\cdots,x_n\\right)_{\\rm P C N F}\\) と書くこととする. 例えば, ブール式 \\(f\\left(x_1,x_2,x_3\\right)=x_1\\land\\left(x'_2\\land x_3\\right)'\\) を PCNF で表すとすると, \\begin{eqnarray} f\\left(x_1,x_2,x_3\\right)&=&x_1\\land\\left(x'_2\\land x_3\\right)'\\\\ &=&x_1\\land\\left(x_2\\lor x'_3\\right)&\\left(\\because {\\rm 定理: \\href{#de_morgan}{ド・モルガンの法則}}\\right)\\\\ &=&\\left(x_1\\lor x_2\\land x'_2\\right)\\land\\left(x_2\\lor x'_3\\right)&\\left(\\because {\\rm \\href{#boolean_algebra3}{公理 3}:同一律}\\right)\\\\ &=&\\left(x_1\\lor x_2\\right)\\land\\left(x_1\\lor x'_2\\right)\\land\\left(x_2\\lor x'_3\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理 2}:分配律}\\right)\\\\ &=&\\left(x_1\\lor x_2\\lor x_3\\land x'_3\\right)\\land\\left(x_1\\lor x'_2\\lor x_3\\land x'_3\\right)\\land\\left(x_1\\land x'_1\\lor x_2\\land x'_3\\right)&\\left(\\because {\\rm \\href{#boolean_algebra3}{公理 3}:同一律}\\right)\\\\ &=&\\left(x_1\\lor x_2\\lor x_3\\right)\\land\\left(x_1\\lor x_2\\lor x'_3\\right)\\land\\left(x_1\\lor x'_2\\lor x_3\\right)\\\\ &&\\land\\left(x_1\\lor x'_2\\lor x'_3\\right)\\land\\left(x_1\\lor x_2\\lor x'_3\\right)\\land\\left(x'_1\\lor x_2\\lor x'_3\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理 2}:分配律}\\right)\\\\ &=&\\left(x_1\\lor x_2\\lor x_3\\right)\\land\\left(x_1\\lor x_2\\lor x'_3\\right)\\land\\left(x_1\\lor x'_2\\lor x_3\\right)\\\\ &&\\land\\left(x_1\\lor x'_2\\lor x'_3\\right)\\land\\left(x'_1\\lor x_2\\lor x'_3\\right)&\\left(\\because {\\rm 定理:\\href{#idempotence}{べき等律}}\\right) \\end{eqnarray} 従って \\[f\\left(x_1,x_2,x_3\\right)_{\\rm P C N F}=\\left(x_1\\lor x_2\\lor x_3\\right)\\land\\left(x_1\\lor x_2\\lor x'_3\\right)\\land\\left(x_1\\lor x'_2\\lor x_3\\right)\\land\\left(x_1\\lor x'_2\\lor x'_3\\right)\\land\\left(x'_1\\lor x_2\\lor x'_3\\right)\\] となる. 例としてもう 1 つ, \\(f\\left(x_1,x_2,x_3\\right)=x_1\\land x'_2\\lor x_2\\land x_3\\) としたときの PCNF は \\begin{eqnarray} f\\left(x_1,x_2,x_3\\right)&=&x_1\\land x'_2\\lor x_2\\land x_3\\\\ &=&\\left(x_1\\land x'_2\\lor x_2\\right)\\land\\left(x_1\\land x'_2\\lor x_3\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理 2}:分配律}\\right)\\\\ &=&\\left(x_1\\lor x_2\\right)\\land\\left(x_1\\lor x_3\\right)\\land\\left(x'_2\\lor x_3\\right)&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}:補元律}\\right)\\\\ &=&\\left(x_1\\lor x_2\\lor x_3\\land x'_3\\right)\\land\\left(x_1\\lor x_2\\land x'_2\\lor x_3\\right)\\land\\left(x_1\\land x'_1\\lor x'_2\\lor x_3\\right)&\\left(\\because {\\rm \\href{#boolean_algebra4}{公理 4}:補元律}\\right)\\\\ &=&\\left(x_1\\lor x_2\\lor x_3\\right)\\land\\left(x_1\\lor x_2\\lor x'_3\\right)\\land\\left(x_1\\lor x'_2\\lor x_3\\right)\\land\\left(x'_1\\lor x'_2\\lor x_3\\right)&\\left(\\because {\\rm \\href{#boolean_algebra2}{公理 2}:分配律}\\right) \\end{eqnarray} 従って \\[f\\left(x_1,x_2,x_3\\right)_{\\rm P C N F}=\\left(x_1\\lor x_2\\lor x_3\\right)\\land\\left(x_1\\lor x_2\\lor x'_3\\right)\\land\\left(x_1\\lor x'_2\\lor x_3\\right)\\land\\left(x'_1\\lor x'_2\\lor x_3\\right)\\] となる. 簡単化 ブール式を簡単化する方法について見ていく. カルノー図 例えばブール関数が \\[f\\left(x_1,x_2\\right)=x_1\\land x'_2\\lor x'_1\\land x'_2\\lor x_1\\land x'_2\\lor x_1\\land x_2 \\label{eq:third}\\tag{3}\\] と与えられたとき, 式変形をしていくと簡単化できることがわかる. 事実, \\(\\eqref{eq:third}=\\left(x_1\\lor x'_1\\right)\\land x'_2\\lor x_1\\land\\left(x'_2\\lor x_2\\right)=x'_2\\lor x_1\\) である. このような, 公理4: 補元律 を用いた式変形は, カルノー図という図式を用いることで視覚的に捉えることができる. カルノー図は, 真理値表を 2 次元的に並べる形をしており, 例えば式 \\(\\eqref{eq:third}\\) をカルノー図で表すと次のようになる. \\(x_1\\backslash x_2\\) \\(0\\) \\(1\\) カルノー図 1 \\(0\\) \\(1\\) \\(0\\) \\(1\\) \\(1\\) \\(1\\) 緑色の表示となっているセルの部分それぞれが最小項を表しており, 元の論理関数に含まれる最小項のセルには \\(1\\), 含まれないセルには \\(0\\) を記述する 6 ことで 上図 のようになる. このとき, 緑色の表示となっているセルの部分の個数は \\(2&#94;n\\) である. これらをまとめることが, 冗長な変数の削除に対応するのである. カルノー図をみて \\(1\\) となるセルの和を書き下すことは, PDNF を書くことと同値である (\\(\\eqref{eq:third}\\) のブール式は元から PDNF である. カルノー図 1 から結果として, これが導出できる). カルノー図の隣接するセルの間では, 全ての変数のうちのどれか 1 つの \\(1\\) か \\(0\\) が変わった結果となっているので, 公理4: 補元律 を利用してまとめることができるのである. 従って, 隣接する \\(1\\) のセルをグループ化し, 公理4: 補元律 を利用することで簡単化が実現できる. 以下, \\(i\\) 行目 \\(j\\) 列目のセルを \\(i:j\\) と示すこととする. 例えば, カルノー図 1 で \\(1\\) となるセルは \\(1:1,2:1,2:2\\) で, これらはそれぞれ \\(x'_1\\land x'_2,x_1\\land x'_2,x_1\\land x_2\\) である. ここで, 任意の隣接するセル \\(c_i\\) をグループ化したことを \\(\\left\\{c_1,c_2,\\cdots,c_n\\right\\}\\) と書くとき, \\(g_1=\\left\\{1:1,2:1\\right\\}, g_2=\\left\\{2:1,2:2\\right\\}\\) とグループ化できることがわかる. 従って, それぞれを論理式で基本積の形に表すと, \\begin{eqnarray} g_1&=&x'_1\\land x'_2\\lor x_1\\land x'_2&=&\\left(x'_1\\lor x_1\\right)\\land x'_2&=&x'_2\\\\ g_2&=&x_1\\land x'_2\\lor x_1\\land x_2&=&x_1\\land\\left(x'_2\\lor x_2\\right)&=&x_1 \\end{eqnarray} よって, \\(\\eqref{eq:third}=x'_2\\lor x_1\\) とわかる. 別のカルノー図についてもやってみよう. \\(x_1x_2\\backslash x_3x_4\\) \\(00\\) \\(01\\) \\(11\\) \\(10\\) カルノー図 2 \\(00\\) \\(0\\) \\(1\\) \\(1\\) \\(0\\) \\(01\\) \\(0\\) \\(1\\) \\(0\\) \\(0\\) \\(11\\) \\(0\\) \\(0\\) \\(0\\) \\(0\\) \\(10\\) \\(1\\) \\(0\\) \\(1\\) \\(1\\) これは, 4 つの引数をもったブール関数のカルノー図である. カルノー図では, 最上, 最下また最左, 最右のセルは隣接していると考える. 従って, カルノー図 2 におけるグループ化の一つの例として \\(g_1=\\left\\{1:2,2:2\\right\\},g_2=\\left\\{1:3,4:3\\right\\},g_3=\\left\\{4:1,4:4\\right\\}\\) と構成できる. よって, \\begin{eqnarray} g_1&=&x'_1\\land x'_2\\land x'_3\\land x_4\\lor x'_1\\land x_2\\land x'_3\\land x_4&=&x'_1\\land x'_3\\land x_4\\\\ g_2&=&x'_1\\land x'_2\\land x_3\\land x_4\\lor x_1\\land x'_2\\land x_3\\land x_4&=&x'_2\\land x_3\\land x_4\\\\ g_3&=&x_1\\land x'_2\\land x'_3\\land x'_4\\lor x_1\\land x'_2\\land x_3\\land x'_4&=&x_1\\land x'_2\\land x'_4 \\end{eqnarray} ゆえに カルノー図 2 で示される論理関数の簡単な表現は \\[x'_1\\land x'_3\\land x_4\\lor x'_2\\land x_3\\land x_4\\lor x_1\\land x'_2\\land x'_4\\] となる. このグループ化という操作が一意ではないことからわかるように, 簡単化したブール式も一意でないことがわかる. 例えば, \\(g_1=\\left\\{1:2,2:2\\right\\},g_2=\\left\\{1:2,1:3\\right\\},g_3=\\left\\{4:1,4:4\\right\\},g_4=\\left\\{4:3,4:4\\right\\}\\) とグループ化すると, \\begin{eqnarray} g_1&=&x'_1\\land x'_2\\land x'_3\\land x_4\\lor x'_1\\land x_2\\land x'_3\\land x_4&=&x'_1\\land x'_3\\land x_4\\\\ g_2&=&x'_1\\land x'_2\\land x'_3\\land x_4\\lor x'_1\\land x'_2\\land x_3\\land x_4&=&x'_1\\land x'_2\\land x_4\\\\ g_3&=&x_1\\land x'_2\\land x'_3\\land x'_4\\lor x_1\\land x'_2\\land x_3\\land x'_4&=&x_1\\land x'_2\\land x'_4\\\\ g_4&=&x_1\\land x'_2\\land x_3\\land x_4\\lor x_1\\land x'_2\\land x_3\\land x'_4&=&x_1\\land x'_2\\land x_3 \\end{eqnarray} ゆえに, \\[x'_1\\land x'_3\\land x_4\\lor x'_1\\land x'_2\\land x_4\\lor x_1\\land x'_2\\land x'_4\\lor x_1\\land x'_2\\land x_3\\] となる. 1 つの例を見ただけなので, 厳密に言えたことではないが, 一般的にグループの数が少なく, かつグループ内のセルの数を(\\(2n\\) 個で)なるべく多く取る方がより簡単な論理式を構成できることがわかる. さて, ある論理変数の組み合わせが予め起こりえないことがわかっていたとき, その場合もカルノー図を用いて簡単化を進めることができる. このような組み合わせに対する最小項を禁止項, または don't care 項という. 例えば, \\begin{eqnarray} f\\left(x_1,x_2,x_3,x_4\\right)&=&x'_1\\land x'_2\\land x'_3\\land x_4 \\\\ &&\\lor x'_1\\land x_2\\land x'_3\\land x_4 \\\\ &&\\lor x'_1\\land x_2\\land x_3\\land x_4\\\\ &&\\lor x'_1\\land x_2\\land x_3\\land x'_4\\\\ &&\\lor x_1\\land x'_2\\land x_3\\land x_4\\\\ &&\\lor x_1\\land x'_2\\land x_3\\land x'_4\\label{eq:fourth}\\tag{4} \\end{eqnarray} というブール関数を簡単化することを考える. このとき, \\(x_1\\land x_2\\), また \\(x_1\\land x'_2\\land x'_3\\land x'_4\\) は禁止項とする. 禁止行の対応するセルには \\(\\phi\\) を記述する. すると, 式 \\(\\eqref{eq:fourth}\\) のカルノー図は次のとおりとなる. \\(x_1x_2\\backslash x_3x_4\\) \\(00\\) \\(01\\) \\(11\\) \\(10\\) カルノー図 3 \\(00\\) \\(0\\) \\(1\\) \\(0\\) \\(0\\) \\(01\\) \\(0\\) \\(1\\) \\(1\\) \\(1\\) \\(11\\) \\(\\phi\\) \\(\\phi\\) \\(\\phi\\) \\(\\phi\\) \\(10\\) \\(\\phi\\) \\(0\\) \\(1\\) \\(1\\) 禁止項は, \\(1\\) でも \\(0\\) でもよいということになるので, グループを構成するにあたって自分で都合よく \\(1\\) か \\(0\\) に解釈してしまって良い. できる限り多くのセルと少ないグループの数で構成するために, いま \\(3:3,3:4\\) を \\(1\\) と解釈すれば, \\(g_1=\\left\\{1:2,2:2\\right\\},g_2=\\left\\{2:3,2:4,3:3,3:4\\right\\},g_3=\\left\\{3:3,3:4,4:3,4:4\\right\\}\\) とグループ化できる. 従って, \\begin{eqnarray} g_1&=&x'_1\\land x'_2\\land x'_3\\land x_4\\lor x'_1\\land x_2\\land x'_3\\land x_4&=&x'_1\\land x'_3\\land x_4\\\\ g_2&=&x'_1\\land x_2\\land x_3\\land x_4\\lor x'_1\\land x_2\\land x_3\\land x'_4\\lor x_1\\land x_2 \\land x_3\\land x_4\\lor x_1\\land x_2\\land x_3\\land x'_4&=&x_2\\land x_3\\\\ g_3&=&x_1\\land x_2\\land x_3\\land x_4\\lor x_1\\land x_2\\land x_3\\land x'_4\\lor x_1\\land x'_2\\land x_3\\land x_4\\lor x_1\\land x'_2\\land x_3\\land x'_4&=&x_1\\land x_3 \\end{eqnarray} ゆえに, \\(\\eqref{eq:fourth}\\) は \\[f\\left(x_1,x_2,x_3,x_4\\right)=x'_1\\land x'_3\\land x_4\\lor x_2\\land x_3\\lor x_1\\land x_3\\] と簡単化できた. カルノー図は, 1 次元につき 2 つまでの引数を扱えると考えると, 人間の次元認識能力の見地から実質 6 つの引数にまで対応できることとなるわけだが, 実際は平面的に考えることが多いので, 大抵, 最大 4 個の引数までしか扱うことができない. クワイン・マクラスキー法 主にクワイン・マクラスキー法は \\[x\\land y\\lor x\\land y'=x\\land\\left(y\\lor y'\\right)=x\\label{eq:fifth}\\tag{5}\\] を繰り返し利用し, ブール関数を機械的に簡単化していく方法であり, その手順は次のとおりである. ブール式を PDNF にする 式 \\(\\eqref{eq:fifth}\\) を利用して圧縮し, 主項を求める ブール式を 2 進値に割り当てる 7 ハミング距離 1 のビット列同士を可能な限り繰り返し組み合わせる 求めた主項からただ 1 つの最小項を包含する主項(必須項)を求める. ブール関数を作成する 必須項の和をとる 必須項により包含されていない最小項があるとき, 最も簡単な主項を選択し和を取る. いま, 式 \\(\\eqref{eq:fourth}\\) を簡単化することを考えるとしよう. このとき, まず式を PDNF にする. \\(\\eqref{eq:fourth}\\) はすでに PDNF の形式となっているので, 今回は必要ない. 次に, カルノー図 3 の各セル \\(i:j\\) を \\(m_0=1:1,m_1=2:1,m_2=3:1,m_3=4:1,m_4=1:2,\\cdots,m_{15}=4:4\\) とおき, PDNF を構成する各最小項について次のようにビット列と対応させる. \\begin{eqnarray} m_4&=&x'_1\\land x'_2\\land x'_3\\land x_4=0001\\\\ m_5&=&x'_1\\land x_2\\land x'_3\\land x_4=0101\\\\ m_9&=&x'_1\\land x_2\\land x_3\\land x_4=0111\\\\ m_{11}&=&x_1\\land x'_2\\land x_3\\land x_4=1011\\\\ m_{13}&=&x'_1\\land x_2\\land x_3\\land x'_4=0110\\\\ m_{15}&=&x_1\\land x'_2\\land x_3\\land x'_4=1010 \\end{eqnarray} ここで, 先と同様, \\(x_1\\land x_2\\) と \\(x_1\\land x'_2\\land x'_3\\land x'_4\\) を禁止項としたときは, それについてもビット列と対応させておく. \\begin{eqnarray} m_2&=&x_1\\land x_2\\land x'_3\\land x'_4=1100\\\\ m_3&=&x_1\\land x'_2\\land x'_3\\land x'_4=1000\\\\ m_6&=&x_1\\land x_2\\land x'_3\\land x_4=1101\\\\ m_{10}&=&x_1\\land x_2\\land x_3\\land x_4=1111\\\\ m_{14}&=&x_1\\land x_2\\land x_3\\land x'_4=1110 \\end{eqnarray} これは \\(\\displaystyle\\bigvee {\\rm m}\\left(4,5,9,11,13,15\\right)+{\\rm dc}\\left(2,3,6,10,14\\right)=\\eqref{eq:fourth}\\) と書かれる. このとき, 例えば \\(m_4\\lor m_5\\) は式 \\(\\eqref{eq:fifth}\\) を利用して簡単化できることがわかる. 事実, \\[x'_1\\land x'_2\\land x'_3\\land x_4\\lor x'_1\\land x_2\\land x'_3\\land x_4=x'_1\\land x'_3\\land x_4\\land\\left(x'_2\\lor x_2\\right)=x'_1\\land x'_3\\land x_4\\] である. このような簡単化をすべての可能な組み合わせについて繰り返し実行する. この作業を圧縮ということとする. 先にブール式をビット列と対応させたので, 圧縮とはハミング距離 1 のビット列同士を繰り返し組み合わせることと同値である. 次の表に, 圧縮を 1 度行った結果を示す. 組み合わせられたビット部分は \\(-\\), それ以上圧縮できないものを主項といい, \\(\\ast\\) で示すものとする 8 . これを圧縮表ということとする. 1 の数 最小項 ビット列表現 圧縮表 (1 回目) \\(1\\) \\(m_{4,5}\\) \\(0-01\\ast\\) \\(m_{3,15}\\) \\(10-0\\) \\(m_{2,3}\\) \\(1-00\\) \\(2\\) \\(m_{5,9}\\) \\(01-1\\) \\(m_{5,6}\\) \\(-101\\) \\(m_{9,13}\\) \\(011-\\) \\(m_{13,14}\\) \\(-110\\) \\(m_{14,15}\\) \\(1-10\\) \\(m_{11,15}\\) \\(101-\\) \\(m_{2,6}\\) \\(110-\\) \\(m_{2,14}\\) \\(11-0\\) \\(3\\) \\(m_{9,10}\\) \\(-111\\) \\(m_{10,11}\\) \\(1-11\\) \\(m_{6,10}\\) \\(11-1\\) \\(m_{10,14}\\) \\(111-\\) 残りのすべての最小項について \\(\\ast\\) がつくまで繰り返す. 1 の数 最小項 ビット列表現 圧縮表 (2 回目) \\(1\\) \\(m_{2,3,14,15}\\) \\(1—0\\ast\\) \\(2\\) \\(m_{5,6,9,10}\\) \\(-1-1\\ast\\) \\(m_{9,10,13,14}\\) \\(-11-\\ast\\) \\(m_{10,11,14,15}\\) \\(1-1-\\ast\\) \\(m_{2,6,10,14}\\) \\(11—\\ast\\) 従って, 主項は \\(m_{4,5},m_{2,3,14,15},m_{5,6,9,10},m_{9,10,13,14},m_{10,11,14,15},m_{2,6,10,14}\\) であるから, 圧縮表 1 および 2 より, 式 \\(\\eqref{eq:fourth}\\) は次のように表現できることがわかる. \\[\\underbrace{x'_1\\land x'_3\\land x_4}_{m_{4,5}}\\lor \\underbrace{x_1\\land x'_4}_{m_{2,3,14,15}}\\lor\\underbrace{x_2\\land x_4}_{m_{5,6,9,10}}\\lor\\underbrace{x_2\\land x_3}_{m_{9,10,13,14}}\\lor\\underbrace{x_1\\land x_3}_{m_{10,11,14,15}}\\lor \\underbrace{x_1\\land x_2}_{m_{2,6,10,14}}\\] しかしこれはまだ冗長である. この主項から必須項を調べる. 縦軸に主項, 横軸に最小項を並べ, 最小項を包含する主項のセルに印 \\(\\bigcirc\\) を, 包含する最小項が 1 つしかない主項のセルに印 \\(\\circledcirc\\) をつける. これを主項表という. 主項 \\(\\backslash\\) 最小項 \\(m_4\\) \\(m_5\\) \\(m_9\\) \\(m_{13}\\) \\(m_{11}\\) \\(m_{15}\\) ビット表現 主項表 1 \\(m_{4,5}\\) \\(\\require{color}\\textcolor{blue}{\\circledcirc}\\) \\(\\require{color}\\textcolor{blue}{\\bigcirc}\\) \\(0-01\\) \\(m_{5,6,9,10}\\) \\(\\bigcirc\\) \\(\\bigcirc\\) \\(-1-1\\) \\(m_{9,10,13,14}\\) \\(\\require{color}\\textcolor{blue}{\\bigcirc}\\) \\(\\require{color}\\textcolor{blue}{\\circledcirc}\\) \\(-11-\\) \\(m_{10,11,14,15}\\) \\(\\require{color}\\textcolor{blue}{\\circledcirc}\\) \\(\\require{color}\\textcolor{blue}{\\bigcirc}\\) \\(1-1-\\) \\(m_{2,3,14,15}\\) \\(\\bigcirc\\) \\(1—0\\) \\(m_{2,6,10,14}\\) \\(11—\\) 従って, 必須項は \\(\\circledcirc\\) のつく \\(m_{4,5},m_{9,10,13,14},m_{10,11,14,15}\\) である. あとはそれらを書き出し, 残りの主項で最小項を全て含む最も簡単な組み合わせを探すこととなる(ここで現れる必須項が全ての最小項を包含するとは限らない). ここで, もし \\(\\circledcirc\\) が 1 つも含まれない最小項があれば, すなわち必須項にすべての最小項が含まれていなければ, 最も簡単となりかつ, 全ての最小項を含むブール式となるよう適当な主項を選択する. 今回の場合では, 必須項のみで全ての最小項を包含することができている(印を青の表示としておいた)から \\(m_{4,5},m_{9,10,13,14},m_{10,11,14,15}\\) の和, すなわち \\[x'_1\\land x'_3\\land x_4\\lor x_2\\land x_3\\lor x_1\\land x_3\\] が式 \\(\\eqref{eq:fourth}\\) の最簡形である. 先に示したカルノー図による簡単化で得られたブール式と同等の結果が得られたことがわかる. なお, クワイン・マクラスキー法は NP 完全である 9 ため, 使用範囲が限られる. ペトリック法 先のクワイン・マクラスキー法の最後では, 「最も簡単となりかつ, 全ての最小項を含むブール式となるよう適当な主項を選択」することによって最簡形を得るとのことであったが, この部分をペトリック法で置き換えることにより, 機械的に最簡形のブール式を決定することができる. ここでも, \\(\\eqref{eq:fourth}\\) を例に方法を示すこととする. クワイン・マクラスキー法の手順のうち 3 まで実行したものとし, 主項表 1 が得られたとしよう. まず 主項表 1 の列を見て, 印のある主項らで和を取り, それらの積をとった次の式を得る. \\[m_{4,5}\\land \\left(m_{4,5}\\lor m_{5,6,9,10}\\right)\\land\\left(m_{5,6,9,10}\\lor m_{9,10,13,14}\\right)\\land m_{9,10,13,14}\\land m_{10,11,14,15}\\land\\left(m_{10,11,14,15}\\lor m_{2,3,14,15}\\right)\\label{eq:sixth}\\tag{6}\\] 式 \\(\\eqref{eq:sixth}\\) を 公理2 : 分配律および 吸収律 を用いて変形していくと, \\begin{eqnarray} \\eqref{eq:sixth}&=&\\left(m_{4,5}\\lor m_{4,5}\\land m_{5,6,9,10}\\right)\\land\\left(m_{5,6,9,10}\\land m_{9,10,13,14}\\lor m_{9,10,13,14}\\right)\\land\\left(m_{10,11,14,15}\\lor m_{10,11,14,15}\\land m_{2,3,14,15}\\right)\\\\ &=&m_{4,5}\\land m_{9,10,13,14}\\land m_{10,11,14,15} \\end{eqnarray} この主項の積となっている部分を主項の和とすることで, ブール関数の最簡形が求まる. 従って, 先と同様の結果が機械的に得られたことがわかる. クワイン・マクラスキー法, ペトリック法の実装 これらは一度プログラムで実装することが割と学習の定番となっているので, Haskell で実装した. 次のリポジトリにて管理している. falgon/bsimplified - The simple and pure implementation of Quine-McCluskey method, Petrick's method and parsing of Boolean formula まず, いま解いた簡単化を再度実行してみる. よくある実装法だと思うが, クワイン・マクラスキー法の圧縮過程は二分木のデータ構造として表現する. 従って, まずはじめに各最小項に対応するノードを作成することで PDNF を表現することとした. Prelude > : m + BSimplified . QMM Data . Maybe Prelude BSimplified . QMM Data . Maybe > let tr = fromJust $ pdnfForest ( fromJust $ strBitsList [ \"0001\" , \"0101\" , \"0111\" , \"1011\" , \"0110\" , \"1010\" , \"1100\" , \"1000\" , \"1101\" , \"1111\" , \"1110\" ]) ( replicate 6 False ++ replicate 5 True ) Prelude BSimplified . QMM Data . Maybe > tr [ CTNode { row = TruthTableRow { var = 1 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 18370878410602274422 , prevLeft = CTEmpty , prevRight = CTEmpty }, CTNode { row = TruthTableRow { var = 101 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 17795521015237778886 , prevLeft = CTEmpty , prevRight = CTEmpty }, CTNode { row = TruthTableRow { var = 111 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 9505003458451781531 , prevLeft = CTEmpty , prevRight = CTEmpty }, CTNode { row = TruthTableRow { var = 1011 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 5344459161969259783 , prevLeft = CTEmpty , prevRight = CTEmpty }, CTNode { row = TruthTableRow { var = 110 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 2509103263232437805 , prevLeft = CTEmpty , prevRight = CTEmpty }, CTNode { row = TruthTableRow { var = 1010 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 9465362842462816922 , prevLeft = CTEmpty , prevRight = CTEmpty }, CTNode { row = TruthTableRow { var = 1100 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 5080631804786515567 , prevLeft = CTEmpty , prevRight = CTEmpty }, CTNode { row = TruthTableRow { var = 1000 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 8905849755465195471 , prevLeft = CTEmpty , prevRight = CTEmpty }, CTNode { row = TruthTableRow { var = 1101 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 7582384624143865392 , prevLeft = CTEmpty , prevRight = CTEmpty }, CTNode { row = TruthTableRow { var = 1111 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 4819471800686604738 , prevLeft = CTEmpty , prevRight = CTEmpty }, CTNode { row = TruthTableRow { var = 1110 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 8582731269452337816 , prevLeft = CTEmpty , prevRight = CTEmpty }] pdnfForest には QMyBits のインスタンス ( DigitListBits , StrBits , RawBits ) のリストと Don't care か否かを制御するフラグのリストを渡す. このとき, 2 つのリストの要素数は同一でなければならない (もしそうでなければ Nothing が返る). ここで, DigitListBits , StrBits , RawBits はそれぞれビット列の表現を包括的に捉えるための型である. Prelude BSimplified . QMM Data . Maybe > : m + BSimplified . Bits Prelude BSimplified . QMM Data . Maybe BSimplified . Bits > toRawBits ( StrBits \"1010\" ) == toRawBits ( RawBits 10 ) True Prelude BSimplified . QMM Data . Maybe BSimplified . Bits > toRawBits ( StrBits \"1010\" ) == toRawBits ( DigitListBits [ 1 , 0 , 1 , 0 ]) True クワイン・マクラスキー法によって圧縮を実行する. Prelude BSimplified . QMM Data . Maybe BSimplified . Bits > quineMcCluskey tr PrimeImplicants [ CTNode { row = TruthTableRow { var = 1 ( binary ), dontcare = False }, mergedFlag = 2 , identifier = 577617992350188464 , prevLeft = CTNode { row = TruthTableRow { var = 1 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 18370878410602274422 , prevLeft = CTEmpty , prevRight = CTEmpty }, prevRight = CTNode { row = TruthTableRow { var = 101 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 17795521015237778886 , prevLeft = CTEmpty , prevRight = CTEmpty }}, CTNode { row = TruthTableRow { var = 11 ( binary ), dontcare = False }, mergedFlag = 2 , identifier = 6829379978376433071 , prevLeft = CTNode { row = TruthTableRow { var = 11 ( binary ), dontcare = False }, mergedFlag = 1 , identifier = 8439440437090953821 , prevLeft = CTNode { row = TruthTableRow { var = 101 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 17795521015237778886 , prevLeft = CTEmpty , prevRight = CTEmpty }, prevRight = CTNode { row = TruthTableRow { var = 111 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 9505003458451781531 , prevLeft = CTEmpty , prevRight = CTEmpty }}, prevRight = CTNode { row = TruthTableRow { var = 111 ( binary ), dontcare = False }, mergedFlag = 1 , identifier = 3159344086055741426 , prevLeft = CTNode { row = TruthTableRow { var = 1101 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 7582384624143865392 , prevLeft = CTEmpty , prevRight = CTEmpty }, prevRight = CTNode { row = TruthTableRow { var = 1111 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 4819471800686604738 , prevLeft = CTEmpty , prevRight = CTEmpty }}}, CTNode { row = TruthTableRow { var = 11 ( binary ), dontcare = False }, mergedFlag = 2 , identifier = 10719524625750522604 , prevLeft = CTNode { row = TruthTableRow { var = 11 ( binary ), dontcare = False }, mergedFlag = 0 , identifier = 11617789877111658934 , prevLeft = CTNode { row = TruthTableRow { var = 111 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 9505003458451781531 , prevLeft = CTEmpty , prevRight = CTEmpty }, prevRight = CTNode { row = TruthTableRow { var = 110 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 2509103263232437805 , prevLeft = CTEmpty , prevRight = CTEmpty }}, prevRight = CTNode { row = TruthTableRow { var = 111 ( binary ), dontcare = False }, mergedFlag = 0 , identifier = 3889360259696288602 , prevLeft = CTNode { row = TruthTableRow { var = 1111 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 4819471800686604738 , prevLeft = CTEmpty , prevRight = CTEmpty }, prevRight = CTNode { row = TruthTableRow { var = 1110 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 8582731269452337816 , prevLeft = CTEmpty , prevRight = CTEmpty }}}, CTNode { row = TruthTableRow { var = 11 ( binary ), dontcare = False }, mergedFlag = 1 , identifier = 18197116026168548551 , prevLeft = CTNode { row = TruthTableRow { var = 101 ( binary ), dontcare = False }, mergedFlag = 0 , identifier = 14515361159708671901 , prevLeft = CTNode { row = TruthTableRow { var = 1011 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 5344459161969259783 , prevLeft = CTEmpty , prevRight = CTEmpty }, prevRight = CTNode { row = TruthTableRow { var = 1010 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 9465362842462816922 , prevLeft = CTEmpty , prevRight = CTEmpty }}, prevRight = CTNode { row = TruthTableRow { var = 111 ( binary ), dontcare = False }, mergedFlag = 0 , identifier = 3889360259696288602 , prevLeft = CTNode { row = TruthTableRow { var = 1111 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 4819471800686604738 , prevLeft = CTEmpty , prevRight = CTEmpty }, prevRight = CTNode { row = TruthTableRow { var = 1110 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 8582731269452337816 , prevLeft = CTEmpty , prevRight = CTEmpty }}}, CTNode { row = TruthTableRow { var = 10 ( binary ), dontcare = False }, mergedFlag = 1 , identifier = 14507692373987760546 , prevLeft = CTNode { row = TruthTableRow { var = 100 ( binary ), dontcare = False }, mergedFlag = 1 , identifier = 17927799263722280277 , prevLeft = CTNode { row = TruthTableRow { var = 1010 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 9465362842462816922 , prevLeft = CTEmpty , prevRight = CTEmpty }, prevRight = CTNode { row = TruthTableRow { var = 1000 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 8905849755465195471 , prevLeft = CTEmpty , prevRight = CTEmpty }}, prevRight = CTNode { row = TruthTableRow { var = 110 ( binary ), dontcare = False }, mergedFlag = 1 , identifier = 3574163930668469495 , prevLeft = CTNode { row = TruthTableRow { var = 1100 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 5080631804786515567 , prevLeft = CTEmpty , prevRight = CTEmpty }, prevRight = CTNode { row = TruthTableRow { var = 1110 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 8582731269452337816 , prevLeft = CTEmpty , prevRight = CTEmpty }}}, CTNode { row = TruthTableRow { var = 11 ( binary ), dontcare = False }, mergedFlag = 0 , identifier = 1892010599057419013 , prevLeft = CTNode { row = TruthTableRow { var = 110 ( binary ), dontcare = False }, mergedFlag = 0 , identifier = 3438512683213686879 , prevLeft = CTNode { row = TruthTableRow { var = 1100 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 5080631804786515567 , prevLeft = CTEmpty , prevRight = CTEmpty }, prevRight = CTNode { row = TruthTableRow { var = 1101 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 7582384624143865392 , prevLeft = CTEmpty , prevRight = CTEmpty }}, prevRight = CTNode { row = TruthTableRow { var = 111 ( binary ), dontcare = False }, mergedFlag = 0 , identifier = 3889360259696288602 , prevLeft = CTNode { row = TruthTableRow { var = 1111 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 4819471800686604738 , prevLeft = CTEmpty , prevRight = CTEmpty }, prevRight = CTNode { row = TruthTableRow { var = 1110 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 8582731269452337816 , prevLeft = CTEmpty , prevRight = CTEmpty }}}] 実際の計算ではこれで十分なのだが, 一応人間にとってより分かりやすい traceQuineMcCluskey を用意してある. 引数には, pdnfForest で作成したノードのリストと, それに対応する変数名のリストを渡す. 両者の要素数は同一でなければならない (もしそうでない場合 Nothing が返る). ここでは, 先に扱った例題に対応した変数名を渡しているので, 得られた主項が先と同一であることが確認できる. Prelude BSimplified . QMM Data . Maybe BSimplified . Bits > : m + Control . Monad Prelude BSimplified . QMM Data . Maybe BSimplified . Bits Control . Monad > void $ traceQuineMcCluskey tr [ \"m_4\" , \"m_5\" , \"m_9\" , \"m_11\" , \"m_13\" , \"m_15\" , \"m_2\" , \"m_3\" , \"m_6\" , \"m_10\" , \"m_14\" ] The state of compression # 1 : [ \"m_4 m_5\" , \"m_5 m_9\" , \"m_5 m_6\" , \"m_9 m_13\" , \"m_9 m_10\" , \"m_11 m_15\" , \"m_11 m_10\" , \"m_13 m_14\" , \"m_15 m_3\" , \"m_15 m_14\" , \"m_2 m_3\" , \"m_2 m_6\" , \"m_2 m_14\" , \"m_6 m_10\" , \"m_10 m_14\" ] Found prime implicants : [ \"m_4 m_5\" ] The state of compression # 2 : [ \"m_5 m_9 m_6 m_10\" , \"m_9 m_13 m_10 m_14\" , \"m_11 m_15 m_10 m_14\" , \"m_15 m_3 m_2 m_14\" , \"m_2 m_6 m_10 m_14\" ] Found prime implicants : [ \"m_5 m_9 m_6 m_10\" , \"m_9 m_13 m_10 m_14\" , \"m_11 m_15 m_10 m_14\" , \"m_15 m_3 m_2 m_14\" , \"m_2 m_6 m_10 m_14\" ] 簡単化された最低限の項を得るには minTerms 等を用いる. これも, 変数名と対応した結果を得ることのできる minTermsStr を用意してある. Prelude BSimplified . QMM Data . Maybe BSimplified . Bits Control . Monad > minTerms tr [ CTNode { row = TruthTableRow { var = 1 ( binary ), dontcare = False }, mergedFlag = 2 , identifier = 577617992350188464 , prevLeft = CTNode { row = TruthTableRow { var = 1 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 18370878410602274422 , prevLeft = CTEmpty , prevRight = CTEmpty }, prevRight = CTNode { row = TruthTableRow { var = 101 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 17795521015237778886 , prevLeft = CTEmpty , prevRight = CTEmpty }}, CTNode { row = TruthTableRow { var = 11 ( binary ), dontcare = False }, mergedFlag = 2 , identifier = 10719524625750522604 , prevLeft = CTNode { row = TruthTableRow { var = 11 ( binary ), dontcare = False }, mergedFlag = 0 , identifier = 11617789877111658934 , prevLeft = CTNode { row = TruthTableRow { var = 111 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 9505003458451781531 , prevLeft = CTEmpty , prevRight = CTEmpty }, prevRight = CTNode { row = TruthTableRow { var = 110 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 2509103263232437805 , prevLeft = CTEmpty , prevRight = CTEmpty }}, prevRight = CTNode { row = TruthTableRow { var = 111 ( binary ), dontcare = False }, mergedFlag = 0 , identifier = 3889360259696288602 , prevLeft = CTNode { row = TruthTableRow { var = 1111 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 4819471800686604738 , prevLeft = CTEmpty , prevRight = CTEmpty }, prevRight = CTNode { row = TruthTableRow { var = 1110 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 8582731269452337816 , prevLeft = CTEmpty , prevRight = CTEmpty }}}, CTNode { row = TruthTableRow { var = 11 ( binary ), dontcare = False }, mergedFlag = 1 , identifier = 18197116026168548551 , prevLeft = CTNode { row = TruthTableRow { var = 101 ( binary ), dontcare = False }, mergedFlag = 0 , identifier = 14515361159708671901 , prevLeft = CTNode { row = TruthTableRow { var = 1011 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 5344459161969259783 , prevLeft = CTEmpty , prevRight = CTEmpty }, prevRight = CTNode { row = TruthTableRow { var = 1010 ( binary ), dontcare = False }, mergedFlag = - 1 , identifier = 9465362842462816922 , prevLeft = CTEmpty , prevRight = CTEmpty }}, prevRight = CTNode { row = TruthTableRow { var = 111 ( binary ), dontcare = False }, mergedFlag = 0 , identifier = 3889360259696288602 , prevLeft = CTNode { row = TruthTableRow { var = 1111 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 4819471800686604738 , prevLeft = CTEmpty , prevRight = CTEmpty }, prevRight = CTNode { row = TruthTableRow { var = 1110 ( binary ), dontcare = True }, mergedFlag = - 1 , identifier = 8582731269452337816 , prevLeft = CTEmpty , prevRight = CTEmpty }}}] Prelude BSimplified . QMM Data . Maybe BSimplified . Bits Control . Monad > minTermsStr tr [ \"m_4\" , \"m_5\" , \"m_9\" , \"m_11\" , \"m_13\" , \"m_15\" , \"m_2\" , \"m_3\" , \"m _6\" , \"m_10\" , \"m_14\" ] Just [[ \"m_4\" , \"m_5\" ],[ \"m_9\" , \"m_13\" , \"m_10\" , \"m_14\" ],[ \"m_11\" , \"m_15\" , \"m_10\" , \"m_14\" ]] また, ブール式を入力して, 最も簡単な式となる項を見つけられるようにもしてある. ブール式の表記としては, 後述の記号 (否定: ~ , 積: * , 和: + , 括弧: ( , ) ) を用いることができる. アルファベット 1 文字は変数名として捉える. ここでは, 例として式 \\(\\eqref{eq:third}\\) を入力として与える. $ stack build $ stack exec bsimplified -- \"A*~B+~A*~B+A*~B+A*B\" Minterms ( Truth patterns ) : m_0 = { A = True, B = True } m_1 = { A = True, B = False } m_3 = { A = False, B = False } The state of compression #1: [\"m_0 m_1\",\"m_1 m_3\"] Found prime implicants: [ \"m_0 m_1\" , \"m_1 m_3\" ] Simplified terms: ( m_0 m_1 ) , ( m_1 m_3 ) \\(m_{0,1},m_{1,3}\\) が結果として得られた. それぞれ, ビット列上の圧縮された部分を \\(-\\) で表記すると, \\(m_{0,1}=1-, m_{1,3}=-0\\) である. これはつまり \\(A B'\\) なので, 従って最簡形は \\(A\\lor B'\\) である. 当然ながら, 先に求めた解と同じ結果が得られたことが確認できる. 実装については普通に字句解析, 再起下降で計算, 真理値表を構成して PDNF をつくっている. ところで, この最簡形を得るという問題は充足可能性問題であり NP 困難 10 なので, 変数の多いブール関数に対する最簡形を得ることは難しい. その場合, 現実的な時間で比較的良質な解が得られるヒューリスティックを含む方法で求めることとなる. ブール代数の例 ここではブール代数の一例として, 計算機科学で一般的に用いられるブール代数を挙げる. 集合 \\(L=\\left\\{0,1\\right\\}\\) に対して \\(\\land\\) を積 \\(\\cdot:L\\times L\\to L\\), \\(\\lor\\) を和 \\(+:L\\times L\\to L\\), 補元 \\(x'\\) を否定 \\(\\overline{x}\\) とおく. 各演算子は, 次の 真理値表 1 に従う (\\(\\overline{y}\\) は \\(\\overline{x}\\) と同様なので省略). \\(x\\) \\(y\\) \\(\\overline{x}\\) \\(x\\cdot y\\) \\(x+y\\) 真理値表 1 \\(1\\) \\(1\\) \\(0\\) \\(1\\) \\(1\\) \\(1\\) \\(0\\) \\(0\\) \\(0\\) \\(1\\) \\(0\\) \\(1\\) \\(1\\) \\(0\\) \\(1\\) \\(0\\) \\(0\\) \\(1\\) \\(0\\) \\(0\\) これは紛れもなくブール代数である. この形式の下で書かれる式は一般に論理式, 演算子は論理記号といわれる. 計算機科学の分野において, ブール代数は排他的論理和: \\(\\oplus\\), 否定論理積: \\(\\mid\\), 否定論理和: \\(\\downarrow\\) といった記号らをも含めて論理記号として扱うことが多い. これらの真理値表は \\(x,y\\in L\\) に対して次の通りである. \\(x\\) \\(y\\) \\(x\\mid y\\) \\(x\\downarrow y\\) \\(x\\oplus y\\) 真理値表 2 \\(1\\) \\(1\\) \\(0\\) \\(0\\) \\(0\\) \\(1\\) \\(0\\) \\(1\\) \\(0\\) \\(1\\) \\(0\\) \\(1\\) \\(1\\) \\(0\\) \\(1\\) \\(0\\) \\(0\\) \\(1\\) \\(1\\) \\(0\\) とくに, 否定論理積 \\(\\mid\\) はそれ一つで積, 和, 否定が定義できるため, 他の論理記号よりも特別視されるような場合のある結合子である. これは, シェファーの棒記号といわれ, 真理値表をみるとわかるように \\(\\overline{\\left(x\\land y\\right)}\\), また \\(\\overline{x}\\lor \\overline{y}\\) と同値である. この否定論理積を使って, \\(\\overline{x}:=x\\mid x\\) と否定が定義できる. この否定を使って, \\(x\\land y:=\\overline{\\left(x\\mid y\\right)}\\) と積が定義できるし, \\(x\\lor y:=\\overline{x}\\mid \\overline{y}\\) と和も定義できる. どちらかをも定義せずとも, 否定に加えて積があれば和が定義できるし, 和があれば積が定義できる. 参考文献 \" What is the difference between Boolean logic and propositional logic? \" 2019 年 4 月 13 日アクセス. \" What is the difference between Boolean Algebra and propositional logic? If either they are same or one is a subset of another why should we study those separately? \" 2019 年 4 月 13 日アクセス. J. Donald Monk (1976) \"Mathematical Logic (Graduate Texts in Mathematics)\" Springer; Softcover reprint of the original 1st ed. 1976版 (1976/9/7). ISBN -13: 978-1468494549 赤間世紀, 長田康敬, 玉城史朗 (2006)『 情報数学入門 』共立出版. ISBN -13: 978-4320018143 W. V. Quine (1952) \"The Problem of Simplifying Truth Functions\" The American Mathematical Monthly Vol. 59, No. 8 (Oct., 1952), pp. 521-531 W. V. Quine (1955) \"A Way to Simplify Truth Functions\" The American Mathematical Monthly Vol. 62, No. 9 (Nov., 1955), pp. 627-631 [動画] Phalanetra. H.S \" Quine McCluskey minimisation and Petrick's method for obtaining simplified Boolean expressions \", 2019 年 4 月 30 日アクセス. Lecture #10: Petrick's Method Czort, S. (1999) \" The complexity of minimizing disjunctive normal form formulas (Master's thesis) \". University of Aarhus. イギリスの数学者ジョージ・ブール (英: George Boole) は 19 世紀半ばに人間の思考を代数計算で行うための研究を行い, ブール代数を形式化した. 命題論理はそれよりも昔にフレーゲにより構築された論理体型であるが, これは哲学的投機から派生したものである. 19 世紀後半になると, 哲学者たちは殆どブールの象徴主義を採用し, その後の 20 世紀ではこれらの学問間における明確な区別はなかったとのこと( 参考文献2 より引用: The main difference is historical. George Boole was a mathematician interested in efficient practical solutions of complicated logical questions in the middle 19th century. His main innovation was symbolic logic, a system of notation for clear specification of propositions and relations among propositions. [..] Propositional logic goes back to ancient times and derives from philosophical speculation. In the late 19th century philosophers mostly adopted Boole's symbolism. Therefore in the 20th century there's no clear distinction between the two fields, ). しかしながら, ブール代数に還元できないいくつかの命題論理が残っているとのこと( 参考文献2 より引用: although there remains some propositional logic that cannot be reduced to Boolean symbols. ). これが事実ならば, ブール代数は命題論理のサブセット的な論理であることがいえるが, 参考文献3 p.158 では, \" the correspondence between Boolean algebras and sentential logics […] We shall see that there is a full correspondence between these two kinds of mathematical objects. とあり, さらに同著書 p.160 で \" the following theorem, which is another kind of completeness theorem for Boolean algebras. […] Hence we may say that the theories of Boolean algebras and of sentential logics are equivalent, in some sense. \" とも言われていることから, 大まかに言い切ってしまえば, 殆ど差はないということであろう. ↩ ブール式は 1 つのブール関数を定めるが, ブール関数はブール式を一意には定めない. ↩ \\(\\displaystyle\\bigwedge&#94;{n}_{i=1} A_i = A_1\\land\\cdots\\land A_n, \\bigvee&#94;{n}_{i=1} A_i=A_1\\lor\\cdots\\lor A_n\\) ↩ 真理値表とは, 簡単にいえばここでは \\(x,y\\in B\\) に対してそれぞれ \\(1\\) または \\(0\\) を実際に代入したときに取りうるすべての値を書き下したものである. より厳密な取り扱いについては命題論理のエントリ( TODO )を参照. ↩ このあたりは自明とする. ↩ すなわち, ブール関数の値を記述する. \\(0\\) は記述せずに省略される場合もある. ↩ 2 進値を用いず, 変数を用いて圧縮表を作成する方法はクワイン法といわれる. ウィラード・ヴァン・オーマン・クワイン (英: Willard van Orman Quine) によって提案されたクワイン法がエドワード・J・マクラスキーによって発展されたため, このように言われている. ↩ この表記の仕方は Wikipedia の記事 を参考とした. ↩ 参考文献 9 より ↩ これについては, 命題論理のエントリ( TODO )内のトートロジー判定器のセクションにおいて取り上げている. ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2019/ 5月/29/BooleanAlgebra/","tags":"math","url":"posts/2019/ 5月/29/BooleanAlgebra/","title":"ブール代数"},{"text":"関係 (集合論) について復習. 一般的な関係 いま, 二つの要素の順序体を \\(\\left\\lt a, b\\right\\gt\\) と書くこととする. 他の異なる順序体 \\(\\left\\lt c, b\\right\\gt\\) に対し, 以下の通り定義する. \\begin{eqnarray} \\left\\lt a,b\\right\\gt=\\left\\lt c,d\\right\\gt&:=&a=c, b=d\\\\\\ {\\rm デカルト積} = {\\rm 直積} = A\\times B&:=&\\left\\{\\left\\lt a,b\\right\\gt\\mid a\\in A, b\\in B\\right\\} \\end{eqnarray} このとき順序体の要素を \\(n\\) 個に拡張したものを \\(n\\)-tuple といい, 以下の通り定義する. \\(n\\)-tuple の同値関係と直積 \\begin{eqnarray} \\left\\lt a_1,a_2,\\cdots,a_n\\right\\gt=\\left\\lt b_1,b_2,\\cdots,b_n\\right\\gt&:=&\\left(a_1=b_1,a_2=b_2,\\cdots,a_n=b_n\\right) \\label{eq:first}\\tag{1} \\\\ {\\rm デカルト積} = {\\rm直積} = A_1\\times A_2\\times\\cdots\\times A_n=\\prod_{i=1}&#94;{n}A_i&:=&\\left\\{\\left\\lt a_1,a_2,\\cdots,a_n\\right\\gt\\mid a_1\\in A_1,a_2\\in A_2,\\cdots,a_n\\in A_n\\right\\} \\label{eq:second}\\tag{2} \\end{eqnarray} なお \\(\\eqref{eq:second}\\) より \\(A&#94;n:=\\left(A_1=A_2=\\cdots =A_n\\right)\\) が自明に導ける. いま集合 \\(A\\) から \\(B\\) に対する二項関係 \\(R\\subseteq A\\times B\\) があって, \\(\\left\\lt a,b\\right\\gt\\in R\\) ならば \\(a\\) と \\(b\\) は関係 \\(R\\) にあるといい, \\(R\\left(a,b\\right)\\) または \\(aRb\\) と書く. \\[R:=\\left\\{\\left\\lt a,b\\right\\gt\\mid a\\in A,b\\in B,aRb\\right\\}\\] \\(\\left(a,b\\right)\\not\\in R\\) ならば \\(a\\) と \\(b\\) は関係 \\(R\\) にないといい, \\(\\overline{R}\\left(a,b\\right)\\) または \\(a\\overline{R}b\\) と書く. このとき \\(A=B\\) ならば二項関係 \\(R\\subseteq \\left(A&#94;2=A\\times B\\right)\\) を \\(A\\) 上の二項関係という 1 . 例えば, 自然数の集合 \\(\\mathbb{N}\\) に対し, その 同値関係 \"\\(=\\)\" を順序体を用いて新たに \\[R:=\\left\\{\\left\\lt n,n\\right\\gt\\mid n\\in \\mathbb{N}\\right\\}\\subseteq\\mathbb{N}&#94;2\\] と定義すると \\(a,b\\in \\mathbb{N}\\) に対して \\(a R_=b\\Leftrightarrow a=b\\) である. また, 集合 \\(X=\\left\\{1,2,3\\right\\}\\) に対し, その 順序関係 \\(R_\\gt\\subseteq X&#94;2\\) を大なりの関係 \"\\(\\gt\\)\" とすると \\(R_\\gt\\) は \\[R_\\gt=\\left\\{\\left\\lt 2,1\\right\\gt, \\left\\lt 3,1\\right\\gt, \\left\\lt 3,2\\right\\gt\\right\\}\\] となる. ここで, 逆関係を導入する. 関係 \\(R\\) の逆関係は \\(B\\) から \\(A\\) への関係, すなわち \\[R&#94;{-1}:=\\left\\{\\left\\lt b,a\\right\\gt\\mid a\\in A, b\\in B, aRb\\right\\}\\] と定義される. 従って, 例えば集合 \\(X\\) に対する \\(R_\\gt\\) の逆関係は \\(R_\\gt&#94;{-1}=\\left\\{\\left\\lt 1,2\\right\\gt, \\left\\lt 1,3\\right\\gt, \\left\\lt 2,3\\right\\gt\\right\\}\\) である. 二項関係は, より一般化することができる. \\(n\\) 項関係 いま複数の集合の直積の部分集合, すなわち \\(n\\) 項関係 \\(R\\subseteq\\prod_{i=1}&#94;{n}A_i\\) があって, \\(\\left\\lt a_1,a_2,\\cdots,a_n\\right\\gt\\in R\\) ならば \\(a_1,a_2,\\cdots,a_n\\) は 関係 \\(R\\) にあるといい, \\(R\\left(a_1,a_2,\\cdots,a_n\\right)\\) と書く. \\[R:=\\left\\{\\left\\lt a_1,a_2,\\cdots,a_n\\right\\gt\\mid a_1\\in A_1,a_2\\in A_2,\\cdots,a_n\\in A_n, R\\left(a_1,a_2,\\cdots,a_n\\right)\\right\\}\\subseteq\\prod_{i=1}&#94;{n}A_i\\] また \\(\\left\\lt a_1,a_2,\\cdots,a_n\\right\\gt\\not\\subseteq R\\) ならば \\(a_1,a_2,\\cdots,a_n\\) は 関係 \\(R\\) にないといい, \\(\\overline{R}\\left(a_1,a_2,\\cdots,a_n\\right)\\) と書く. ここで, 本ブログ内で特に断りなく使われる一般的な関係に関する記号の表記, その意図について表明しておく. 本ブログで使われる一般的な関係に関する記号表記 任意の二項関係 \\(\\lesssim\\) の要素 \\(\\left\\lt a,b\\right\\gt\\in\\ \\lesssim\\) に対し: \\(\\prec\\ :=\\left\\{\\left\\lt a,b \\right\\gt\\mid \\left\\lt a, b\\right\\gt\\in\\ \\lesssim, a\\not=b\\right\\}\\) \\(\\ll\\ :=\\left\\{\\left\\lt a,b\\right\\gt\\mid\\left\\lt a, c\\right\\gt\\not\\in\\ \\lesssim\\ {\\rm かつ}\\ \\left\\lt c,b\\right\\gt\\not\\in\\ \\lesssim\\right\\}\\) すなわち, \\(x\\prec y\\) は \\(x\\) は真に \\(y\\) の前にある, \\(x\\ll y\\) は \\(x\\) は \\(y\\) の直前にあることを意味する. 主な二項関係の規則 主な二項関係における規則を以下に定義する. 反射律 二項関係 \\(R\\subseteq A\\times B\\), また \\(x\\in A\\cap B\\) があって, \\(\\left\\lt x,x\\right\\gt\\in R\\) が存在するとき \\(R\\) は反射律を満たすという. 例えば, 実数の集合 \\(\\mathbb{R}\\) をとってみると, 任意の \\(&#94;\\forall x\\in\\mathbb{R}\\) に対して \\(x\\leq x\\) であるから \\(\\leq\\) は \\(\\mathbb{R}\\) の下で反射律を満たす. しかし, \\(x\\lt x\\) は成立しないので, \\(\\lt\\) は \\(\\mathbb{R}\\) の下で反射律を満たさない. 対象律 二項関係 \\(R\\subseteq A\\times B\\), また \\(x,y\\in A\\cap B\\) があって, \\(\\left\\lt x,y\\right\\gt\\in R\\) ならば \\(\\left\\lt y,x\\right\\gt \\in R\\) が存在するとき, \\(R\\) は対象律を満たすという. 例えば, 実数の集合 \\(\\mathbb{R}\\) をとってみると, 自明な例でいえば, 任意の \\(&#94;\\forall x,y\\in\\mathbb{R}\\) に対して \\(x=y\\) ならば \\(y=x\\) なので \\(=\\) は \\(\\mathbb{R}\\) の下で対象律を満たす. しかし, \\(x\\lt y\\) ならば \\(y\\lt x\\) ではないので, \\(\\lt\\) は \\(\\mathbb{R}\\) の下で対象律を満たさない. また, 別の例として, 例えば平面状のすべての三角形から成る集合 \\(A\\) と, 相似の関係 \\(R\\) を組み合わせると \\(R\\) は \\(A\\) 上で対象律を満たす. \\[R=\\left\\{\\left\\lt x,y\\right\\gt\\mid x,y\\in A,x\\ {\\rm と}\\ y\\ {\\rm は相似}\\right\\}\\subseteq A&#94;2\\] なお, これは 同値律 を満たす. 対象律の特徴を挙げると: 必ずしも \\(x=y\\) ではない 真に大きい/小さい関係はあり得ない. \\(R\\not=\\ \\prec\\) かつ \\(R\\not=\\ \\succ\\) (すべてのありとあらゆる集合上で \\(x\\prec y ならば y\\not\\prec x\\) なので) 反対象律 二項関係 \\(R\\subseteq A\\times B\\), また \\(x,y\\in A\\cap B\\) があって, \\(\\left\\lt x,y\\right\\gt\\in R\\) に対し \\(\\left\\lt y,x\\right\\gt\\in R\\) が存在するならば \\(x=y\\) のとき, \\(R\\) は反対象律を満たすという. 例えば, 集合 \\(A=\\left\\{a_1,a_2\\right\\}\\) に対して 二項関係を: \\(R=\\left\\{\\left\\lt a_1,a_1\\right\\gt,\\left\\lt a_2,a_2\\right\\gt\\right\\}\\) とおくと, \\(R\\) は \\(A\\) 上で ( 対象律 を満たし) 反対象律を満たす. なお, これは 同値律 を満たす. \\(R=\\left\\{\\left\\lt a_1,a_1\\right\\gt,\\left\\lt a_1,a_2\\right\\gt\\right\\}\\) とおくと, \\(R\\) は \\(A\\) 上で ( 対象律 を満たさないが) 反対象律を満たす. \\(R=\\left\\{\\left\\lt a_1,a_2\\right\\gt,\\left\\lt a_2,a_1\\right\\gt\\right\\}\\) とおくと, \\(R\\) は \\(A\\) 上で ( 対象律 を満たすが) 反対象律を満たさない. 反対象律の特徴を挙げると: 対象的な二項関係が存在するとき, 必ず \\(x=y\\) 推移律 二項関係 \\(R\\subseteq A\\times B\\), また \\(x,y,z\\in A\\cap B\\) があって, \\(\\left\\lt x,y\\right\\gt,\\left\\lt y,z\\right\\gt\\in R\\) ならば \\(\\left\\lt x,z\\right\\gt \\in R\\) が存在するとき, \\(R\\) は推移律を満たすという. 例えば, 実数の集合 \\(\\mathbb{R}\\) をとってみると, 任意の \\(&#94;\\forall x,y,z\\in\\mathbb{R}\\) に対して \\(x\\leq y\\) かつ \\(y\\leq z\\) ならば \\(x\\leq z\\) なので \\(\\leq\\) は \\(\\mathbb{R}\\) の下で推移律を満たす. しかし, 例えば自然数の集合 \\(\\mathbb{N}\\) に対して $$R=\\left\\{\\left\\lt a, b\\right\\gt\\mid a,b,c\\in\\mathbb{N}, a=b&#94;2\\ {\\rm かつ}\\ b=c&#94;2\\ {\\rm ならば}\\ a=c&#94;2\\ {\\rm を満たす}\\right\\}\\subseteq\\mathbb{N}&#94;2$$ としたとき, 任意の \\(x,y\\in A\\) に対し必ずしも \\(\\left\\lt x,y\\right\\gt\\in R\\) が存在するとは限らない (反例: \\(16=4&#94;2\\) かつ \\(4=2&#94;2\\) だが \\(16\\not=2&#94;2\\)) ので, \\(R\\) は \\(\\mathbb{N}\\) の下で推移律を満たさない. 主な二項関係 前順序 二項関係 \\(R\\) が集合 \\(A\\) 上で 反射律 , 推移律 を同時に満たすとき, \\(R\\) は \\(A\\) 上の前順序関係という. これは要するに, じゃんけんのような, 3 すくみ, すなわち グー \\(\\lesssim\\) パー \\(\\lesssim\\) チョキ \\(\\lesssim\\) グー \\(\\lesssim\\cdots\\) といった循環関係がないこと, グラフで表したときに有向非巡回グラフとなることを要請している. 同値 前順序関係 \\(R\\) が集合 \\(A\\) 上で 対象律 を満たすとき, \\(R\\) は \\(A\\) 上で同値律を満たすという. また: \\(\\left\\{y\\in X\\mid xRy\\right\\}\\) を \\(x\\) の同値類といい, \\(\\left[x\\right]_R\\) や \\(\\left[x\\right]\\) と書く. このときの \\(x\\) は, 同値類 \\(\\left[x\\right]\\) の代表元という 集合 \\(A\\) 上の同値関係 \\(R\\) の同値類全体から成る集合 \\(\\left\\{[a]\\mid a\\in A\\right\\}\\) を商集合といい, \\(A/R\\) と書く まず自明な例でいえば, \\(=\\) は, 空でない任意の集合上で同値関係にあるといえる. ほかに, 例えば, 整数の集合 \\(\\mathbb{Z}\\) について \\(R\\) を整数 \\(p\\in\\mathbb{Z}\\) を法とする合同関係 \\(\\equiv_p\\) とおくと, \\(R\\) は \\(\\mathbb{Z}\\) 上の同値関係となる. \\[R=\\equiv_p=\\left\\{\\left\\lt m,n\\right\\gt\\mid m,n\\in\\mathbb{Z}, m {\\rm と}\\ n\\ {\\rm は}\\ p\\ {\\rm で割ったときの余りが等しい}\\right\\}\\subseteq\\mathbb{Z}&#94;2\\] 一つ一つ確認してみると 反射律: 任意の \\(m\\in\\mathbb{Z}\\) に対して \\(m-m=0\\cdot p\\) なので \\(m\\equiv_p m\\) 推移律: 任意の \\(m,n,k\\in\\mathbb{Z}\\) に対して \\(m\\equiv_p n\\) かつ \\(n\\equiv_p k\\) と仮定すると, ある \\(d,d'\\in\\mathbb{Z}\\) に対して \\(m-n=d\\cdot p\\) かつ \\(n-k=d'\\cdot p\\) で, このとき \\(m-k=\\left(m-n\\right)+\\left(n-k\\right)=\\left(d+d'\\right)\\cdot p\\) である. \\(d+d'\\in\\mathbb{Z}\\) なので, \\(m\\equiv_p k\\) 対象律: 任意の \\(m,n\\in\\mathbb{Z}\\) に対して \\(m\\equiv_p n\\) と仮定すると, ある \\(d\\in\\mathbb{Z}\\) に対して \\(m-n=d\\cdot p\\) だから \\(n-m=(-d)\\cdot p\\) で, \\(-d\\in\\mathbb{Z}\\) だから \\(n\\equiv_p m\\) と同値律を満たすことがわかる. 同値類や商集合の例として, 集合 \\(X=\\left\\{1,3,6,10,11,15,16\\right\\}\\subseteq \\mathbb{N}\\) の要素 \\(1\\) を代表元とし, いまその同値関係を \\(5\\) を法とした合同 2 で考えると, \\(1\\) の同値類 \\(\\left[1\\right]_R=\\left\\{x\\mid 1\\equiv x\\pmod{5}\\right\\}\\) は \\(\\left[1\\right]_R=\\left\\{1,6,11,16\\right\\}\\) である 3 . また, \\begin{eqnarray} \\left[1\\right]_R&=&\\left\\{1,6,11,16\\right\\}\\\\\\ \\left[3\\right]_R&=&\\left\\{3\\right\\}\\\\\\ \\left[6\\right]_R&=&\\left\\{1,6,11,16\\right\\}\\\\\\ \\left[10\\right]_R&=&\\left\\{10,15\\right\\}\\\\\\ \\left[11\\right]_R&=&\\left\\{1,6,11,16\\right\\}\\\\\\ \\left[15\\right]_R&=&\\left\\{10,15\\right\\}\\\\\\ \\left[16\\right]_R&=&\\left\\{1,6,11,16\\right\\} \\end{eqnarray} であるので, \\(X/R=\\left\\{\\left\\{1,6,11,16\\right\\},\\left\\{10,15\\right\\},\\left\\{3\\right\\}\\right\\}\\) である. 半順序 前順序関係 \\(R\\) が集合 \\(A\\) 上で 反対象律 を満たすとき, \\(R\\) は \\(A\\) 上の半順序関係という. 例えば, 集合族上の包含関係 \\(\\subset\\) は以下の通り半順序である. \\begin{eqnarray} \\begin{array}{l} A\\subset A\\\\ A\\subset B{\\rm\\ かつ}\\ B\\subset A{\\rm\\ ならば}\\ A=B\\\\ A\\subset B{\\rm\\ かつ}\\ B\\subset C{\\rm\\ ならば}\\ A\\subset C \\end{array} \\end{eqnarray} 半順序集合が定義できれば, (最(大|小), 極(大|小))(要素|元)が定義できる. (最(大|小)|極(大|小))(要素|元) 半順序集合 \\(A\\) の要素 \\(a_0\\in A\\) について \\(&#94;\\exists a\\in A\\ {\\rm s.t.}\\ a_0\\lesssim a\\) なる \\(a\\) が存在しないとき \\(a_0\\) を \\(A\\) の最大(要素|元)といい, \\(\\max A\\) と書く. とくに \\(A\\) が複素数の部分集合 \\(A\\subseteq\\mathbb{C}\\) ならば, \\(\\max A\\) を最大値という \\(&#94;\\exists a\\in A\\ {\\rm s.t.}\\ a\\lesssim a_0\\) なる \\(a\\) が存在しないとき \\(a_0\\) を \\(A\\) の最小(要素|元)といい, \\(\\min A\\) と書く. とくに \\(A\\) が複素数の部分集合 \\(A\\subseteq\\mathbb{C}\\) ならば, \\(\\min A\\) を最小値という また \\(a\\in A\\) に対し \\(a\\gtrsim a_0\\) ならば \\(a=a_0\\) のとき \\(a_0\\) を \\(A\\) の極大(要素|元)という \\(a\\lesssim a_0\\) ならば \\(a=a_0\\) のとき \\(a_0\\) を \\(A\\) の極小(要素|元)という なお最大値, 最小値あるいは極大値, 極小値を総じて extremum という ( 参考文献 1 , 参考文献 2 ). 例えば, 自然数全体の集合 \\(\\mathbb{N}\\) の最小要素は \\(0\\) であるが, 最大要素は存在しない. 実数全体の集合 \\(\\mathbb{R}\\) には最(大|小)要素が存在しない 4 . 集合 \\(X=\\left\\{x_1,x_2,x_3\\right\\}\\) に対して順序集合 \\(\\left(\\wp\\left(X\\right)-\\left\\{\\emptyset,X\\right\\},\\leq\\right)\\) 5 の極大要素は \\(\\left\\{x_1,x_2\\right\\},\\left\\{x_1,x_3\\right\\},\\left\\{x_2,x_3\\right\\}\\), また極小要素は \\(\\left\\{x_1\\right\\},\\left\\{x_2\\right\\},\\left\\{x_3\\right\\}\\) である. 半順序集合が定義できれば, (上|下)(界|限)が定義できる. (上|下)(界|限) 半順序集合 \\(\\left(\\wp\\left(X\\right),\\leq\\right)\\) の空でない部分集合 \\(A\\not =\\emptyset\\) の任意の要素 \\(a\\in A\\) に対し, \\(&#94;\\exists x\\in X\\ {\\rm s.t.}\\ a\\lesssim x\\) なる \\(x\\) が存在するならば \\(A\\) は上に有界であるといい, \\(x\\) を \\(A\\) の上界という. \\(&#94;\\exists x\\in X\\ {\\rm s.t.}\\ x\\gtrsim a\\) なる \\(x\\) が存在するならば \\(A\\) は下に有界であるといい, \\(x\\) を \\(A\\) の下界という. \\(A\\) の上界全体の集合 \\(B=\\left\\{x\\in X | a\\lesssim x\\right\\}\\) の最小要素 \\(\\min B\\) を \\(A\\) の上限, または最小上界といい, \\(\\sup A\\) と書く. \\(A\\) の下界全体の集合 \\(B=\\left\\{x\\in X | x\\lesssim a\\right\\}\\) の最大要素 \\(\\max B\\) を \\(A\\) の下限, または最大下限といい, \\(\\inf A\\) と書く. 例えば, 集合 \\(X=\\left\\{1,\\frac{1}{2},\\frac{1}{3},\\frac{1}{4},\\cdots\\right\\}\\) について, 上界および最大値は \\(\\sup A=\\max A=1\\), 下界は \\(\\inf A=0\\), 最小値は存在しないといえる. また, 実数全体の集合 \\(R\\) の空でない部分集合が(上|下)に有界ならば, その(上|下)限が必ず存在する. これは, ワイエルストラスの定理といわれる. 有向 (directed) 集合 集合 \\(A\\not=\\emptyset\\) と 前順序関係 \\(R\\) との組 \\(\\left(A,R\\right)\\) に対し, \\(A\\) の任意の有限部分集合 \\(X\\subseteq A\\) の上界 \\(\\sup X\\in A\\) が存在するとき, \\(A\\) を有向 (directed) 集合という. 有向集合は, 反対象律 を要請されていないので, 必ずしも 半順序 集合とはならないことに注意. 例えば, 集合 \\(A=\\left\\{a_1,a_2,a_3\\right\\}\\) と関係 \\(R=\\left\\{\\left\\lt a_1,a_1\\right\\gt,\\left\\lt a_1,a_2\\right\\gt,\\left\\lt a_1,a_3\\right\\gt, \\left\\lt a_2,a_2\\right\\gt,\\left\\lt a_3,a_3\\right\\gt,\\left\\lt a_3,a_1\\right\\gt,\\left\\lt a_3,a_2\\right\\gt\\right\\}\\) の組は, 半順序でない有向集合である (\\(\\left\\lt a_1,a_3\\right\\gt,\\left\\lt a_3,a_1\\right\\gt\\in R\\) だが, \\(a_1=a_3\\) は要請していない). 図 1: 集合 \\(A=\\left\\{a_1,a_2,a_3\\right\\}\\) と関係 \\(R=\\left\\{\\left\\lt a_1,a_1\\right\\gt, \\left\\lt a_1,a_2\\right\\gt,\\left\\lt a_1,a_3\\right\\gt, \\left\\lt a_2,a_2\\right\\gt,\\left\\lt a_3,a_3\\right\\gt, \\left\\lt a_3,a_1\\right\\gt,\\left\\lt a_3,a_2\\right\\gt\\right\\}\\) の有向グラフによる図示 全順序 半順序関係 \\(R\\) が集合 \\(A\\) 上の任意の要素に対して比較可能であるとき, \\(R\\) は \\(A\\) 上の全順序関係という. 任意の全順序集合は有向集合である. その他, 例えば, 大小関係 \\(\\leq\\) は自然数の集合 \\(\\mathbb{N}\\) 上で全順序関係である. ハッセ図 主に半順序集合の図示の方法としてよく使われるハッセ図について, 以下にいくつかの例を示す. まずは, 入門書でよく見る例題に習い, 自然数全体の集合 \\(\\mathbb{N}\\) の任意の要素 \\(m,n\\in\\mathbb{N}\\) について, \\(m\\) が \\(n\\) を割り切ることを \\(m\\mid n\\) と書くとき 6 , 整除関係 \\(\\mid\\) は \\(\\mathbb{N}\\) 上の半順序であることに関して考察しよう. \\begin{eqnarray} \\begin{array}{l} x\\mid x\\\\ x\\mid y{\\rm\\ かつ}\\ y\\mid x{\\rm\\ ならば}\\ x=y\\\\ x\\mid y{\\rm\\ かつ}\\ y\\mid z{\\rm\\ ならば}\\ x\\mid z \\end{array} \\end{eqnarray} さて, このような一つの有限半順序集合上の関係は, 図 1 と同様にして, 以下のように有向グラフにより表現できる. いま, 集合 \\(X=\\left\\{n\\mid n\\in\\mathbb{N}, 1\\leq n\\leq 10\\right\\}\\) に対する整除関係による順序を \\(\\ll\\) で考えると, \\(x\\mid y\\) なら \\(y\\) は必ず \\(x\\) の後に存在する (\\(x\\lesssim y\\)) ので, 次のような有向非巡回グラフが書ける 7 . 図2: 整除の下で \\(\\ll\\) の関係における \\(X\\) の有限グラフによる図示 これをハッセ図では次のように書く. 図3: 整除の下で \\(\\ll\\) の関係における \\(X\\) のハッセ図による図示 有向グラフが \\(x\\to y\\) というように矢印で順序を表しているのに対して, ハッセ図では \\(y\\) を \\(x\\) よりも高い位置に置いて, それぞれを線で結ぶ. このときの最小値および下限は \\(1\\) であり, 上界は \\(10,8,6,9\\) だが \\(10,8,6,9\\) を比較不可能であるため, 上限は存在しない. 別の例として, \\(X=\\left\\{a, b, c, d\\right\\}\\) とおいたとき, \\(a\\lesssim c, a\\lesssim d, b\\lesssim c, b\\lesssim d\\) という半順序関係にある集合 \\(\\left(X,\\lesssim\\right)\\) を考えると, 以下のように示せる. 図4: 半順序関係 \\(a\\lesssim c, a\\lesssim d, b\\lesssim c, b\\lesssim d\\) のハッセ図による図示 このときの下界は \\(a,b\\), 上界は \\(c,d\\) である. 最小元, 最大元, 下限, 上限は \\(a,b\\) および \\(c,d\\) が比較不可能であるため存在しない. 最後にもう 1 つ, 半順序集合 \\(\\left(\\wp\\left(\\left\\{x_1,x_2,x_3\\right\\}\\right), \\subset\\right)\\) について考えてみる. 先にも示したように, 集合族上の包含関係 \\(\\subset\\) は半順序である. \\(\\emptyset\\subset\\left\\{x_1\\right\\},\\left\\{x_1\\right\\}\\subset\\left\\{x_1,x_2\\right\\},\\cdots\\) と考えていくと, ハッセ図は次のようになる. 図5: 半順序集合 \\(\\left(\\wp\\left(\\left\\{x_1,x_2,x_3\\right\\}\\right), \\subset\\right)\\) のハッセ図による図示 このときの最小元および下限は \\(\\emptyset\\) であり, 最大元および上限は \\(\\left\\{x_1,x_2,x_3\\right\\}\\) である. 半順序集合の拡張 有向半順序 (directed partial order) 集合 半順序関係 \\(R\\) と 有向集合 \\(A\\) の組 \\(\\left(A, R\\right)\\) に対し \\(A\\) を有向半順序 dpo (directed partial order) 集合という. 有向完備半順序 (directed complete partial order) 集合 半順序 集合 \\(A\\) の任意の有向部分集合 \\(X\\subseteq A\\) について, \\(X\\) の上限 \\(\\sup X\\in A\\) が存在するとき, \\(A\\) を有向完備半順序 dcpo (directed complete partial order) 集合という. いま \\(X\\subseteq A\\) を有限有向部分集合としたとき, 有限半順序集合 \\(A\\) の部分集合 \\(X\\) は, \\(A\\) の半順序関係により必ず有向部分集合となる. つまり, 有限半順序集合は有向完備半順序集合になる. 従って, 図 3 , 図 4 , 図 5 で示される集合は dcpo 集合である (上記の定義のニュアンスとして, たまに任意の部分集合が有向部分集合でなければならないと捉えられる場合があるが, そうではなく, あくまで有向部分集合として構成可能な部分集合のうちという意味合いである). 完備半順序 (complete partial order) 集合 次の 2 つの条件を満たす半順序集合 \\(A\\) を完備半順序集合 cpo (complete partial order) という. \\(A\\) は dcpo 集合 \\(A\\) は最小元をもつ 以下にいくつかの例を示す. 図 3 および 図 5 で示される集合は dcpo でありかつ最小元をもつため cpo だが, 図 4 は最小元をもたないため, cpo ではない \\(\\left(\\mathbb{N}, \\leq\\right)\\) は, 有向集合として \\(\\mathbb{N}\\subseteq\\mathbb{N}\\) が取れるが, その上限は存在しないので, cpo ではない. ここで, \\(\\infty = \\max \\mathbb{N}\\) となるように拡張した \\(\\left(\\mathbb{N}\\cup\\left\\{\\infty\\right\\},\\leq\\right)\\) で考えると, cpo になる. なお, cpo は上限をもつ \\(\\omega\\) 鎖と定義することもできる. 束 二項演算子 \\(\\land,\\lor\\) 9 のもとで閉じている空でない集合 \\(L\\) の任意の要素 \\(x,y,z\\in L\\) に対して, 次の三つの束の公理 可換律:\\(x\\land y=y\\land x, x\\lor y=y\\lor x\\) 結合律:\\(\\left(x\\land y\\right)\\land z=x\\land\\left(y\\land z\\right), \\left(x\\lor y\\right)\\lor z=x\\lor\\left(y\\lor z\\right)\\) 吸収律:\\(x\\land\\left(x\\lor y\\right)=x,x\\lor\\left(x\\land y\\right)=x\\) を満たすとき, 集合 \\(L\\) は束であるといい, \\(\\left(L,\\land,\\lor\\right)\\) と表す. ここで \\(\\lor,\\land\\) はそれぞれ, 結び, 交わりと言われる. いま半順序集合 \\(S\\) の任意の要素 \\(a,b\\) について, 上限を \\[\\sup\\left\\{a,b\\right\\}:=\\left\\{x\\mid &#94;\\forall m\\in M\\left(x\\lesssim m\\right),x\\in M\\right\\}, M=\\left\\{m\\mid a,b\\lesssim m,m\\in S\\right\\}\\] 下限を \\[\\inf\\left\\{a,b\\right\\}:=\\left\\{x\\mid &#94;\\forall m\\in M\\left(x\\gtrsim m\\right),x\\in M\\right\\}, M=\\left\\{m\\mid a,b\\gtrsim m,m\\in S\\right\\}\\] と書くこととすると, \\(\\sup\\left\\{a,b\\right\\},\\inf\\left\\{a,b\\right\\}\\) はそれぞれ \\(a\\lor b,a\\land b\\) と同値である. すなわち, 束とは, \\(x, y\\) について上限と下限が存在する半順序集合のことである 10 . また, 束 \\(L\\) の任意の部分集合が上限と下限をもつとき, 束 \\(L\\) をとくに完備束 束の部分集合が束であるとき, その束をとくに部分束 束 \\(L\\) の任意の要素 \\(&#94;\\forall x,y\\in L\\) について \\(f\\left(x\\land y\\right)=f\\left(x\\right)\\land f\\left(y\\right), f\\left(x\\lor y\\right)=f\\left(x\\right)\\lor f\\left(y\\right)\\) を満足する単射 \\(f: L_1\\to L_2\\) が存在するとき束 \\(L_1,L_2\\) は同型 束の任意の要素 \\(x,y,z\\) について \\(x\\lor\\left(y\\land z\\right)=\\left(x\\lor y\\right)\\land\\left(x\\lor z\\right), x\\land\\left(y\\lor z\\right)=\\left(x\\land y\\right)\\lor\\left(x\\land z\\right)\\) を満たす束をとくに分配束 という. 例えば, 先の例 でも挙げた \\(\\left(\\wp\\left(\\left\\{x_1,x_2,x_3\\right\\}\\right), \\subset\\right)\\) は束である. 任意の要素として \\(\\left\\{x_1\\right\\},\\left\\{x_2\\right\\}\\) をとってみると, その上限 \\(\\sup\\left\\{\\left\\{x_1\\right\\},\\left\\{x_2\\right\\}\\right\\}\\) は \\(\\left\\{x_1\\right\\}\\subset\\left\\{x_1,x_2\\right\\},\\left\\{x_2\\right\\}\\subset\\left\\{x_1,x_2\\right\\}\\) なので, \\(\\sup\\left\\{\\left\\{x_1\\right\\},\\left\\{x_2\\right\\}\\right\\}=\\left\\{x_1,x_2\\right\\}\\) である. 図6: 半順序集合 \\(\\left(\\wp\\left(\\left\\{x_1,x_2,x_3\\right\\}\\right), \\subset\\right)\\) のハッセ図による図示, \\(\\sup\\left\\{\\left\\{x_1\\right\\},\\left\\{x_2\\right\\}\\right\\}\\) を強調 ハッセ図で考えると, 上方向に辺を辿っていったとき, 各ノードそれぞれが順序比較可能でありかつ最小であるものが上限となる. 同様に, 例えば \\begin{eqnarray} \\sup\\left\\{\\left\\{x_1,x_2\\right\\},\\left\\{x_2,x_3\\right\\}\\right\\}&=&\\left\\{x_1,x_2,x_3\\right\\}\\\\ \\sup\\left\\{\\left\\{x_1\\right\\},\\left\\{x_2,x_3\\right\\}\\right\\}&=&\\left\\{x_1,x_2,x_3\\right\\}\\\\ \\sup\\left\\{\\emptyset,\\left\\{x_1,x_2\\right\\}\\right\\}&=&\\left\\{x_1,x_2\\right\\}\\\\ \\sup\\left\\{\\emptyset,\\emptyset\\right\\}&=&\\emptyset\\label{eq:nineth}\\tag{9} \\end{eqnarray} となる. 最後の \\(\\eqref{eq:nineth}\\) はすべての束の任意の要素について言えることである. すなわち任意の束 \\(L\\) の任意の要素 \\(x\\in L\\) に対して \\(\\sup\\left\\{x,x\\right\\}=x\\) である. これは, 束の公理から導ける, 一般にべき等律といわれる定理である. 証明 : \\(x,y\\in L,z=\\left(x\\lor y\\right)\\) に対して \\begin{eqnarray} \\sup\\left\\{x,x\\right\\}\\leftrightarrow x\\lor x&=&x\\lor\\left(x\\land\\left(x\\lor y\\right)\\right) & \\left(\\because {\\rm \\href{#lattice3}{公理3}: 吸収律}\\right)\\\\ &=&x\\lor \\left(x\\land z\\right)&\\left(\\because {\\rm \\href{#lattice3}{公理3}: 吸収律}\\right)\\\\ &=&x&\\left(\\because {\\rm \\href{#lattice3}{公理3}: 吸収律}\\right) \\end{eqnarray} \\(\\square\\) ここで一度, 上の定理に加えて考察できるいくつかの事項を羅列する. 下限は, 上限の逆順序で定義されるものである. 例えば, \\(\\inf\\left\\{\\left\\{x_1\\right\\},\\left\\{x_2\\right\\}\\right\\}=\\emptyset\\) である 完備束 \\(\\left(L,\\land,\\lor\\right)\\) の任意の部分集合 \\(S\\subseteq L\\) に対して \\(S=\\emptyset\\) ならば \\(\\sup S=\\min L\\) , \\(S=L\\) ならば \\(\\sup S=\\max D\\) である いま, 分配束 \\(L\\) の最大元, 最小元をそれぞれ \\(1,0\\) と書くこととする. 束 \\(L\\) の任意の要素 \\(x,y\\in L\\) について \\(x\\lor y=1,x\\land y=0\\) を満足するとき, \\(x\\) は \\(y\\) の補元といい, \\(x'\\) または \\(\\bar{x}\\) と書く. 元 \\(1,0\\) はそれぞれ単位元, 零元である. このときの \\(L\\) の補元は, 唯一に定まる. 証明 : \\(x,y\\in L\\) が \\(a\\in L\\) の二つの補元だと仮定する. \\begin{eqnarray} x&=&x\\lor 0\\\\ &=&x\\lor\\left(a\\land y\\right)\\\\ &=&\\left(x\\lor a\\right)\\land\\left(x\\lor y\\right)\\\\ &=&1\\land\\left(x\\lor y\\right)\\\\ &=&x\\land y \\end{eqnarray} 同様に \\(y=x\\lor y\\) となるから \\(x=y\\). \\(\\square\\) 束 \\(L\\) のすべての元が補元をもつとき, \\(L\\) は可補束, または相補束という. 可補分配束は一般に ブール代数 である 10 . 参考文献 Extremum - Wolfram MathWorld 2019/3/15 アクセス. Maximum and minimum of a function - Encyclopedia of Mathematics 2019/3/15 アクセス. 赤間世紀, 長田康敬, 玉城史朗 (2006)『 情報数学入門 』共立出版. ISBN -13: 978-4320018143 \" Directed complete partial orders\", http://math.chapman.edu/~jipsen/structures/doku.php/directed_complete_partial_orders 2020/7/9 アクセス. 例えば \\(xy\\) 座標平面を \\(\\mathbb{R}&#94;2\\) と書くのは, それが実数二つのペアの集合と考えられるからである. ↩ 任意の整数 \\(a,b,c,n\\in \\mathbb{N}\\) に対して \\begin{eqnarray}a\\equiv b \\pmod n\\\\\\ a\\equiv b\\pmod n&\\rightarrow& b\\equiv a\\pmod n\\\\\\ a\\equiv b, b\\equiv c\\pmod n &\\rightarrow& a\\equiv c\\pmod n\\end{eqnarray} であることを容易に確かめられる. 従って, 合同は同値関係である. ↩ これをとくに剰余類という. FYI : エルガマル暗号, ガロア体のセクションを参照 . ↩ 関連: \\(\\epsilon-\\delta\\) 論法 ↩ ここで, \\(\\wp\\left(A\\right)\\) は \\(\\wp\\left(A\\right):=\\left\\{Y\\mid Y\\subseteq A\\right\\}\\) であり, \\(A\\) の冪集合という. すなわち \\(A=\\left\\{a,b\\right\\}\\) とすると \\(\\wp\\left(A\\right)=\\left\\{\\emptyset,\\left\\{a\\right\\},\\left\\{b\\right\\},\\left\\{a,b\\right\\}\\right\\}\\) となる. いまその要素の個数を \\(\\left|\\wp\\left(A\\right)\\right|\\) と書くとすると, \\(\\left|\\wp\\left(A\\right)\\right|\\) は集合 \\(A\\) の全要素の全組み合わせであるので \\(\\left|\\wp\\left(A\\right)\\right|={}_3C_0+{}_3C_1+{}_3C_2=7\\) となる. 従って, ここで取り上げた例題について丁寧に書き出してみると, \\[\\wp\\left(X\\right)-\\left\\{\\emptyset,X\\right\\}=\\left\\{X,\\left\\{x_1,x_2\\right\\},\\left\\{x_1,x_3\\right\\},\\left\\{x_2,x_3\\right\\},\\left\\{x_1\\right\\},\\left\\{x_2\\right\\},\\left\\{x_3\\right\\},\\emptyset\\right\\}-\\left\\{\\emptyset,X\\right\\}\\] ということ. ↩ \\(\\mid\\) は整数論の界隈で普遍的な記述である. 「割り切れない」も同様にして \\(\\not\\mid\\) と書いたりする. FYI : エルガマル暗号 ↩ \\(1\\) と自分自身以外の数で割り切れるかを考える. \\(1\\) は始点なので, \\(1\\) のノードへ向けられる辺はないだろう. \\(2\\) について考えてみると, \\(1\\mid 2,3\\) なら \\(1\\mid 3\\) であるが, \\(4\\) は \\(1\\mid 2\\mid 4\\) である. これを全要素について適用していくと図のようになる. ↩ 論理記号とは無関係であることに注意. ↩ 半順序集合 \\(S\\) の任意の要素 \\(x, y\\) に対して \\(\\sup\\left\\{x,y\\right\\},\\inf\\left\\{x,y\\right\\}\\) が存在すれば, \\(x, y\\) と順序関係のある \\(z\\in S\\) に対して \\begin{eqnarray}\\sup\\left\\{x,y\\right\\}&=&\\sup\\left\\{y,x\\right\\}\\\\ \\sup\\left\\{\\sup\\left\\{x,y\\right\\},z\\right\\}&=&\\sup\\left\\{x,\\sup\\left\\{y,z\\right\\}\\right\\}\\\\ \\sup\\left\\{x,\\inf\\left\\{x,y\\right\\}\\right\\}&=&x\\end{eqnarray} より束の公理を満たす. 双対の原理より双対についても成り立つ. ↩ 可補束ついて次の性質が成り立つ. \\begin{eqnarray}x''&=&x\\\\ 0'&=&1\\\\ 1'&=&0\\\\ x\\lor 0&=&x\\\\ x\\land 0&=&0\\\\ x\\lor 1&=&1\\\\ x\\land 1&=&x\\\\ \\left(x\\land y\\right)'&=&x'\\lor y'\\\\ \\left(x\\lor y\\right)'&=&x'\\land y'\\\\ x\\leq y&\\leftrightarrow& y'\\leq x'\\end{eqnarray} 面倒なので証明略. ブール代数 のエントリにて分配律を用いずに証明しているものがあるので, それで代用できるかと. ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2019/ 3月/15/Relation/","tags":"math","url":"posts/2019/ 3月/15/Relation/","title":"関係 (集合論)"},{"text":"放物運動に関する復習と再現. 等加速度運動をする物体の位置関数の導出 時刻 \\(t=0\\) における物体の位置を \\(\\boldsymbol{x_0}\\) , 速度を \\(\\boldsymbol{v_0}\\) とし, 加速度を考慮しない等速運動の三次元空間上の一点に対する位置関数 \\(\\boldsymbol{x}(t)\\) を \\[\\boldsymbol{x}(t)=\\boldsymbol{x_0}+\\boldsymbol{v_0}t\\] とおく. このとき, 時間 \\(t_1\\) から \\(t_2\\) への変化量 \\(\\boldsymbol{x}(t_2)-\\boldsymbol{x}(t_1)\\) を \\(\\Delta t=t_2-t_1\\) で割れば, 時間経過に対する物体の位置の対比が得られる. これは正しく速度のことであるが, これは時間 \\(t_1\\) に位置 \\(\\boldsymbol{x}(t_1)\\), 時間 \\(t_2\\) に位置 \\(\\boldsymbol{x}(t_2)\\) にあった物体の平均速度である. いま時間 \\(t\\) における物体の瞬間速度を知りたいとすると, \\(\\Delta t\\) が微小量となるように極限(\\(t_2\\to t_1\\Leftrightarrow \\Delta t\\to 0\\))を取れば良い. 従って, 物体の瞬間速度の関数 \\(\\boldsymbol{v}(t)\\) を \\(\\boldsymbol{x}(t)\\) の導関数 \\[\\boldsymbol{v}(t)=\\dot{\\boldsymbol{x}}(t)=\\frac{d\\boldsymbol{x}(t)}{dt}\\] でおけることがわかる. しばしば力学においては, 上のように原始関数の上部に点を記述し, 時間の微分を表現する. なお, いまは速度を一定としているので \\(\\boldsymbol{v}(t)=\\boldsymbol{v_0}\\) である. ここで, 物体の運動が加速することを加味するために, 加速度を導入する. 加速度とは, 平均の速度とその所用時間の対比のことであり, すなわち \\(\\frac{\\boldsymbol{v}(t_2)-\\boldsymbol{v}(t_1)}{\\Delta t}\\) である. 先と同様, \\(\\Delta t\\to 0\\) としていけば, その瞬間の加速度を得ることができるから, 瞬間加速度の関数 \\(\\boldsymbol{a}(t)\\) は \\[\\boldsymbol{a}(t)=\\dot{\\boldsymbol{v}}(t)=\\ddot{\\boldsymbol{x}}(t)=\\frac{d&#94;2\\boldsymbol{x}(t)}{dt&#94;2}\\] であり, 結果として 2 次導関数でおかれる. 従って, 一定の加速度 \\(\\boldsymbol{a}(t)=\\boldsymbol{a_0}\\) を受けている物体の瞬間速度関数は \\(\\boldsymbol{w}(t)=\\boldsymbol{v_0}+\\boldsymbol{a_0}t\\) となるから, 時刻 \\(t_1\\) から \\(t_2\\) 間の移動距離は \\(d=\\int&#94;{t_2}_{t_1}\\boldsymbol{w}(t)dt\\) であり, 経過時刻 \\(t\\) に対する物体の移動距離は同様にして \\[d=\\int&#94;t_0\\boldsymbol{w}(t)dt=\\boldsymbol{v_0}t+\\frac{\\boldsymbol{a_0}t&#94;2}{2}\\] となる. よって初期位置 \\(x_0\\) を加えることで等加速度運動をする物体の位置関数 \\(\\boldsymbol{y}(t)\\) が \\[\\boldsymbol{y}(t)=\\boldsymbol{x_0}+\\boldsymbol{v_0}t+\\frac{\\boldsymbol{a_0}t&#94;2}{2}\\label{eq:first}\\tag{1}\\] と定められる. 重力を踏まえた運動 重力のみの影響を受ける物体の運動について考える. 三次元空間上の上方向を \\(z\\) 軸としたとき, 下向きの重力加速度ベクトルは \\(\\boldsymbol{g}=\\left(0,0,-g\\right)&#94;T\\) である. これは, 地球上において \\(g=9.80665{\\rm m/s}&#94;2\\) と知られているから, 地球上の質量 \\(m\\) の物体は下向きに \\(m\\boldsymbol{g}\\) の力を受けていることとなる. いま時刻 \\(t=0\\) における初期位置を \\(\\boldsymbol{x_0}=\\left(x_0,y_0,z_0\\right)&#94;T\\), 初速度を \\(\\boldsymbol{v_0}=\\left(v_x,v_y,v_z\\right)&#94;T\\) としたとき, 物体 \\(P\\) の位置は \\(\\eqref{eq:first}\\) より \\[\\boldsymbol{x}(t)=\\boldsymbol{x_0}+\\boldsymbol{v_0}t+\\frac{\\boldsymbol{g}t&#94;2}{2}\\label{eq:second}\\tag{2}\\] である. また, 初速度 \\(\\boldsymbol{v_0}\\) の各成分は, \\(x\\) 方向に発射速度 \\(v\\) で発射されるとしたとき, 三角関数を思い出せば, \\(\\boldsymbol{v_0}=\\left(v\\cos\\theta,0,v\\sin\\theta\\right)&#94;T\\) であることがいえる. 到達高度に達するとき, 到達高度 いま物体 \\(P\\) が到達高度に達するときと, その高度について考える. 到達高度に達するときとは, 垂直方向の速度が \\(0\\) であるときなので, 物体 \\(P\\) の時刻 \\(t\\) における \\(z\\) 成分を \\(\\eqref{eq:second}\\) より \\[z(t)=z_0+v_zt-\\frac{gt&#94;2}{2}\\label{eq:third}\\tag{3}\\] とおくと, 次のように微分方程式で表現できる. \\[\\dot{z}(t)=v_z-gt=0\\Leftrightarrow t=\\frac{v_z}{g}\\label{eq:fourth}\\tag{4}\\] 後はこの \\(t\\) を \\(z(t)\\) に代入すれば \\begin{eqnarray} h&=&z_0+v_z\\frac{v_z}{g}-\\frac{g}{2}\\left(\\frac{v_z}{g}\\right)&#94;2\\\\\\ &=&z_0+\\frac{v_z&#94;2}{g}-\\frac{v_z&#94;2}{2g}\\\\\\ &=&z_0+\\frac{v_z&#94;2}{2g} \\end{eqnarray} と到達高度 \\(h\\) が求まる. また, 到達高度を \\(h\\) にするための発射角度 \\(\\theta\\) は上式より \\(h=\\frac{\\left(v\\sin\\theta\\right)&#94;2}{2g}\\) だから \\[\\sin&#94;2\\theta=\\frac{2gh}{v&#94;2}\\Leftrightarrow\\sin\\theta=\\frac{\\sqrt{2gh}}{v}\\Leftrightarrow\\theta=\\sin&#94;{-1}\\frac{\\sqrt{2gh}}{v}\\] と求まる. 到達距離 水平面 \\(z_0=0\\) から物体 \\(P\\) が発射されたときを考える. 発射されてから地面につく時刻 \\(t\\) は \\(\\eqref{eq:third}\\) より \\[v_zt-\\frac{gt&#94;2}{2}=t\\left(v_z-\\frac{gt}{2}\\right)=0\\Leftrightarrow t=0, \\frac{2v_z}{g}\\] であり, 発射した時刻と地面につく時刻の解が得られた. いま関心があるのは \\(\\frac{2v_z}{g}\\) であるが, これは \\(\\eqref{eq:fourth}\\) の \\(2\\) 倍, すなわち到達高度に達する時間の \\(2\\) 倍の時間をかければ地面につくという, 左右対称の扇型の放物線運動を思い浮かべれば, 当然と思える結果が導けた. 従って, 物体 \\(P\\) が原点から \\(x\\) 軸方向に発射されたとすると, 到達距離 \\(l\\) は \\(x\\) 方向の移動距離に等しいから \\[l=v_x\\frac{2v_z}{g}\\] となる. また, 到達距離を \\(l\\) にするための発射角度 \\(\\theta\\) は上式より \\begin{eqnarray} l&=&\\frac{2\\left(v\\cos\\theta\\right)\\left(v\\sin\\theta\\right)}{g}\\\\\\ &=& \\frac{2v&#94;2}{g}\\sin\\theta\\cos\\theta\\\\\\ &=& \\frac{v&#94;2\\sin2\\theta}{g}\\ \\left(\\because\\ 2{\\rm 倍角の公式:}\\ 2\\sin\\theta\\cos\\theta=\\sin2\\theta\\right) \\end{eqnarray} だから \\[\\theta=\\frac{1}{2}\\sin&#94;{-1}\\frac{lg}{v&#94;2}\\] ただし, \\(\\sin\\left(\\pi-\\theta\\right)=\\sin\\theta\\) より \\(\\sin2\\theta=\\sin\\left(\\pi-2\\theta\\right)=\\sin2\\left(\\frac{\\pi}{2}-\\theta\\right)\\) とすると, \\(\\frac{\\pi}{2}-\\theta\\) でも同一の到達距離 \\(l\\) となることがわかる. すなわち, 2 つの到達の解があることとなる. 放物運動のシミュレート ここまで示した内容で, 重力のみが考慮された簡単な物体の放物運動について シミュレートできる(クリックで展開). var Module = { canvas: (function() { return document.getElementById('canvas'); })() }; Module['locateFile'] = function(path, prefix) { return \"/roki.log/images/2019/Mar/7/\" + path; } C++ と SDL2 で書いたものを emscripten で Web Assembly にしているので, 恐らく古いブラウザでは動かないだろう. 操作感でわかると思うが, 初速の指定はボールとのユークリッド距離を元に決めている. このときのボールの回転角度は, arctan の定義そのものである. 一応全体のソースコードは, 次のリポジトリにて公開している. falgon/sdl2_wasm_parabolic - For blog posts if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2019/ 3月/07/ParabMotion/","tags":"math","url":"posts/2019/ 3月/07/ParabMotion/","title":"放物運動"},{"text":"要旨 本エントリー( WIP )はカーブフィッティング全般に関して記述したものであり, それぞれの原理, 性質について学んだ際のメモとして, より単純なものから広く浅く挙げています. 極力ないようにはしていますが, 本内容は独学で得た知見より書いておりますので, 一部正確さが欠けている可能性があることは否めません. 何かありましたら, コメント等で指摘していただけるとありがたいです. また, 本エントリ内における近似およびプロット等に関する実装は次のリポジトリ falgon/PlayLinearAlgebra - My playground about linear albebra: LU decomposition, pseudo inverse, least squared method, etc… にまとまっています. 線形回帰 まずは, 回帰解析のうち最も基本的な手法である最小二乗法について. 次のような散布図 1 を考える. このデータセットは, マイルラン という中距離マラソンにおける男子世界記録の遷移を表しており, 横軸が世界記録を更新した年, 縦軸がその記録の秒数となっている. この散布図は負の相関関係があるといえる. まあ, 記録の更新というのは, ゴールするまでのタイムが縮んだということをいうので, これは当たり前の相関関係である. このような直線的な関係があるようにみえるような散布について, それなりにそれらの点に相応しいような直線, つまり各点からの距離が最も小さくなるような直線を引きたいとしよう. これが本エントリにおける主題である. 線形最小二乗法 最小二乗法は, 上記のようなデータの組 \\(\\left(x_i,y_i\\right)\\) が \\(n\\) 組与えられたとき(\\(x_i\\) の全てが等しい場合を除いて)に, それらの点に相応しい関数 \\[y_i=a_i+a_ix&#94;1_1+\\cdots+a_ix&#94;n_i\\label{eq:ffirst}\\tag{i}\\] の係数(傾きと切片)を決定する方法である(定義式は \\(\\eqref{eq:eleventh}\\)). なお, このときの線形性とは, 係数 \\(a_k\\) の線形性を意味しており, すなわち応答変数 \\(y\\) は係数 \\(a_k\\) の線形関数を表している. まずは最もシンプルな例として, 回帰モデルを \\(y=ax+b\\) として考えると, これに対する線形最小二乗法は, 簡単に導出できる: ある点 \\(\\left(x_i, y_i\\right)\\) とモデルとなる直線の誤差, すなわち偏差は \\(y_i-\\left(ax_i+b\\right)\\) とかける. このとき, 各点からの距離が最小であってほしいのだから, まず総和を \\[\\epsilon(a,b):=\\displaystyle\\sum&#94;{n}_{i=1}\\left(y_i-ax_i-b\\right)&#94;2\\label{eq:first}\\tag{1}\\] とおくこととする. いまここで二乗したのは, モデルとなる直線よりも下に点があった場合, 符号が負となり, これが誤差を相殺してしまったり, 値を負にしてしまうからである. 絶対値を用いないのは, 後の微分計算を可能にするためである. さて, いま \\(\\eqref{eq:first}\\) の最小値を求めたいわけだが, 簡単のためにここでまず \\(b\\) を固定したと考える. すると, \\(\\eqref{eq:first}\\) は単なる \\(a\\) の二次関数と捉えることができる. その係数 \\(\\displaystyle\\sum&#94;{n}_{i=1}x_i&#94;2\\) は正であるので, この二次関数は, 下に凸の放物線を描くことがわかる. よってこの二次関数の最小値は, 接線の傾きを \\(0\\) とした値をとることがいえるので, それを \\[\\frac{\\partial\\epsilon(a,b)}{\\partial a}=0\\] とかける. 同様に, \\(a\\) を固定したと考えれば, 係数は \\(n\\) でこれは正であるから, これも下に凸の放物線を描くことがわかる. つまりこの場合の最小値も, \\[\\frac{\\partial\\epsilon(a,b)}{\\partial b}=0\\] とかける. いま求めたかったのはこのどちらをも満たす \\(a,b\\) であるので, これらの連立方程式を解けば良いこととなる. 従って \\(\\eqref{eq:first}\\) より \\begin{eqnarray} &&\\begin{cases} &\\displaystyle\\frac{\\partial\\epsilon(a,b)}{\\partial a}&=&\\displaystyle\\sum_{i=1}&#94;{n}2\\left(y_i-(ax_i+b)\\right)\\cdot(-x_i)&=&0 \\\\\\ &\\displaystyle\\frac{\\partial\\epsilon(a,b)}{\\partial b}&=&\\displaystyle\\sum_{i=1}&#94;{n}2\\left(y_i-(ax_i+b)\\right)&=&0 \\end{cases} \\end{eqnarray} このような, 線形方程式におけるすべての定数項が \\(0\\) であるものを同次線形系(英:homogeneous linear system)という. この両辺を \\(2\\) で割って, \\begin{eqnarray} &\\leftrightarrow &\\begin{cases} &\\displaystyle\\sum_{i=1}&#94;{n}\\left(y_i-(ax_i+b)\\right)\\cdot x_i&=&0 \\\\\\ &\\displaystyle\\sum_{i=1}&#94;{n}\\left(y_i-(ax_i+b)\\right)&=&0 \\end{cases} \\\\\\ &\\leftrightarrow &\\begin{cases} &\\displaystyle a\\sum_{i=1}&#94;{n}x&#94;2_i&+&\\displaystyle b\\sum_{i=1}&#94;{n}x_i&=&\\displaystyle\\sum_{i=1}&#94;{n}x_i y_i \\\\\\ &\\displaystyle a\\sum_{i=1}&#94;{n}x_i&+&bn&=&\\displaystyle\\sum_{i=1}&#94;{n}y_i \\end{cases} \\label{eq:second}\\tag{2} \\end{eqnarray} 両辺を \\(n\\) で割って, \\begin{eqnarray} &\\leftrightarrow &\\begin{cases} &\\displaystyle a\\frac{\\sum_{i=1}&#94;{n}x&#94;2_i}{n}&+&\\displaystyle b\\frac{\\sum_{i=1}&#94;{n}x_i}{n}&=&\\displaystyle\\frac{\\sum_{i=1}&#94;{n}x_i y_i}{n} \\\\\\ &\\displaystyle a\\frac{\\sum_{i=1}&#94;n x_i}{n}&+&b&=&\\frac{\\sum_{i=1}&#94;ny_i}{n} \\end{cases} \\end{eqnarray} ここで, \\(\\frac{\\sum_{i=1}&#94;n x_i}{n}\\) は \\(x\\) の総和をその個数で割っているので \\(x\\) の平均, \\(\\frac{\\sum_{i=1}&#94;ny_i}{n}\\) は \\(y\\) の総和をその個数で割っているので \\(y\\) の平均であるから, \\(\\overline{x}=\\frac{\\sum_{i=1}&#94;{n}x_i}{n}, \\overline{y}=\\frac{\\sum_{i=1}&#94;ny_i}{n}, \\overline{x&#94;2}=\\frac{\\sum_{i=1}&#94;{n}x_i&#94;2}{n}, \\overline{xy}=\\frac{\\sum_{i=1}&#94;{n}x_i y_i}{n}\\) と平均の記号を用いて書くことができる. よって, \\(b=-a\\overline{x}+\\overline{y}\\) を代入すれば \\(a\\) も求まるわけだが, 一旦これを行列で表現すると, \\begin{eqnarray} \\left(\\begin{array}{cc} \\overline{x&#94;2} & \\overline{x} \\\\\\ \\overline{x} & 1 \\end{array}\\right) \\left(\\begin{array}{c} a \\\\\\ b \\end{array}\\right) &=& \\left(\\begin{array}{c} \\overline{xy} \\\\\\ \\overline{y} \\end{array}\\right) \\end{eqnarray} 左辺の行列の行列式 \\begin{eqnarray} {\\rm det}\\left(\\begin{array}{cc} \\overline{x&#94;2} & \\overline{x} \\\\\\ \\overline{x} & 1 \\end{array}\\right) \\end{eqnarray} は, \\(x_i\\) がすべて等しくない限り \\(0\\) とはならない. いまはそのような場合を除いているから, 同行列は正則で \\begin{eqnarray} \\left(\\begin{array}{c} a \\\\\\ b \\end{array}\\right) &=&\\left(\\begin{array}{cc} \\overline{x&#94;2} & \\overline{x} \\\\\\ \\overline{x} & 1 \\end{array}\\right)&#94;{-1} \\left(\\begin{array}{c} \\overline{xy} \\\\\\ \\overline{y} \\end{array}\\right) \\end{eqnarray} より \\(\\left(a\\ b\\right)&#94;T\\) は \\begin{eqnarray} &=&\\left(\\begin{array}{c} \\frac{\\overline{xy}-\\overline{x}\\cdot\\overline{y}}{\\overline{x&#94;2}-\\overline{x}&#94;2} \\\\\\ \\frac{\\overline{x&#94;2}\\cdot\\overline{y}-\\overline{xy}\\cdot\\overline{x}}{\\overline{x&#94;2}-\\overline{x}&#94;2} \\end{array}\\right)\\label{eq:third}\\tag{3} \\end{eqnarray} と求まる. ここで, \\(\\overline{xy}-\\overline{x}\\cdot\\overline{y}\\) は共分散, \\(\\overline{x&#94;2}-\\overline{x}&#94;2\\) は分散の形になっているので, \\(a\\) は \\(\\frac{\\mathrm{Cov}(x,y)}{\\sigma_x&#94;2}\\) とまとめることができ, よくみる最小二乗法の定義式の形となった. 実際にプログラムにすることを考えるときは, 平均などはどうでもよくて, 単に \\(\\eqref{eq:third}\\) の各項に \\(n\\) を乗じた形で計算すればよい. つまり, \\begin{eqnarray} \\eqref{eq:second}&\\leftrightarrow& \\left(\\begin{array}{cc} \\displaystyle \\sum_{i=1}&#94;{n}x&#94;2_i &\\displaystyle \\sum_{i=1}&#94;{n}x_i \\\\\\ \\displaystyle \\sum_{i=1}&#94;{n}x_i &n \\end{array}\\right) \\left(\\begin{array}{c} a \\\\\\ b \\end{array}\\right)&=& \\left(\\begin{array}{c} \\displaystyle\\sum_{i=1}&#94;{n}x_i y_i \\\\\\ \\displaystyle\\sum_{i=1}&#94;{n}y_i \\end{array}\\right) \\\\\\ &\\leftrightarrow& \\left(\\begin{array}{c} a \\\\\\ b \\end{array}\\right)&=& \\left(\\begin{array}{cc} \\displaystyle \\sum_{i=1}&#94;{n}x&#94;2_i &\\displaystyle \\sum_{i=1}&#94;{n}x_i \\\\\\ \\displaystyle \\sum_{i=1}&#94;{n}x_i &n \\end{array}\\right)&#94;{-1} \\left(\\begin{array}{c} \\displaystyle\\sum_{i=1}&#94;{n}x_i y_i \\\\\\ \\displaystyle\\sum_{i=1}&#94;{n}y_i \\end{array}\\right) \\\\\\ &&&=&\\left(\\begin{array}{c} \\frac{\\left(\\sum&#94;n_{i=1}x_iy_i\\right) n-\\left(\\sum&#94;n_{i=1}x_i\\right)\\left(\\sum&#94;n_{i=1}y_i\\right)}{\\left(\\sum&#94;n_{i=1}x&#94;2_i\\right) n-\\left(\\sum&#94;n_{i=1}x_i\\right)&#94;2} \\\\\\ \\frac{\\left(\\sum&#94;n_{i=1}x&#94;2_i\\right)\\left(\\sum&#94;n_{i=1}y_i\\right)-\\left(\\sum&#94;n_{i=1}x_iy_i\\right)\\left(\\sum&#94;n_{i=1}x_i\\right)}{\\left(\\sum&#94;n_{i=1}x&#94;2_i\\right) n-\\left(\\sum&#94;n_{i=1}x_i\\right)&#94;2} \\end{array}\\right) \\end{eqnarray} である. これを用いて, 次のように近似できる. というのが, 最も素朴な最小二乗法の例である 2 . より一般に, \\(y\\) が \\(m\\) 次の多項式 \\(\\displaystyle f(x)=b+\\sum_{j=1}&#94;{m}a_j x&#94;{j}\\) として表されるような場合についても, 同様にしていうことができる. この場合, 偏差の二乗和は, \\[\\displaystyle\\epsilon=\\sum&#94;{n}_{i=1}\\left(y_i-b-\\sum_{j=1}&#94;{m}a_j x&#94;{j}\\right)&#94;2\\label{eq:fourth}\\tag{4}\\] 先と同様, 各変数ごとの偏微分が \\(0\\) となる連立方程式を解けば良いから, \\begin{eqnarray} \\begin{cases} &\\displaystyle\\frac{\\partial\\epsilon}{\\partial b}&=&\\displaystyle-\\sum_{i=1}&#94;{n}2\\left(y_i-b-\\sum_{j=1}&#94;{m}a_j x&#94;{j}\\right)&=&0 \\\\\\ &\\displaystyle\\frac{\\partial\\epsilon}{\\partial a_1}&=&\\displaystyle-\\sum_{i=1}&#94;{n}2x_i\\left(y_i-b-\\sum_{j=1}&#94;{m}a_j x&#94;{j}\\right)&=&0 \\\\\\ &&&\\vdots& \\\\\\ &\\displaystyle\\frac{\\partial\\epsilon}{\\partial a_m}&=&\\displaystyle-\\sum_{i=1}&#94;{n}2x&#94;m_i\\left(y_i-b-\\sum_{j=1}&#94;{m}a_j x&#94;{j}\\right)&=&0 \\end{cases} \\end{eqnarray} 先の例に合わせて, 両辺を \\(2n\\) で割った行列とすると, 平均の記号を用いて \\begin{eqnarray} \\left(\\begin{array}{cccc} 1 & \\overline{x} & \\cdots & \\overline{x&#94;m} \\\\\\ \\overline{x} & \\overline{x&#94;2} & \\cdots & \\overline{x&#94;{m+1}} \\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\\ \\overline{x&#94;m} & \\overline{x&#94;{m+1}} & \\cdots & \\overline{x&#94;{2m}} \\end{array}\\right) \\left(\\begin{array}{c} b \\\\\\ a_1 \\\\\\ \\vdots \\\\\\ a_m \\end{array}\\right)= \\left(\\begin{array}{c} \\overline{y} \\\\\\ \\overline{xy} \\\\\\ \\vdots \\\\\\ \\overline{x&#94;my} \\end{array}\\right) \\end{eqnarray} なので, \\begin{eqnarray} \\left(\\begin{array}{c} b \\\\\\ a_1 \\\\\\ \\vdots \\\\\\ a_m \\end{array}\\right)&=& \\left(\\begin{array}{cccc} 1 & \\overline{x} & \\cdots & \\overline{x&#94;m} \\\\\\ \\overline{x} & \\overline{x&#94;2} & \\cdots & \\overline{x&#94;{m+1}} \\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\\ \\overline{x&#94;m} & \\overline{x&#94;{m+1}} & \\cdots & \\overline{x&#94;{2m}} \\end{array}\\right)&#94;{-1} \\left(\\begin{array}{c} \\overline{y} \\\\\\ \\overline{xy} \\\\\\ \\vdots \\\\\\ \\overline{x&#94;my} \\end{array}\\right) \\\\\\ &=&\\left(\\begin{array}{cccc} n & \\displaystyle\\sum&#94;{n}_{i=1}x_i & \\cdots & \\displaystyle\\sum&#94;{n}_{i=1}x&#94;m_i \\\\\\ \\displaystyle\\sum&#94;{n}_{i=1}x_i & \\displaystyle\\sum&#94;{n}_{i=1}x_i&#94;2 & \\cdots & \\displaystyle\\sum&#94;{n}_{i=1}x_i&#94;{m+1} \\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\\ \\displaystyle\\sum&#94;{n}_{i=1}x_i&#94;m & \\displaystyle\\sum&#94;{n}_{i=1}x_i&#94;{m+1} & \\cdots & \\displaystyle\\sum&#94;{n}_{i=1}x_i&#94;{2m} \\end{array}\\right)&#94;{-1} \\left(\\begin{array}{c} \\displaystyle\\sum&#94;n_{i=1}y_i \\\\\\ \\displaystyle\\sum&#94;n_{i=1}x_iy_i \\\\\\ \\vdots \\\\\\ \\displaystyle\\sum&#94;n_{i=1}x_i&#94;my_i \\end{array}\\right) \\end{eqnarray} で求まる. この正確な解を機械的に求める場合には, この逆行列を求めなくとも, ガウスの消去法などを基本とした解法(直接解法)で解ける. 先のデータは直線的であったので, 今度は曲線が引けそうなデータセットとして, \\(x_i=i-1, y_i=\\sin(x_i)+\\epsilon, i=1,2,\\cdots,11\\) に対し, フィッティングを試行してみる事とする. ここで \\(\\epsilon\\) は \\(\\mathrm{N}(0, 0.2)\\) の正規分布に従う確率変数である. 次のアニメーションでは, 次数 \\(1\\leq m\\leq 9\\) に応じた近似の遷移を観察できる( LU 分解による計算 \\(\\to\\) 解説 ). ところで, 冒頭で示した関数 \\(\\eqref{eq:ffirst}\\) の線形回帰モデルは, 次のように表すことができる. \\[y_i=a_0+\\sum&#94;m_{j=1}a_jf_j(x_i&#94;1,x_i&#94;2,\\cdots,x_i&#94;n)+u_i,\\ i=1,\\cdots,m\\label{eq:ssecond}\\tag{ii}\\] ここで, \\(f_j\\) は独立変数 \\(x_{i}&#94;k\\) のスカラー関数, \\(u_i\\) は \\(i\\) 番目のノイズ項(確率変数)である. 線形最小二乗法は, 単にすべてのデータ値に対する偏差の二乗和を最小化する. すなわち, データに関わらず全ての値が同じように扱われる. これは, すべてのノイズ項 \\(u_i\\) の確率分布が同一であると仮定することと同値であり, 従って, すべての \\(u_i\\) は無相関かつ i.i.d で \\(\\mathrm{N}\\left(0,\\sigma&#94;2\\right)\\) (標準正規分布) に従うことを前提としているといえる 4 . 一般逆行列 ここまでは, 回帰直線の考え方に沿って近似曲線/直線を得た訳であるが, そもそも, \\((x_i,y_i)\\) の組があって線形方程式 \\(y\\) の \\(x\\) に関する関数における\"適当な\"係数が\"直接\"求まるような行列があれば良いのではないだろうか. つまり \\(m\\) を方程式の個数, \\(n'=n+1\\) を未知数の個数とし, \\(X\\boldsymbol{a}=\\boldsymbol{y}\\ \\ {\\rm where}\\ X\\in\\mathbb{R}&#94;{m\\times n'}, \\boldsymbol{a}\\in\\mathbb{R}&#94;{n'\\times 1}, \\boldsymbol{y}\\in\\mathbb{R}&#94;{m\\times 1}\\) 5 としたとき \\begin{eqnarray} \\left(\\begin{array}{c} y_1 \\\\\\ y_2 \\\\\\ \\vdots \\\\\\ y_m \\end{array}\\right)= \\left(\\begin{array}{cccc} x_1&#94;0 & x_1&#94;1 & \\cdots & x_1&#94;n \\\\\\ x_2&#94;0 & x_2&#94;1 & \\cdots & x_2&#94;n \\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\\ x_m&#94;0 & x_m&#94;1 &\\cdots & x_m&#94;n \\end{array}\\right) \\left(\\begin{array}{c} a_0 \\\\\\ a_1 \\\\\\ \\vdots \\\\\\ a_n \\end{array}\\right) \\\\\\ \\left(\\begin{array}{cccc} x_1&#94;0 & x_1&#94;1 & \\cdots & x_1&#94;n \\\\\\ x_2&#94;0 & x_2&#94;1 & \\cdots & x_2&#94;n \\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\\ x_m&#94;0 & x_m&#94;1 &\\cdots & x_m&#94;n \\end{array}\\right)&#94;{-1} \\left(\\begin{array}{c} y_1 \\\\\\ y_2 \\\\\\ \\vdots \\\\\\ y_m \\end{array}\\right) = \\left(\\begin{array}{c} a_0 \\\\\\ a_1 \\\\\\ \\vdots \\\\\\ a_n \\end{array}\\right)\\label{eq:fifth}\\tag{5} \\end{eqnarray} を解いて, それが求まれば良いのではないか, ということである(\\(n+1\\) と \\(m\\) は必ずしも等しくないことに注意 3 ). このときに考えられるパターンは, 次のとおりである: \\(n'=m\\) かつそのランク \\({\\rm rank}(X)\\) が \\(n'=m\\)(フルランク)ならば, \\(X\\) は正則である. 従って, \\(X&#94;{-1}X\\boldsymbol{a}=X&#94;{-1}\\boldsymbol{y}\\) として解が求まる. \\(n'\\lt m\\) かつそのランクが \\(n'\\)(列フルランク)ならば, すべての方程式を満たすような解が存在しないことがいえる. これは, すべての方程式をそれぞれ直線と捉えたときに, それらすべての交点となる一点が存在しないことをイメージするとわかりやすい. 要するに, \\(\\boldsymbol{a}\\) に対する \\(X\\) と \\(\\boldsymbol{y}\\) の制約が相互的に成立しないのである. ここで \\({\\rm rank}(X)\\lt n'\\)(ランク落ち)ならば, 方程式のどこかに重複がある. \\(m\\lt n'\\) かつそのランクが \\(m\\)(行フルランク)ならば, 解が一意とならないことがいえる. これも, 方程式を直線に捉えると, \\(\\boldsymbol{a}\\) に対する制約が足りないことで, 方程式で構成される直線上のすべてが解となりうることから納得できる. ここで \\({\\rm rank}(X)\\lt m\\)(ランク落ち)ならば, 方程式のどこかに重複がある. いま 2 つの重複がある場合を考えることができたが, 重複を除けば, いま述べたうちのどれかに帰着させることができる. 重複の場合を直線で捉えると, それぞれの方程式が \\(x, y\\) の関係に関して全く異なる解を示しているということなので, それぞれの直線は平行の関係にあることとなる. まとめると, つまり \\(X\\boldsymbol{a}=\\boldsymbol{y}\\) というように表される線形方程式には, 以上の 3 つのパターン(重複について考えれば 4 パターン)があることがわかる. これらのすべてのパターンに対して\"適当であるような\"解を与える逆行列を考えれば, どのような方程式にも\"適当であるような\"解を与えることができる. このように, 正則でない行列に対する擬似的な逆行列の定義を一般逆行列という. 一般逆行列 次の式を満たす行列 \\(X&#94;-\\in\\mathbb{R}&#94;{m\\times n'}\\) を一般逆行列といい, \\(X\\) が特異行列ならば \\(X&#94;-\\) は一意ではないが常に存在する. \\[X X&#94;-X = X\\] \" 適当であるような\"解は様々に考えられるように, 一般逆行列の定義も様々である. 以下やや天下り的ではあるが便宜上の理由より示してしまうと, いくらかの一般逆行列は次で定めるムーア・ベンローズ一般逆行列(以下 MP 逆行列)に従っており, 暗に一般逆行列と言ってこの MP 逆行列のことを示すような場合が巷ではある 6 . Moore-Penrose 一般逆行列 次のすべての条件を満たす 一般逆行列 \\(X&#94;{\\dagger}\\) は Moore-Penrose 一般逆行列( MP 逆行列)といい, その存在は一意 7 である. \\begin{eqnarray} X X&#94;\\dagger X&=&X;\\label{eq:sixth}\\tag{6} \\\\ X&#94;{\\dagger}X X&#94;{\\dagger}&=&X;&#94;{\\dagger}\\label{eq:seventh}\\tag{7} \\\\ \\left(X&#94;{\\dagger}X\\right)&#94;T&=&X;&#94;{\\dagger}X\\label{eq:eigth}\\tag{8} \\\\ \\left(X X&#94;{\\dagger}\\right)&#94;T&=&X; X&#94;{\\dagger}\\label{eq:ninth}\\tag{9} \\end{eqnarray} 最小二乗形一般逆行列 まず, ケース 2 の場合について考える. これは, 最小二乗形一般逆行列といわれる一般逆行列を用いる. これが定める\"適当であるような\"解とは, その名の通り, すべての方程式の二乗誤差が最小である値であり, まさしく上で述べた最小二乗法の値である. 最小二乗形一般逆行列 正規方程式 \\[\\boldsymbol{a}=X&#94;-\\boldsymbol{y}\\] の解 \\(\\boldsymbol{a}\\) を二乗誤差最小の値で定める 一般逆行列 \\[&#94;\\exists X&#94;-\\in\\mathbb{R}&#94;{m\\times n'}\\ {\\rm s.t.}\\ m\\gt n'\\land\\left(X X&#94;-\\right)&#94;T = X X&#94;-\\] は \\(X\\) の最小二乗形一般逆行列である. 以下, 最小二乗形一般逆行列の定式を求めるが, 上で既に述べた内容と本質的には全く変わらない. ここで, 少し扱いやすくするために, \\(n\\) 次多項式を \\(f_n(x)=a_0x&#94;0_i+a_1x&#94;1_i+\\cdots+a_nx&#94;n_i=\\sum&#94;{n}_{j=0}a_jx&#94;j_i\\), \\(\\eqref{eq:fifth}\\) の \\(x_i&#94;j\\) についての行列を \\(X\\) とする. そしてその \\(i\\) 行目を 1 つの縦ベクトルとしたものを \\(\\boldsymbol{x_i}\\) (\\({\\rm e.g.}\\ \\ \\boldsymbol{x_1}=\\left(x_1&#94;0, x_1&#94;1, \\cdots, x_1&#94;n \\right)&#94;T\\)) とし, \\(\\eqref{eq:fourth}\\) の式を \\[\\epsilon=\\sum_{i=1}&#94;{m}\\left(y_i-f_n(\\boldsymbol{x_i})\\right)&#94;2\\label{eq:twelth}\\tag{10}\\] というように表す(これは \\(\\eqref{eq:fourth}\\) と全く同じことを書いただけである)とする. \\(f(\\boldsymbol{x_i})=\\boldsymbol{x_i}&#94;T\\boldsymbol{a}\\) だから \\[=\\sum_{i=1}&#94;{m}\\left(y_i-\\boldsymbol{x_i}&#94;T\\boldsymbol{a}\\right)&#94;2\\] \\(\\left(\\boldsymbol{x_1}&#94;T,\\boldsymbol{x_2}&#94;T,\\cdots,\\boldsymbol{x_m}&#94;T\\right)&#94;T=X\\) なので \\[=\\left(\\boldsymbol{y}-X\\boldsymbol{a}\\right)&#94;T\\left(\\boldsymbol{y}-X\\boldsymbol{a}\\right)\\] ここで, 先にやった, 偏微分を考えることで下に凸な二次関数となることを利用し, その値を \\(0\\) とした上でそれらすべての連立方程式を求め, 最小値を得たことを思いだし, この式を \\(\\boldsymbol{a}\\) で微分する(すべての \\(\\boldsymbol{a_i}\\) で偏微分する, すなわち勾配を求める)と \\[\\nabla\\epsilon\\left(\\boldsymbol{a}\\right)=2X&#94;T X\\boldsymbol{a}-2X&#94;T\\boldsymbol{y}=-2X&#94;T\\left(\\boldsymbol{y}-X\\boldsymbol{a}\\right)\\] \\(\\nabla\\epsilon(\\boldsymbol{a})=0\\) とおくと, \\[X&#94;T X\\boldsymbol{a}=X&#94;T\\boldsymbol{y}\\] と正規方程式が求まった. ここで, \\(n'=m-1\\) のとき \\(X\\) はヴァンデルモンド行列 3 となり, \\(\\boldsymbol{x_1}, \\cdots, \\boldsymbol{x_m}\\) が相異なるとき \\(X\\) は正則となる. 従って, 正規方程式の解は \\[\\boldsymbol{a}=\\left(X&#94;T X\\right)&#94;{-1}X&#94;T \\boldsymbol{y}={X}&#94;{-1}\\boldsymbol{y}\\] とかける. \\(n'\\lt m-1\\) ならば行列 \\(X&#94;T X\\) が正則なので, 正規方程式の解は \\[\\boldsymbol{a}=\\left(X&#94;T X\\right)&#94;{-1}X&#94;T\\boldsymbol{y}\\label{eq:tenth}\\tag{11}\\] とかける. このとき \\(m\\lt n\\) ならば, \\(X&#94;T X\\) が非正則となってしまうから, 最小二乗形一般逆行列は構成できない. この結果から, 時間計算量は多項式時間 \\(\\mathrm{O}(n&#94;3)\\) であることがわかる. また, 最小二乗形一般逆行列は, MP 逆行列 であることが導出できる 8 . 最小ノルム形一般逆行列 次に, ケース 3 の場合を考える. この場合, 最小ノルム形一般逆行列を用いる. ケース 3 は様々な値が解になりうるということであったが, 最小ノルム形一般逆行列は, いまそれを \\(X&#94;-\\) としたとき, \\(\\boldsymbol{a}=X&#94;-\\boldsymbol{y}\\) の解 \\(\\boldsymbol{a}\\) を その \\(L&#94;2\\) ノルム \\(\\mid\\mid \\boldsymbol{a}\\mid\\mid_2\\) が最小となるように定める. 最小ノルム形一般逆行列 正規方程式 \\[\\boldsymbol{a}=X&#94;-\\boldsymbol{y}\\] の解 \\(\\boldsymbol{a}\\) をその \\(L&#94;2\\) ノルム \\(\\mid\\mid \\boldsymbol{a}\\mid\\mid_2\\) が最小となる値で定める 一般逆行列 \\[&#94;\\exists X&#94;-\\in\\mathbb{R}&#94;{m\\times n'}\\ {\\rm s.t.}\\ m\\lt n'\\land\\left(X&#94;- X\\right)&#94;T = X&#94;- X\\] は \\(X\\) の最小ノルム形一般逆行列である. つまり, 解くべきは次に示す制約付き最適化問題/条件付き極小値問題である. \\[\\min_{\\boldsymbol{a}}\\mid\\mid\\boldsymbol{a}\\mid\\mid&#94;2_2\\ {\\rm s.t.}\\ \\boldsymbol{y}=X\\boldsymbol{a}\\] 条件付き極値の問題はラグランジュの未定乗数法で解ける. この証明は中々大変なので, 本エントリでは公理として認めた上で用いることとする( TODO ). 従って, ラグランジアンを次のように定義する. \\[\\mathcal{L}(\\boldsymbol{a}, \\boldsymbol{\\lambda}):=\\mid\\mid\\boldsymbol{a}\\mid\\mid&#94;2_2+\\boldsymbol{\\lambda}&#94;T\\left(\\boldsymbol{y}-X\\boldsymbol{a}\\right)\\] ラグランジュの未定乗数法に従い, それぞれの偏導関数から求めて \\begin{eqnarray} \\begin{cases} \\frac{\\partial}{\\partial\\boldsymbol{a}}\\mathcal{L}(\\boldsymbol{a})&=&2\\boldsymbol{a}-X&#94;T\\boldsymbol{\\lambda}&=&0 \\\\\\ \\frac{\\partial}{\\partial\\boldsymbol{\\lambda}}\\mathcal{L}(\\boldsymbol{a})&=&\\boldsymbol{y}-X\\boldsymbol{a}&=&0 \\end{cases} \\end{eqnarray} よって \\begin{eqnarray} \\begin{cases} \\boldsymbol{a}&=&\\frac{1}{2}X&#94;T\\lambda \\\\\\ \\boldsymbol{y}&=&X\\boldsymbol{a} \\end{cases}\\leftrightarrow\\boldsymbol{y}=\\frac{1}{2}X X&#94;T\\lambda \\end{eqnarray} \\(m\\lt n'\\) ならば \\(X X&#94;T\\) は正則なので \\[\\lambda=2\\left(X X&#94;T\\right)&#94;{-1}\\boldsymbol{y}\\leftrightarrow \\boldsymbol{a}=X&#94;T\\left(X X&#94;T\\right)&#94;{-1}\\boldsymbol{y}\\] \\(X\\boldsymbol{a}=X\\left\\{X&#94;T\\left(X X&#94;T\\right)&#94;{-1}\\boldsymbol{y}\\right\\}=\\left(X X&#94;T\\right)\\left(X X&#94;T\\right)&#94;{-1}\\boldsymbol{y}=\\boldsymbol{y}\\) よりこの正規方程式の解が一般逆行列として成立していることが確認できる. 制限つき最小二乗法 最後に, 重複がある(ランク落ちである)ケースを考える. この場合は, \\(X&#94;T X, X X&#94;T\\) がともに特異行列となってしまうため, 対象の行列に対してまず特異値分解(以下 SVD )を行う. 特異値分解 \\(&#94;\\forall X\\in\\mathbb{R}&#94;{m\\times n'}\\) に対して \\[ &#94;\\exists U\\in\\mathbb{R}&#94;{m\\times m}, &#94;\\exists V\\in\\mathbb{R}&#94;{n'\\times n'}, &#94;\\exists \\Sigma\\in\\mathbb{R}&#94;{n'\\times m}\\ {\\rm s.t.}\\ X = U\\Sigma V&#94;T \\\\ {\\rm where}\\ \\Sigma=\\left( \\begin{array}{ccccc} \\lambda_1&\\cdots&0 \\\\ \\vdots&\\ddots&\\vdots \\\\ 0&\\cdots&\\lambda_{r} \\\\ &&&0 \\\\ &&&&0 \\end{array} \\right), \\lambda_1\\geq\\cdots\\geq\\lambda_{r}\\geq 0, r=\\mathrm{rank}(X)=\\min(m,n') \\] このとき \\(U\\Sigma V&#94;T\\) を \\(X\\) の特異値分解(英: Singular value decomposition)という. これは \\begin{eqnarray} \\displaystyle\\sum&#94;{r}_{i=1}\\lambda_i\\boldsymbol{u_i}\\boldsymbol{v_i}&#94;T\\ {\\rm where} \\ \\begin{array}{cc} \\left(\\boldsymbol{u_1},\\cdots,\\boldsymbol{u_m}\\right)&#94;T &=&\\left(\\begin{array}{ccc} u_{11}&\\cdots&u_{1m} \\\\\\ \\vdots&\\ddots&\\vdots\\\\\\ u_{m1}&\\cdots&u_{mm} \\end{array}\\right)&=&U \\\\\\ \\left(\\boldsymbol{v_1},\\cdots,\\boldsymbol{v_{n'}}\\right)&#94;T &=&\\left(\\begin{array}{ccc} v_{11}&\\cdots&v_{1n'} \\\\\\ \\vdots&\\ddots&\\vdots\\\\\\ v_{n'1}&\\cdots&v_{n'n'} \\end{array}\\right)&=&V \\end{array} \\end{eqnarray} と同値であり, 一般に \\(\\lambda_i\\) を特異値, \\(\\boldsymbol{u_i}\\) を左特異ベクトル \\(\\boldsymbol{v_i}\\) を右特異ベクトルという. TODO : 詳解を追記 オーバーフィッティングと正則化およびその評価 先に, 次数に応じた近似の遷移が観察できるアニメーションを示したが, あまり次数を大きくすると, データ点の間で誤差が大きくなってしまうことがある. これをオーバーフィッティングという. 先と同様, \\(x_i=i-1, y_i=\\sin(x_i)+\\epsilon, i=1,2,\\cdots,11\\) に対する各次元での係数を見てみると(\\(\\eqref{eq:fifth}\\) では, 係数のベクトルを \\(\\left(a_0,a_1,\\cdots,a_n\\right)&#94;T\\) と並べているが, 下記は \\(\\left(a_n,a_{n-1},\\cdots,a_0\\right)&#94;T\\) の順である), λ > : m + Data . Tuple . Extra Data . Maybe System . Random Random . Normal Control . Monad ML . Approx . OLS . ByPinv Utils λ > let uni = normalIO' ( 0 , 0.2 ) λ > let d = zipWith ( \\ x y -> ( x , sin x + y )) [ 0 .. 10 ] <$> replicateM 11 uni λ > dd <- d λ > dd [( 0.0 , - 5.563765361160251e-4 ),( 1.0 , 0.9418472638241775 ),( 2.0 , 1.1378051539092622 ),( 3.0 , 0.30341406458452413 ),( 4.0 , - 0.8411970236084821 ),( 5.0 , - 0.8558604338359868 ),( 6.0 , - 0.2586281201459223 ),( 7.0 , 0.8031257237891795 ),( 8.0 , 1.1562504257723663 ),( 9.0 , 0.39633872602316167 ),( 10.0 , - 0.8085898217611907 )] λ > let outCoes i = putStrLn $ maybe \"failed\" ((( ++ ) $ show i ++ \" ----- \\n \" ) . foldr1 ( ++ ) . ( map (( ++ \" \\n \" ) . show ))) $ resolve i dd λ > mapM_ outCoes [ 1 .. 10 ] 1 ----- [ - 4.168066672607503e-2 ] [ 0.38785329563173637 ] 2 ----- [ 6.311957210780993e-3 ] [ - 0.10480023883388496 ] [ 0.4825326537934513 ] ( 略 ) 9 ----- [ 6.2497127164502315e-6 ] [ - 2.783924911591259e-4 ] [ 5.143290075166487e-3 ] [ - 5.026523522855991e-2 ] [ 0.2724261548894942 ] [ - 0.7770268952402895 ] [ 1.0147233691594897 ] [ - 0.7860963186273294 ] [ 1.2602569068891822 ] [ - 2.3687551597216985e-4 ] 10 ----- [ - 1.626701126479776e-5 ] [ 8.196002759563384e-4 ] [ - 1.7705498506683254e-2 ] [ 0.21421719275219878 ] [ - 1.5895590768542918 ] [ 7.43609912277545 ] [ - 21.670288785218535 ] [ 37.428871273332284 ] [ - 34.68074111840572 ] [ 13.820707197220901 ] [ - 5.563765361160251e-4 ] \\(m=10\\) で, \\(-21.670\\cdots,37.428\\cdots,-34.680\\cdots,13.820\\cdots\\) といった, 絶対値の大きな値が見られる. 実際に \\(m=9, 10\\) でプロットしてみると, λ > mapM_ ( \\ i -> plot $ PP ( \"./image\" ++ show i ++ \".png\" ) ( \"m = \" ++ show i ) \"points\" \"line\" dd $ fromJust $ implicitFn $ fromJust $ resolve i dd ) [ 9 , 10 ] \\(m=10\\) のモデルによる近似は \\(m=9\\) の場合と比べて激しく振れていることが見てとれる. 天下り的になってしまうが, このような現象は推定する係数に対して標本数が少ないようなときによく遭遇する. その特徴として, いま示したように, 係数の絶対値が大きくなることが挙げられる. 従って, 次数を適当に固定した上で(この場合 \\(n=\\)データ数\\(-1\\), すなわちデータ数から機械的に次数を決定する), 係数を絶対値を制限することができれば, これを防ぐことができるだろう. 具体的な手法として, 式 \\(\\eqref{eq:fourth}\\) に対してノルムを加え, その最小化を求めるといったような 9 手法が広く知られている. この手法は, ノルムに対して, 次のように平滑化パラメータ \\(\\lambda \\geq 0\\) を作用させることで正則化の強度を設定することができる. \\[\\epsilon\\left(\\boldsymbol{a}\\right)_\\lambda=\\sum&#94;m_{i=1}\\left(y_i-f_n(\\boldsymbol{x}_i)\\right)&#94;2+\\underbrace{\\lambda R\\left(\\boldsymbol{a}\\right)}_{\\rm 正則化項}\\] このような最適化を正則化法という. こうすると, モデルの変動が大きくなるにつれて正則化項も大きくなり, それが最小化問題へのペナルティとなって, 結果的に滑らかな曲線の推定に繋がる. ただし, 過剰に大きいパラメータをとると, 高次の項へのペナルティが強くなってしまうことで, 結局, 高次の項を無視するのと同等となってしまい, 低次の関数でモデルを作るのと同等になってしまう. 従って, 依然として適切なパラメータの設定が要されるわけだが, モデルの次数を決定するよりかは楽である. またパラメータ \\(\\lambda\\) を標本数で割った形式が取られることもある. \\[\\epsilon\\left(\\boldsymbol{a}\\right)_\\lambda=\\sum&#94;m_{i=1}\\left(y_i-f_n(\\boldsymbol{x}_i)\\right)&#94;2+\\underbrace{\\frac{\\lambda}{m} R\\left(\\boldsymbol{a}\\right)}_{\\rm 正則化項}\\] 両者の違いは正則化項の影響度である. 先に, 推定する係数に対して標本数が少ないようなときにオーバーフィッティングはよく起こると述べたが, ならば当然, 標本数が十分である場合には正則化項は必要ない. パラメータ \\(\\lambda\\) を標本数で割ってやれば, 標本数の増加に従って正則化項の影響度を抑制できる. どちらを用いるかはその時々で選択の余地があるだろう. 例えば, \\(\\lambda\\) を標本数に依らず直接作用させる形式で \\(R\\left(\\boldsymbol{v}\\right)\\) を \\(L&#94;2\\) ノルムとする 9 と, \\begin{eqnarray} \\epsilon\\left(\\boldsymbol{a}\\right)_\\lambda&=&\\sum&#94;m_{i=1}\\left(y_i-f_n(\\boldsymbol{x}_i)\\right)&#94;2+\\lambda\\sum_{j=0}&#94;{n}a&#94;2_j \\\\\\ &=&\\left(\\boldsymbol{y}-X\\boldsymbol{a}\\right)&#94;T\\left(\\boldsymbol{y}-X\\boldsymbol{a}\\right)+\\lambda\\boldsymbol{a}&#94;T\\boldsymbol{a} \\end{eqnarray} 先と同様に \\(\\nabla\\epsilon\\left(\\boldsymbol{a}\\right)_\\lambda=0\\) とおいて, \\begin{eqnarray} \\nabla\\epsilon\\left(\\boldsymbol{a}\\right)_\\lambda&=&-2X&#94;T\\left(\\boldsymbol{y}-X\\boldsymbol{a}\\right)+2\\lambda\\boldsymbol{a} \\\\\\ &=&2\\left(\\lambda I+X&#94;T X\\right)\\boldsymbol{a}-2X&#94;T\\boldsymbol{y}\\\\\\ &=&0 \\end{eqnarray} 従ってこの正規方程式の解は, \\[\\boldsymbol{a}=\\left(\\lambda I+X&#94;T X\\right)&#94;{-1}X&#94;T\\boldsymbol{y}\\] となる. \\(\\boldsymbol{a}\\) を求めるに際する時間計算量について加味すると, 逆行列を計算するよりも LU 分解を行った方が良いので, \\[\\left(\\lambda I+X&#94;T X\\right)\\boldsymbol{a}=X&#94;T\\boldsymbol{y}\\] としておく. この正規方程式を用いて, 平滑化パラメータ \\(\\lambda=0.1,1,10\\) を適用しプロットすると, λ > mapM_ ( \\ i -> plot $ PP ( \"./image\" ++ show i ++ \".png\" ) ( \"parameter = \" ++ show i ) \"points\" \"line\" dd $ fromJust $ implicitFn $ fromJust $ resolveRegular i dd ) [ 0.1 , 1 , 10 ] 次のようになる. 問題は, どのようにしてオーバーフィッティングを評価するかである. データセット \\(\\bf x\\) に対し, 真の値 \\(t_i\\) を \\(D=\\left\\{\\left({\\bf x_1},t_1\\right), \\left({\\bf x_2},t_2\\right),\\cdots,\\left({\\bf x_m},t_m\\right)\\right\\} {\\rm where}\\ t_i=g+u_i\\ \\left(\\because\\ \\eqref{eq:ssecond}\\ {\\text より}\\right)\\) とし, 回帰分析によって得られるモデル \\(\\hat{f}_n({\\bf y_i})=f_n(\\boldsymbol{x'_i})\\ {\\rm where}\\ \\boldsymbol{x'_i}=\\left({\\bf y_i&#94;0},{\\bf y_i&#94;1},\\cdots,{\\bf y_i&#94;n}\\right)&#94;T \\left(\\because \\eqref{eq:twelth}\\ {\\text より}\\right)\\) との差を次のように定義する. \\[L\\left(t_i, \\hat{f}_n(\\boldsymbol{{\\bf x_i}})\\right):=\\left(t_i-\\hat{f}_n(\\boldsymbol{{\\bf x_i}})\\right)&#94;2\\] この \\(L\\) は損失関数といわれる. ここで, \\(\\bf x_i\\) と \\(t_i\\) が得られる同時確率を考慮すると, 損失の期待値は \\begin{eqnarray} E\\left[L\\left(t_i, \\hat{f}_n({\\bf x_i})\\right)\\right]&=& \\int\\int\\left(t_i-\\hat{f}_n({\\bf x_i})\\right)&#94;2P\\left(t_i\\cap{\\bf x_i}\\right)dt_id{\\bf x_i} \\\\\\ &=&\\int\\left\\{\\int\\left(t_i-\\hat{f}_n({\\bf x_i})\\right)&#94;2P\\left(t_i\\mid{\\bf x_i}\\right)dt_i\\right\\}P\\left({\\bf x_i}\\right)d{\\bf x_i}\\ \\left(\\because \\href{https://falgon.github.io/roki.log/posts/2018/10月/28/probabilityTerms/#MulTheoremConditionalProbability}{\\text 条件付き確率の乗法定理}\\right) \\end{eqnarray} \\(\\int\\left(t_i-\\hat{f}_n({\\bf x_i})\\right)&#94;2P\\left(t_i|{\\bf x_i}\\right)\\) を最小化したいので, これを \\(g({\\bf y})=\\int\\left(t_i-\\hat{f}_n({\\bf y_i})\\right)&#94;2P\\left(t_i|{\\bf y_i}\\right)\\) とおいて \\begin{eqnarray} \\frac{\\partial}{\\partial \\hat{f}_n({\\bf x_i})} g({\\bf x_i})&=&2\\int\\left(t_i-\\hat{f}_n({\\bf x_i})\\right)P\\left(t\\mid{\\bf x_i}\\right)dt_i \\\\\\ &=&2\\int\\left\\{\\hat{f}_n({\\bf x_i})P\\left(t_i\\mid{\\bf x_i}\\right)\\right\\}dt_i-2\\int t_i P\\left(t_i\\mid{\\bf x_i}\\right)dt_i \\\\\\ &=&2\\hat{f}_n({\\bf x_i})\\int P\\left(t_i\\mid{\\bf x_i}\\right)dt_i-2\\int t_i P\\left(t_i\\mid{\\bf x_i}\\right)dt_i \\\\\\ &=&2\\hat{f}_n({\\bf x_i})-2\\int t_i P\\left(t_i\\mid {\\bf x_i}\\right)dt_i\\ \\left(\\because \\href{https://falgon.github.io/roki.log/posts/2018/10月/28/probabilityTerms/#normalizationLaw}{\\text 規格化条件}\\right) \\end{eqnarray} \\(\\therefore\\) $$ \\nabla g({\\bf x})=0\\leftrightarrow \\hat{f}_n({\\bf x_i})=\\int t_i P\\left(t_i\\mid{\\bf x_i}\\right)=E\\left[t_i\\mid{\\bf x_i}\\right] $$ よって, \\(\\hat{f}_n\\) は条件付き期待値 \\(E\\left[t_i\\mid{\\bf x_i}\\right]\\) で決めると最小化されることがわかった. 先に示した損失関数 \\(L\\) は, 一つの点における差なので, すべての点における差を次のように定義する(英: mean-square error から). $${\\rm MSE}:=\\sum&#94;m_{i=1}L\\left(t_i,\\hat{f}_n({\\bf x_i})\\right)$$ この期待値をできる限り小さくしたい. $$E\\left[{\\rm MSE}\\right]=E\\left[\\sum&#94;m_{i=1}L\\left(t_i,\\hat{f}_n({\\bf x})\\right)\\right]=\\sum_{i=1}&#94;mE\\left[L\\left(t_i,\\hat{f}_n({\\bf x})\\right)\\right]\\ \\left(\\because \\href{https://falgon.github.io/roki.log/posts/2018/10月/28/probabilityTerms/#fn-2}{\\text 期待値の線形性}\\right)$$ \\(E\\left[L\\left(t_i,\\hat{f}_n({\\bf x_i})\\right)\\right]\\) について展開すると, \\begin{eqnarray} E\\left[L\\left(t_i,\\hat{f}_n({\\bf x_i})\\right)\\right]&=& E\\left[\\left(t_i-\\hat{f}_n({\\bf x_i})\\right)&#94;2\\right] \\\\\\ &=&E\\left[\\left(t_i-E\\left[t_i\\mid{\\bf x_i}\\right]+E\\left[t_i\\mid{\\bf x_i}\\right]-\\hat{f}_n({\\bf x_i})\\right)&#94;2\\right] \\left(\\because {\\rm augmentation\\ trick}\\right)\\\\\\ &=&E\\left[\\left\\{\\underbrace{\\left(t_i-E\\left[t_i\\mid{\\bf x_i}\\right]\\right)}_{a}+\\underbrace{\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-\\hat{f}_n({\\bf x_i})\\right)}_{b}\\right\\}&#94;2\\right] \\\\\\ &=&E\\left[ \\begin{array}{c} \\left(t_i-E\\left[t_i\\mid{\\bf x_i}\\right]\\right)&#94;2+ \\\\\\ \\left(E\\left[t_i\\mid{\\bf x_i}\\right]-\\hat{f}_n({\\bf x_i})\\right)&#94;2+ \\\\\\ 2\\left(t_i-E\\left[t_i\\mid{\\bf x_i}\\right]\\right)\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-\\hat{f}_n({\\bf x_i})\\right) \\end{array}\\ \\right] \\left(\\because \\left(a+b\\right)&#94;2=a&#94;2+b&#94;2+2ab\\label{eq:thirteenth}\\tag{12}\\right) \\\\\\ &=& \\begin{array}{c} E\\left[\\left(t_i-E\\left[t_i\\mid{\\bf x_i}\\right]\\right)&#94;2\\right] \\\\\\ +E\\left[\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-\\hat{f}_n({\\bf x_i})\\right)&#94;2\\right] \\\\\\ +E\\left[2\\left(t_i-E\\left[t_i\\mid{\\bf x_i}\\right]\\right)\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-\\hat{f}_n({\\bf x_i})\\right)\\right] \\end{array} \\left(\\because \\href{https://falgon.github.io/roki.log/posts/2018/10月/28/probabilityTerms/#fn-2}{\\text 期待値の線形性}\\right) \\end{eqnarray} 第三項について \\begin{eqnarray} E\\left[2\\left(t_i-E\\left[t_i\\mid{\\bf x_i}\\right]\\right)\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-\\hat{f}_n({\\bf x})\\right)\\right]&=&2\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-\\hat{f}_n({\\bf x})\\right)E\\left[\\left(t_i-g\\right)\\right]\\ \\left(\\because \\href{https://falgon.github.io/roki.log/posts/2018/10月/28/probabilityTerms/#mjx-eqn-eq%3Aexaxiom3}{E\\left[a A\\right]=a E\\left[A\\right]}\\right) \\\\\\ &=&2\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-\\hat{f}_n({\\bf x})\\right)\\left(E\\left[t_i\\right]-E\\left[E\\left[t_i\\mid{\\bf x_i}\\right]\\right]\\right)\\ \\left(\\because \\href{https://falgon.github.io/roki.log/posts/2018/10月/28/probabilityTerms/#fn-2} {\\text 期待値の線形性}\\right) \\\\\\ &=&2\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-\\hat{f}_n({\\bf x})\\right)\\left(E\\left[t_i\\right]-E\\left[t_i\\right]\\right) \\ \\left(\\because \\href{https://falgon.github.io/roki.log/posts/2018/10月/28/probabilityTerms/#fn-4}{E\\left[B\\right]=E\\left[E\\left[B\\mid A\\right]\\right]}\\right) \\\\\\ &=&0 \\end{eqnarray} \\(\\therefore\\) \\begin{eqnarray} E\\left[L\\left(t_i,\\hat{f}_n({\\bf x_i})\\right)\\right]&=& E\\left[\\left(t_i-E\\left[t_i\\mid{\\bf x_i}\\right]\\right)&#94;2\\right]+ E\\left[\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-\\hat{f}_n({\\bf x})\\right)&#94;2\\right] \\\\\\ &=&E\\left[u&#94;2\\right]+E\\left[\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-\\hat{f}_n({\\bf x_i})\\right)&#94;2\\right] \\end{eqnarray} この第一項は, 真の値と最小化された理想の関数の差であるので, ノイズ項に対応することとなる. 従って, 第一項に関してもう少し潜り込んでみると \\begin{eqnarray} E\\left[\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-\\hat{f}_n({\\bf x_i})\\right)&#94;2\\right]&=& E\\left[\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-E\\left[\\hat{f}_n({\\bf x_i})\\right]+E\\left[\\hat{f}_n({\\bf x_i})\\right]-\\hat{f}_n({\\bf x_i})\\right)&#94;2\\right]\\ \\left(\\because {\\rm augmentation\\ trick}\\right)\\\\\\ &=&E\\left[\\left\\{ \\underbrace{\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-E\\left[\\hat{f}_n({\\bf x_i})\\right]\\right)}_{a}+ \\underbrace{\\left(E\\left[\\hat{f}_n({\\bf x_i})\\right]-\\hat{f}_n({\\bf x_i})\\right)}_{b}\\right \\}&#94;2\\right]\\\\\\ &=&E\\left[ \\begin{array}{c} \\left(E\\left[t_i\\mid{\\bf x_i}\\right]-E\\left[\\hat{f}_n({\\bf x_i})\\right]\\right)&#94;2+\\\\\\ \\left(E\\left[\\hat{f}_n({\\bf x_i})\\right]-\\hat{f}_n({\\bf x_i})\\right)&#94;2+\\\\\\ 2\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-E\\left[\\hat{f}_n({\\bf x_i})\\right]\\right)\\left(E\\left[\\hat{f}_n({\\bf x_i})\\right]-\\hat{f}_n({\\bf x_i})\\right)&#94;2 \\end{array} \\right]\\ \\left(\\because \\eqref{eq:thirteenth}\\right) \\\\\\ &=&\\begin{array}{c} E\\left[\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-E\\left[\\hat{f}_n({\\bf x_i})\\right]\\right)&#94;2\\right]+\\\\\\ E\\left[\\left(E\\left[\\hat{f}_n({\\bf x_i})\\right]-\\hat{f}_n({\\bf x_i})\\right)&#94;2\\right]+\\\\\\ 2E\\left[\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-E\\left[\\hat{f}_n({\\bf x_i})\\right]\\right)\\left(E\\left[\\hat{f}_n({\\bf x_i})\\right]-\\hat{f}_n({\\bf x_i})\\right)&#94;2\\right] \\end{array}\\ \\\\\\ &&\\left(\\because \\href{https://falgon.github.io/roki.log/posts/2018/10月/28/probabilityTerms/#fn-2}{\\text 期待値の線形性}, \\href{https://falgon.github.io/roki.log/posts/2018/10月/28/probabilityTerms/#mjx-eqn-eq%3Aexaxiom3}{E\\left[a A\\right]=a E\\left[A\\right]}\\right) \\end{eqnarray} 第三項について \\begin{eqnarray} &2E\\left[\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-E\\left[\\hat{f}_n({\\bf x_i})\\right]\\right)\\left(E\\left[\\hat{f}_n({\\bf x_i})\\right]-\\hat{f}_n({\\bf x_i})\\right)&#94;2\\right]= 2\\left( \\begin{array}{l} E\\left[E\\left[t_i\\mid{\\bf x_i}\\right]E\\left[\\hat{f}_n({\\bf x_i})\\right]\\right]- \\\\\\ E\\left[E\\left[\\hat{f}_n({\\bf x_i})\\right]&#94;2\\right]- \\\\\\ E\\left[\\hat{f}_n({\\bf x_i})E\\left[t_i\\mid{\\bf x_i}\\right]\\right]+ \\\\\\ E\\left[\\hat{f}_n({\\bf x_i})E\\left[\\hat{f}_n({\\bf x_i})\\right]\\right] \\end{array} \\right) \\label{eq:fourteenth}\\tag{13} \\end{eqnarray} ここで \\(\\href{https://falgon.github.io/roki.log/posts/2018/10月/28/probabilityTerms/#mjx-eqn-eq%3Aexaxiom3}{E\\left[a A\\right]=a E\\left[A\\right]} , \\href{https://falgon.github.io/roki.log/posts/2018/10月/28/probabilityTerms/#consExpisCons}{E\\left[a\\right]=a} \\to E\\left[E\\left[a\\right]\\right]=a\\) より $$E\\left[E\\left[t_i\\mid{\\bf x_i}\\right]E\\left[\\hat{f}_n({\\bf x_i})\\right]\\right]=E\\left[t_i\\mid{\\bf x_i}\\right]E\\left[\\hat{f}_n({\\bf x_i})\\right]$$ \\(\\href{https://falgon.github.io/roki.log/posts/2018/10月/28/probabilityTerms/#consExpisCons}{E\\left[a\\right]=a} \\to E\\left[E\\left[a\\right]\\right]=a\\) より $$E\\left[E\\left[\\hat{f}_n({\\bf x_i})\\right]&#94;2\\right]=E\\left[\\hat{f}_n({\\bf x_i})\\right]&#94;2$$ \\(\\href{https://falgon.github.io/roki.log/posts/2018/10月/28/probabilityTerms/#mjx-eqn-eq%3Aexaxiom3}{E\\left[a A\\right]=a E\\left[A\\right]}\\) より $$E\\left[\\hat{f}_n({\\bf x_i})E\\left[t_i\\mid{\\bf x_i}\\right]\\right]=E\\left[t_i\\mid{\\bf x_i}\\right]E\\left[\\hat{f}_n({\\bf x_i})\\right]$$ \\(\\href{https://falgon.github.io/roki.log/posts/2018/10月/28/probabilityTerms/#mjx-eqn-eq%3Aexaxiom3}{E\\left[a A\\right]=a E\\left[A\\right]}\\) より $$E\\left[\\hat{f}_n({\\bf x_i})E\\left[\\hat{f}_n({\\bf x_i})\\right]\\right]=E\\left[\\hat{f}_n({\\bf x_i})\\right]&#94;2$$ よって $$ \\eqref{eq:fourteenth}= 2\\left( E\\left[t_i\\mid{\\bf x_i}\\right]E\\left[\\hat{f}_n({\\bf x_i})\\right]- E\\left[\\hat{f}_n({\\bf x_i})\\right]&#94;2- E\\left[t_i\\mid{\\bf x_i}\\right]E\\left[\\hat{f}_n({\\bf x_i})\\right]+ E\\left[\\hat{f}_n({\\bf x_i})\\right]&#94;2 \\right) =0 $$ \\(\\therefore\\) \\begin{eqnarray} E\\left[\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-\\hat{f}_n({\\bf x_i})\\right)&#94;2\\right] &=& E\\left[\\left(E\\left[t_i\\mid{\\bf x_i}\\right]-E\\left[\\hat{f}_n({\\bf x_i})\\right]\\right)&#94;2\\right]+E\\left[\\left(E\\left[\\hat{f}_n({\\bf x_i})\\right]-\\hat{f}_n({\\bf x_i})\\right)&#94;2\\right] \\\\\\ &=& {\\rm Bias}\\left[\\hat{f}_n({\\bf x_i})\\right]&#94;2+{\\rm Var}\\left[\\hat{f}_n({\\bf x_i})\\right] \\end{eqnarray} また \\begin{eqnarray} E\\left[L\\left(t_i,\\hat{f}_n({\\bf x_i})\\right)\\right]={\\rm Bias}\\left[\\hat{f}_n({\\bf x_i})\\right]&#94;2+{\\rm Var}\\left[\\hat{f}_n({\\bf x_i})\\right]+\\sigma&#94;2 \\end{eqnarray} この一連の展開作業は, バイアス-バリアンス分解といわれる. バイアスは, 損失の期待値を最小化する \\(E\\left[t|{\\bf x_i}\\right]\\) とのずれの期待値である. 従って, 関数モデルを複雑にするほど値は減少する. バリアンスはモデルの分散であり, モデルの複雑さを表す指標である. 従って, 関数モデルを複雑にするほど値は増加する. 両者のこの関係性をバイアスとバリアンスのトレードオフという. 多くの場合, これらが同時に可能な限り低い値をとるモデルのことを, データセットに対する適切なモデルと言うことができるだろう. ここで, 先に示したデータセットに対して, 4 次元と 9 次元の線形関数による近似を行い, それぞれのバイアスとバリアンスを比較する. λ > let bias :: ( Real a , Fractional a ) => ( a -> a ) -> ( a -> a ) -> [ a ] -> a ; bias fh f il = ( / ( fromIntegral $ length il )) $ sum $ map (( &#94;&#94; 2 ) . uncurry ( - ) . first f . second fh . dupe ) il λ > let var :: ( Real a , Fractional a ) => ( a -> a ) -> [ a ] -> a ; var fh il = let len = fromIntegral $ length il ; s = ( / len ) $ sum $ map fh il in ( / len ) $ sum $ map (( &#94;&#94; 2 ) . fh ) il λ > let f = sin λ > let fhat = fromJust . implicitFn . fromJust . flip resolve dd λ > bias ( fhat 4 ) f [ 0 .. 10 ] > bias ( fhat 9 ) f [ 0 .. 10 ] True λ > var ( fhat 4 ) [ 0 .. 10 ] < var ( fhat 9 ) [ 0 .. 10 ] True 先にオーバーフィッティングしてしまった, 10 次元のモデルと 9 次元のモデルのバイアスとバリアンスを比較する. λ > bias ( fhat 9 ) f [ 0 .. 10 ] > bias ( fhat 10 ) f [ 0 .. 10 ] True λ > var ( fhat 9 ) [ 0 .. 10 ] < var ( fhat 10 ) [ 0 .. 10 ] True \\(L&#94;2\\) 正則化(\\(\\lambda=0.1,1,10\\))を施した場合を見てみる. λ > import qualified ML.Approx.Regularization.L2 as Reg λ > let fhat' = fromJust . implicitFn . fromJust . flip Reg . resolve dd λ > mapM_ ( print . ( flip ( flip bias f ) [ 0 .. 10 ]) . fhat' ) [ 0.1 , 1 , 10 ] 1.9110967187955293e-2 2.283386765131595e-2 4.427871557982087e-2 λ > mapM_ ( print . ( flip var [ 0 .. 10 ]) . fhat' ) [ 0.1 , 1 , 10 ] 0.5855240280868919 0.5530852362842676 0.4586444106136849 誤差分布が正規分布でない場合の線形回帰 式 \\(\\eqref{eq:ssecond}\\) 等で, 線形最小二乗法がすべてのノイズ項の確率分布を同一視することを示した. この仮定により, 誤差の分布が非対称, あるいは外れ値が顕著に見られるようなデータセットに対する線形最小二乗法の適用結果は, パラメータの推定, 信頼区間およびその統計量について信頼できなくなる. λ > let d n n' p = zipWith ( \\ x y -> ( x , 2 * x + y )) [ n .. fromIntegral n' ] <$> let uni = normalIO' p in replicateM ( succ n' ) uni λ > dleft <- d 0 10 ( 0 , 0.2 ) λ > dright <- d 15 25 ( 0 , 0.2 ) λ > let dd = dleft ++ [( x , 60 ) | x <- take 4 [ succ $ fst $ last dleft .. ]] ++ dright λ > plot $ PP \"./image.png\" \"Figure\" \"points\" \"line\" dd $ fromJust $ implicitFn $ fromJust $ resolve 1 dd \\(\\mathrm{N}(0,0.2)\\) の確率誤差の他に, 4 つの外れ値 10 を仕込んだこのデータへ線形最小二乗法(\\(n=1\\))を施すと, 外れ値に影響された推定が行われることがわかる. これを防ぐ方法はいくつか存在する. 以下, 説明のために改めて, \\(p\\) 個の独立変数を有する多重線形回帰モデルを \\[\\boldsymbol{y}=X'\\boldsymbol{\\beta}+\\boldsymbol{u}\\] とする. ここで \\(\\boldsymbol{\\beta}=\\boldsymbol{a}\\) で \\(X'\\) は説明変数の行 \\(\\boldsymbol{x'_i}=\\left(x'_{i1}, x'_{i2},\\cdots,x'_{ip}\\right)&#94;T\\) を有するフルランク行列 \\(X'\\in\\mathbb{R}&#94;{m\\times p}\\) であり, \\(\\boldsymbol{u}\\) は i.i.d かつ \\(\\mathrm{N}(0,\\sigma&#94;2)\\) に従う確率誤差のベクトル \\(\\boldsymbol{u}=\\left(u_1,u_2,\\cdots,u_m\\right)&#94;T\\in\\mathbb{R}&#94;{m\\times 1}\\) とする. なおこの定義に従うと, (Ordinary least squares より)通常の最小二乗法は次の式で定義できる. \\begin{eqnarray} \\mathrm{OLS}(X',\\boldsymbol{y})&:=&\\mathrm{arg}\\min_\\boldsymbol{\\boldsymbol{\\beta}}\\sum&#94;m_{i=1}r(\\boldsymbol{\\beta})&#94;2_i \\label{eq:eleventh}\\tag{14} \\\\\\ &=&\\eqref{eq:tenth} \\end{eqnarray} ここで \\(r(\\boldsymbol{\\beta})_i\\) は \\(r(\\boldsymbol{\\beta})_i=y_i-\\boldsymbol{x}_i\\boldsymbol{\\beta}\\) である(\\(\\eqref{eq:fourth}\\) の偏差の部分). 以下, パラメータのベクトル \\(\\boldsymbol{\\beta}\\) を明示的に示す必要がないときには \\(r(\\boldsymbol{\\beta})_i\\) を \\(r_i\\) と示すこととする. 最小刈込み二乗法 一言でいえば, この方法は単純に外れ値を最小二乗法の対象から除外してしまう方法である(以下 Least trimmed squares 11 より LTS と記述)といわれる. \\begin{eqnarray} \\mathrm{LTS}(X,\\boldsymbol{y},k)&:=&\\mathrm{arg}\\min_\\boldsymbol{\\beta}\\sum&#94;k_{i=1}r(\\boldsymbol{\\beta})&#94;2_{(i)} \\\\\\ &&{\\rm s.t.\\ } r(\\boldsymbol{\\beta})&#94;2_{(1)}\\leq r(\\boldsymbol{\\beta})&#94;2_{(2)}\\leq\\cdots\\leq r(\\boldsymbol{\\beta})&#94;2_{(m)} \\end{eqnarray} ここで \\(r(\\boldsymbol{\\beta})_{(i)}\\) は \\(i\\) 番目に小さい残差を示す. 要するに, \\(m\\) 個の偏差の二乗を昇順で並べ, 適当なパラメータ \\(k\\ \\left(k\\leq m\\right)\\) に対して \\(\\sum&#94;k_{i=1}\\left(r&#94;2\\right)_{i:m}\\) を最小化する回帰係数を求めることをいう. 当然, \\(k=m\\) とすると, 通常の最小二乗法と同じ結果となるが, \\(k\\lt m\\) で設定することで \\(m-k\\) 個の大きな偏差をもつデータを無視できる. LTS は次の手順で実行する. TODO : LTS の手順 TODO : LTS による近似の実装 また, 各データ点に対して重み(確率分布)を付与し, それらを単なる算術平均として捉えるのではなく, 期待値として捉えるようにする方法が思いつく. 実際にこれらはそれぞれ名前がついていて, 前者は最小刈り込み二乗法, 後者はロバスト推定といわれる. TODO : 最小刈り込みに情報, ロバスト推定による近似の実装 参考文献 「 正規方程式の導出と計算例 - 高校数学の美しい物語 」 2018 年 11 月 2 日アクセス. 「 Rでスパースモデリング：Elastic Net回帰についてまとめてみる 」 2018 年 11 月 5 日アクセス. 川野 秀一, 廣瀬 慧, 立石 正平, 小西 貞則 (2010)「 回帰モデリングと \\(L_1\\) 型正則化法の最近の展開 」, 日本統計学会誌 第 39 巻, 第 2 号, 211 頁 〜 242 頁 pp.211~215, 2018 年 11 月 5 日アクセス. 「 数値計算 大阪大学基礎工学部 」 2018 年 11 月 5 日アクセス. 美添 泰人 (2010)「 経済と統計の間で 」, 日本統計学会誌 第 38 巻, 第 2 号, 161 頁 〜 179 頁 pp.173~175 2018 年 11 月 10 日アクセス. 「 バイアス-バリアンス分解：機械学習の性能評価 - HELLO CYBERNETICS 」 2018 年 11 月 13 日アクセス. Jurgen A. Doornik (2011) \" Robust Estimation Using Least Trimmed Squares \", Institute for Economic Modelling, Oxford Martin School, and Economics Department, University of Oxford, UK Rousseeuw and B.C. Van Zomeren (1990) \" Unmasking multivariate outliers and leverage points \", Journal of the American Statistical Association, pp.633–639 Vincenzo Verardi \" Robust Statistics Statistics in Stata \", 2018 年 11 月 17 日アクセス. データセットは, Data Set for CHAPTER 2 - DIFFERENTIAL EQUATIONS graphics, models, data を利用させていただいた. ↩ 最小二乗法の定義により「\\(\\mathrm{Cov}(x,y)\\gt 0\\leftrightarrow\\)最小二乗法による直線の傾きが正」がいえることで, 「相関係数が \\(0\\) であるとき, 各 \\(x_i,y_i\\) に相関関係がない」を数学的に説明できたと捉えることができる. ↩ \\(n'=m\\) で, 同行列のような各行が初項 \\(1\\) の等比数列であるような正方行列をヴァンデルモンド行列という. ↩ ↩ したがって, 式に起こすと以下の通り: \\begin{eqnarray}E\\left[y_i\\right]&=&E\\left[\\sum&#94;m_{j=0}a_jf_j\\left(x_i&#94;0,x_i&#94;1,\\cdots,x_i&#94;n\\right)+\\epsilon_i\\right]\\\\\\ &=&\\sum&#94;m_{j=0}a_jf_j\\left(x_i&#94;0,x_i&#94;1,\\cdots,x_i&#94;n\\right)+E\\left[\\epsilon_i\\right] \\\\\\ &=&\\sum&#94;m_{j=0}a_jf_j\\left(x_i&#94;0,x_i&#94;1,\\cdots,x_i&#94;n\\right) \\end{eqnarray} また, \\[V\\left[y_i\\right]=V\\left[\\sum&#94;m_{j=0}a_jf_j\\left(x_i&#94;0,x_i&#94;1,\\cdots,x_i&#94;n\\right)+\\epsilon_i\\right]=V\\left[\\epsilon_i\\right]=\\sigma&#94;2\\] ↩ 複素行列について扱う場合, 転置行列を随伴行列, 直交行列をユニタリ行列にすれば同様にして求まる. ↩ 例えば, Wolfram 言語では PseudoInverse という組み込みシンボルがあるが, これは MP 逆行列を算出する. また R 言語の pinv 関数も同様. ↩ 一意性の証明: いま \\(X\\) に 2 つの相異なる MP 逆行列 \\(A&#94;{\\dagger}\\not =B&#94;{\\dagger}\\) が存在すると仮定する. まず \\(A&#94;{\\dagger}\\) について, \\(A&#94;{\\dagger} = A&#94;{\\dagger} X A&#94;\\dagger = A&#94;\\dagger(X A&#94;\\dagger)&#94;T=A&#94;\\dagger(X B&#94;\\dagger X A&#94;\\dagger)&#94;T=A&#94;\\dagger(X A&#94;\\dagger)&#94;T(X B&#94;\\dagger)&#94;T= A&#94;\\dagger X A&#94;\\dagger X B&#94;\\dagger=A&#94;\\dagger X B&#94;\\dagger\\). 次に \\(B&#94;\\dagger\\) について, \\(B&#94;\\dagger = B&#94;\\dagger X B&#94;\\dagger = (B&#94;\\dagger X)&#94;T B&#94;\\dagger = (B&#94;\\dagger X A&#94;\\dagger X)&#94;T B&#94;\\dagger = (A&#94;\\dagger X)&#94;T (B&#94;\\dagger X)&#94;T B&#94;\\dagger = A&#94;\\dagger X B&#94;\\dagger X B&#94;\\dagger = A&#94;\\dagger X B&#94;\\dagger\\). 背理により, \\(A&#94;\\dagger=B&#94;\\dagger\\). \\(\\square\\) ↩ 最小二乗形一般逆行列が MP 逆行列であることの証明: \\(X&#94;{\\dagger}X=\\underbrace{\\left(X&#94;T X\\right)&#94;{-1}X&#94;T}_{X&#94;\\dagger} X=I\\) だから \\(\\eqref{eq:sixth},\\eqref{eq:seventh}, \\eqref{eq:eigth}, \\eqref{eq:ninth}\\) より \\begin{eqnarray}X X&#94;\\dagger X&=&X\\left(X&#94;\\dagger X\\right)&=&X\\\\\\ X&#94;\\dagger X X&#94;\\dagger&=&\\left(X&#94;\\dagger X\\right)X&#94;\\dagger&=&X&#94;\\dagger\\\\\\ \\left(X&#94;\\dagger X\\right)&#94;T&=&I&#94;T&=&I&=&X&#94;\\dagger X\\\\\\ \\left(X X&#94;\\dagger\\right)&#94;T&=&\\left\\{X\\left(X&#94;T X\\right)&#94;{-1}X&#94;T\\right\\}&#94;T&=&X\\left(X&#94;T X\\right)&#94;{-1}X&#94;T&=&X X&#94;\\dagger\\end{eqnarray} なお最後の式変形では, \\(\\left(A B\\right)&#94;T =B&#94;T A&#94;T, \\left(A&#94;{-1}\\right)&#94;T=\\left(A&#94;T\\right)&#94;{-1}\\) を用いた. \\(\\square\\) ↩ このような, \\(\\lambda\\sum_{j=0}&#94;{n}\\left|a_j\\right|&#94;q\\) で \\(q=2\\) の場合を Ridge 回帰という. また \\(q=1\\) のとき(すなわち正則化項が \\(L&#94;1\\) ノルム)を Lasso 回帰という. さらに, これらの正則化項の線形結合の形式をとる Elastic Net 回帰というモデルもある(Elastic Net 回帰に関する 参考文献2 ). この形式で表せる正則化項を用いる回帰をブリッジ回帰という. ↩ ↩ このような, 線形性の見られるデータセットに従わず, かつ直交座標系における \\(Y\\) 軸方向にデータポイント \\(\\left(x'_{ij},y_i\\right)\\) が外れているような点を垂直外れ値(英: vertical outlier)という. また同状況下で \\(X\\) 軸方向に大きく外れているような点を悪いレバレッジ点(英: bad leverage point)という. さらに, \\(\\left(x'_{ij},y_i\\right)\\) が大多数のパターンに従うとき, それを良いレバレッジ点(英: good leverage point)という(\\(\\to\\) 参考文献8 , 参考文献9 ). ↩ LTS の歴史的背景および専門家らによる認識に関する言及: Peter Rousseeuw introduced several robust regression estimators, including least median of squares ( LMS ) and least trimmed squares ( LTS ), see Rousseeuw (1984) as well as the monograph Rousseeuw and Leroy (1987). LTS converges at rate \\(n&#94;{\\frac{1}{2}}\\) with the same assymptotic efficiency under normalityas Huber's skip estimator. The LMS convergence rate is \\(n&#94;{\\frac{1}{3}}\\) and its objective function is less smooth than LTS . As a consequence, as argued in Rousseeuw and van Driessen (2006), LTS is now preferred over LMS . — 参考文献7 pp.2 , この他にも残差の 2 乗のメディアンを最少にする LMS (least median of squares) などが提案されているが，いずれも収束が遅く，効率も高くないこともあり，Huber (2009) は根本的な問題の検討が必要と指摘している． — 参考文献5 pp.174 ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2019/ 1月/03/leastSquares/","tags":"math","url":"posts/2019/ 1月/03/leastSquares/","title":"最小二乗法で始めるカーブフィッティング"},{"text":"LU 分解に関して初歩的な内容から網羅的にまとめた. ガウスの消去法 ガウスの消去法は, 前進消去による上三角行列の形成と後退代入の組み合わせのことをいい, その本質は行列の行基本変形, すなわち中学校で習う連立方程式の解法そのものである. 例えば, 何の芸もないが, 次の連立方程式 \\begin{eqnarray} \\begin{cases} x+2y&=&3 \\\\\\ 3x+4y&=&5 \\end{cases}\\leftrightarrow \\left(\\begin{array}{cc|c} 1 & 2 & 3 \\\\\\ 3 & 4 & 5 \\end{array}\\right)\\label{eq:sfour}\\tag{1} \\end{eqnarray} をガウスの消去法では次のようにして解くのであった. $$ \\left(\\begin{array}{cc|c} 1 & 2 & 3 \\\\\\ 3 & 4 & 5 \\end{array}\\right)\\to \\underbrace{ \\left(\\begin{array}{cc|c} \\overbrace{1}&#94;{\\times (-3)} & \\overbrace{2}&#94;{\\times (-3)} & \\overbrace{3}&#94;{\\times (-3)} \\\\\\ \\underline{3} & 4 & 5 \\end{array}\\right) }_{\\rm 前進消去}\\to \\left(\\begin{array}{cc|c} 1 & 2 & 3 \\\\\\ 0 & -2 & -4 \\end{array}\\right)\\to \\underbrace{ \\left(\\begin{array}{cc|c} 1 & \\underline{2} & 3 \\\\\\ \\overbrace{0}&#94;{\\times 1} & \\overbrace{-2}&#94;{\\times 1} & \\overbrace{-4}&#94;{\\times 1} \\end{array}\\right) }_{\\rm 後退代入} \\\\\\ \\to \\left(\\begin{array}{cc|c} 1 & 0 & -1 \\\\\\ 0 & -2 & -4 \\end{array}\\right) \\\\\\ \\therefore \\left(x,y\\right)=\\left(-1\\div 1,-4\\div (-2)\\right)=\\left(-1,2\\right) $$ この前進消去の操作は次のように行列の積で表現できる. $$ \\left(\\begin{array}{cc} 1 & 0 \\\\\\ -3 & 1 \\end{array}\\right) \\left(\\begin{array}{cc} 1 & 2 \\\\\\ 3 & 4 \\end{array}\\right)= \\left(\\begin{array}{cc} 1 & 2 \\\\\\ 0 & -2 \\end{array}\\right) $$ これを理解しておくと後述する LU 分解の理解に容易くなる. ここで, この時間計算量について, 一般の \\(n\\) 次線形連立方程式 \\(X\\boldsymbol{a}=\\boldsymbol{y}\\ {\\rm where}\\ X\\in\\mathbb{R}&#94;{n\\times n}, \\boldsymbol{a}\\in\\mathbb{R}&#94;{n\\times 1}, \\boldsymbol{y}\\in\\mathbb{R}&#94;{n\\times 1}\\) を用いて考えるする. $$\\left(\\begin{array}{ccccc} x_{11} & x_{12} & x_{13} & \\cdots & x_{1n} \\\\\\ x_{21} & x_{22} & x_{23} & \\cdots & x_{2n} \\\\\\ x_{31} & x_{32} & x_{33} & \\cdots & x_{3n} \\\\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\\ x_{n1} & x_{n2} & x_{n3} & \\cdots & x_{nn} \\end{array}\\right) \\left(\\begin{array}{c}a_1 \\\\\\ a_2 \\\\\\ a_3 \\\\\\ \\vdots \\\\\\ a_n\\end{array}\\right)= \\left(\\begin{array}{c}y_1 \\\\\\ y_2 \\\\\\ y_3 \\\\\\ \\vdots \\\\\\ y_n\\end{array}\\right) $$ まず前進消去の操作について考える. 前進消去では, \\(x_{11}\\) を使って残りの \\(x_{21}, x_{31}, \\cdots, x_{n1}\\) を掃き出していくのであった. ただし \\(x_{21}, x_{31}, \\cdots, x_{n1}\\) は必ず \\(0\\) となるのだから, これは実質の計算量として考える必要はないだろう. すると \\(x_{21}, x_{31}, \\cdots, x_{n1}\\) を掃きだすのに伴って, 実際の計算を要される部分というのは $$ \\begin{array}{cccc} x_{22} & x_{23} & \\cdots & x_{2n} \\\\\\ x_{32} & x_{33} & \\cdots & x_{3n} \\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\\ x_{n2} & x_{n3} & \\cdots & x_{nn} \\end{array} $$ の箇所であることがいえる. この部分の成分数は \\(\\left(n-1\\right)&#94;2\\) なので, 一回目の前進消去では \\(\\left(n-1\\right)&#94;2\\) 回の計算を行うことがわかる. 次に, 二回目の前進消去では \\(x_{22}\\) を使って, それと同列のそれよりも下の行の成分 \\(x_{32},\\cdots,x_{n2}\\) を先と同様に消していくわけだが, ここでも同様, \\(x_{32},\\cdots,x_{n2}\\) は必ず \\(0\\) なので, 実際に計算を行う部分は $$ \\begin{array}{ccc} x_{33} & \\cdots & x_{3n} \\\\\\ \\vdots & \\ddots & \\vdots \\\\\\ x_{n3} & \\cdots & x_{nn} \\end{array} $$ の箇所である. この部分の成分数は \\(\\left(n-2\\right)&#94;2\\) なので, 二回目の全身消去では \\(\\left(n-2\\right)&#94;2\\) 回の計算を行うことがわかる. これを繰り返すと, 計算を行う部分が残り一成分となるまで同様の計算回数がかかることがわかるから \\[\\left(n-1\\right)&#94;2+\\left(n-2\\right)&#94;2+\\cdots+2&#94;2+1&#94;2 =\\sum&#94;{n}_{i=1}\\left(i-1\\right)&#94;2\\] ここで, 高校数学の教科書にも載っている定理(証明略) \\(\\sum&#94;n_{j=1}j&#94;2=\\frac{n\\left(n+1\\right)\\left(2n+1\\right)}{6}\\) を思い出せば, 先の式は \\(\\sum&#94;n_{i=1}\\left(i-1\\right)&#94;2=\\frac{n&#94;3}{3}+n&#94;2\\) と表せることがわかる. 続いて, 後退代入について考える. 後退代入は, 上三角行列となっている係数行列に対して代入を繰り返し, 対角行列を形成していく操作であった. $$\\left(\\begin{array}{ccccc} x_{11} & x_{12} & x_{13} & \\cdots & x_{1n} \\\\\\ & x_{22} & x_{23} & \\cdots & x_{2n} \\\\\\ & & x_{33} & \\cdots & x_{3n} \\\\\\ & & & \\ddots & \\vdots \\\\\\ &&&& x_{nn} \\end{array}\\right) \\left(\\begin{array}{c}a_1 \\\\\\ a_2 \\\\\\ a_3 \\\\\\ \\vdots \\\\\\ a_n\\end{array}\\right)= \\left(\\begin{array}{c}y_1 \\\\\\ y_2 \\\\\\ y_3 \\\\\\ \\vdots \\\\\\ y_n\\end{array}\\right) $$ この場合, まず \\(x_{nn}\\) を使って, \\(x_{1n},x_{2n},x_{3n},\\cdots,x_{\\left(n-1\\right)n}\\) を消していくわけだが, この際, 係数行列に対する操作というのはただ \\(0\\) にしていくということだけである. これを \\(x_{22}\\) まで繰り返し行うわけだが, その間の係数行列に関する操作はただ \\(0\\) にしていくということだけなので, これを計算量に含む必要はない. 実際に計算が発生するのは, 右辺ベクトルの部分である. まず \\(y_n\\) に対する計算は, 後退代入の操作を考えれば, 当然なにもする必要はない. 次に \\(y_{n-1}\\) に対する計算は \\(\\left(y_{n-1}\\right)'=y_{n-1}-\\frac{x_{\\left(n-1\\right)n}}{x_{nn}}y_n\\) であり, 減算, 除算, 積算が各一回ずつ行われることがいえる. 次の \\(y_{n-2}\\) に対する計算も同様 \\(y_{n-2}-\\frac{x_{\\left(n-2\\right)n}}{x_{\\left(n-1\\right)n}}\\left(y_{n-1}\\right)'\\) であり, 計算の形式は先と全く同じであるが, その前の後退代入の結果 \\(\\left(y_{n-1}\\right)'\\) を用いている点で計算量は異なる. つまり, いま計算したい右辺ベクトルの成分を計算するのには, その一つ下の右辺ベクトルの成分に対する計算結果が必要となる(後退代入の操作そのもの)ことから, これが \\(y_1\\) にまで及ぶことを考えると, 後退代入の総回数は \\[1+2+\\cdots+\\left(n-1\\right)=\\frac{n\\left(n-1\\right)}{2}\\] とかける(右辺への式変形の証明は高校数学の教科書で扱われているので略). ガウスの消去法は前進消去と後退代入の組み合わせであるので, その時間計算量は, \\[O\\left(\\frac{n&#94;3}{3}+\\frac{n\\left(n-1\\right)}{2}\\right)\\label{eq:sthird}\\tag{2}\\] ただし各項の中で最高次の係数だけを考えればよいので, ガウスの消去法の時間計算量は \\[\\frac{1}{3}O\\left(n&#94;3\\right)\\] である. ガウス・ジョルダン法 ガウスの名がつく行列を用いた線形方程式の直接解法には, 今述べたガウスの消去法のほかにガウス・ジョルダン法というものがある. これらは明確に区別されたところであまり意味がないような気もするが, ガウスの消去法が上記のように係数行列となる部分を単位行列でない対角行列へと変形していったのに対し, ガウス・ジョルダン法はそれを直接単位行列となるように変形していく点で異なる. ガウス・ジョルダン法で同様にして計算していくと, $$ \\left(\\begin{array}{cc|c} 1 & 2 & 3 \\\\\\ 3 & 4 & 5 \\end{array}\\right)\\to \\left(\\begin{array}{cc|c} \\overbrace{1}&#94;{\\times (-3)} & \\overbrace{2}&#94;{\\times (-3)} & \\overbrace{3}&#94;{\\times (-3)} \\\\\\ \\underline{3} & 4 & 5 \\end{array}\\right)\\to \\left(\\begin{array}{cc|c} 1 & 2 & 3 \\\\\\ 0 & -2 & -4 \\end{array}\\right)\\to \\left(\\begin{array}{cc|c} 1 & 2 & 3 \\\\\\ \\overbrace{0}&#94;{\\times \\left(-\\frac{1}{2}\\right)} & \\overbrace{-2}&#94;{\\times \\left(-\\frac{1}{2}\\right)} & \\overbrace{-4}&#94;{\\times \\left(-\\frac{1}{2}\\right)} \\end{array}\\right) \\\\\\ \\to \\left(\\begin{array}{cc|c} 1 & 2 & 3 \\\\\\ 0 & 1 & 2 \\end{array}\\right)\\to \\left(\\begin{array}{cc|c} 1 & \\underline{2} & 3 \\\\\\ \\overbrace{0}&#94;{\\times (-2)} & \\overbrace{1}&#94;{\\times (-2)} & \\overbrace{2}&#94;{\\times (-2)} \\end{array}\\right)\\to \\left(\\begin{array}{cc|c} 1 & 0 & -1 \\\\\\ 0 & 1 & 2 \\end{array}\\right) \\\\\\ \\therefore \\left(x,y\\right)=\\left(-1,2\\right) $$ これは掃き出し法とも言われることがある. ガウス・ジョルダン法の計算量は \\(\\frac{1}{2}O\\left(n&#94;3\\right)\\) なので(導出は省略), ガウス・ジョルダン法をわざわざ用いるシーンはあまりない. ピボッティング ところで, いま示したガウスの消去法, ガウスジョルダン法の手順は, このままでは困る場合がある. 例えば, 次の線形方程式をガウスの消去法で解いてみると $$ \\left(\\begin{array}{cccc|c} 1 & 2 & 7 & 6 & 6 \\\\\\ 2 & 4 & 4 & 2 & 2 \\\\\\ 1 & 8 & 5 & 2 & 12 \\\\\\ 2 & 4 & 3 & 3 & 5 \\end{array}\\right)\\to \\left(\\begin{array}{cccc|c} \\overbrace{1}&#94;{\\times (-2)} & \\overbrace{2}&#94;{\\times (-2)} & \\overbrace{7}&#94;{\\times (-2)} & \\overbrace{6}&#94;{\\times (-2)} & \\overbrace{6}&#94;{\\times (-2)} \\\\\\ \\underline{2} & 4 & 4 & 2 & 2 \\\\\\ 1 & 8 & 5 & 2 & 12 \\\\\\ 2 & 4 & 3 & 3 & 5 \\end{array}\\right)\\to \\left(\\begin{array}{cccc|c} 1 & 2 & 7 & 6 & 6 \\\\\\ 0 & 0 & -10 & -10 & -10 \\\\\\ 1 & 8 & 5 & 2 & 12 \\\\\\ 2 & 4 & 3 & 3 & 5 \\end{array}\\right) \\\\\\ \\to \\left(\\begin{array}{cccc|c} \\overbrace{1}&#94;{\\times (-1)} & \\overbrace{2}&#94;{\\times (-1)} & \\overbrace{7}&#94;{\\times (-1)} & \\overbrace{6}&#94;{\\times (-1)} & \\overbrace{6}&#94;{\\times (-1)} \\\\\\ 0 & 0 & -10 & -10 & -10 \\\\\\ \\underline{1} & 8 & 5 & 2 & 12 \\\\\\ 2 & 4 & 3 & 3 & 5 \\end{array}\\right)\\to \\left(\\begin{array}{cccc|c} 1 & 2 & 7 & 6 & 6 \\\\\\ 0 & 0 & -10 & -10 & -10 \\\\\\ 0 & 6 & -2 & -4 & 6 \\\\\\ 2 & 4 & 3 & 3 & 5 \\end{array}\\right)\\to \\left(\\begin{array}{cccc|c} \\overbrace{1}&#94;{\\times (-2)} & \\overbrace{2}&#94;{\\times (-2)} & \\overbrace{7}&#94;{\\times (-2)} & \\overbrace{6}&#94;{\\times (-2)} & \\overbrace{6}&#94;{\\times (-2)} \\\\\\ 0 & 0 & -10 & -10 & -10 \\\\\\ 0 & 6 & -2 & -4 & 6 \\\\\\ \\underline{2} & 4 & 3 & 3 & 5 \\end{array}\\right) \\\\\\ \\to \\left(\\begin{array}{cccc|c} 1 & 2 & 7 & 6 & 6 \\\\\\ 0 & 0 & -10 & -10 & -10 \\\\\\ 0 & 6 & -2 & -4 & 6 \\\\\\ 0 & 0 & -11 & -9 & -7 \\end{array}\\right)\\to \\left(\\begin{array}{cccc|c} 1 & 2 & 7 & 6 & 6 \\\\\\ 0 & \\overbrace{0}&#94;{\\times \\left(-\\frac{6}{0}\\right)} & \\overbrace{-10}&#94;{\\times \\left(-\\frac{6}{0}\\right)} & \\overbrace{-10}&#94;{\\times \\left(-\\frac{6}{0}\\right)} & \\overbrace{-10}&#94;{\\times \\left(-\\frac{6}{0}\\right)} \\\\\\ 0 & \\underline{6} & -2 & -4 & 6 \\\\\\ 0 & 0 & -11 & -9 & -7 \\end{array}\\right) $$ というように \\(0\\) で割るということが起きてしまうのである. これを防ぐために考えられる方法としては, 掃きだすのに利用する値がその列の中で絶対値最大となるように行を入れ替える. これは, 部分ピボット選択付きガウスの消去法といわれる. ピボットとは, いま述べた掃きだすのに利用する値のことである. 部分ピボット選択といわれる理由は, 入れ替えの操作が行に対してのみ行われるからである. 列に対する入れ替え操作をも含んだ方法は完全ピボット選択といわれるが, 当然それは行基本変形の範疇でないので, そのまま計算を続行して単に右辺ベクトルを取り出せばよいという話ではなくなる. 完全ピボット選択は, 絶対値最大の値の選択の余地が部分ピボット選択よりも当然広がるので, 直感的に, より大きな絶対値の値をピボットとして選択できる確率が上がることは考えられるだろう. しかしながら, このアドバンテージは当然行列に依存したものであり, プログラムの複雑度が上がることに釣り合っていないため, 実際に用いられるようなことはあまりないと思われる. というわけで, 下記に部分ピボット選択付きガウスの消去法による計算過程を省略することなく書き下したが, とくに面白みもない上に長いので隠しておいた. クリックで展開. $$ \\left(\\begin{array}{cccc|c} 1 & 2 & 7 & 6 & 6 \\\\\\ 2 & 4 & 4 & 2 & 2 \\\\\\ 1 & 8 & 5 & 2 & 12 \\\\\\ 2 & 4 & 3 & 3 & 5 \\end{array}\\right)\\to \\left(\\begin{array}{cccc|c} 2 & 4 & 4 & 2 & 2 \\\\\\ 1 & 2 & 7 & 6 & 6 \\\\\\ 1 & 8 & 5 & 2 & 12 \\\\\\ 2 & 4 & 3 & 3 & 5 \\end{array}\\right)\\to \\left(\\begin{array}{cccc|c} \\overbrace{2}&#94;{\\times\\left(-\\frac{1}{2}\\right)} & \\overbrace{4}&#94;{\\times\\left(-\\frac{1}{2}\\right)} & \\overbrace{4}&#94;{\\times\\left(-\\frac{1}{2}\\right)} & \\overbrace{2}&#94;{\\times\\left(-\\frac{1}{2}\\right)} & \\overbrace{2}&#94;{\\times\\left(-\\frac{1}{2}\\right)} \\\\\\ \\underline{1} & 2 & 7 & 6 & 6 \\\\\\ 1 & 8 & 5 & 2 & 12 \\\\\\ 2 & 4 & 3 & 3 & 5 \\end{array}\\right)\\\\\\ \\to \\left(\\begin{array}{cccc|c} 2 & 4 & 4 & 2 & 2 \\\\\\ 0 & 0 & 5 & 5 & 5 \\\\\\ 1 & 8 & 5 & 2 & 12 \\\\\\ 2 & 4 & 3 & 3 & 5 \\end{array}\\right)\\to \\left(\\begin{array}{cccc|c} \\overbrace{2}&#94;{\\times\\left(-\\frac{1}{2}\\right)} & \\overbrace{4}&#94;{\\times\\left(-\\frac{1}{2}\\right)} & \\overbrace{4}&#94;{\\times\\left(-\\frac{1}{2}\\right)} & \\overbrace{2}&#94;{\\times\\left(-\\frac{1}{2}\\right)} & \\overbrace{2}&#94;{\\times\\left(-\\frac{1}{2}\\right)} \\\\\\ 0 & 0 & 5 & 5 & 5 \\\\\\ \\underline{1} & 8 & 5 & 2 & 12 \\\\\\ 2 & 4 & 3 & 3 & 5 \\end{array}\\right)\\to \\left(\\begin{array}{cccc|c} 2 & 4 & 4 & 2 & 2 \\\\\\ 0 & 0 & 5 & 5 & 5 \\\\\\ 0 & 6 & 3 & 1 & 11 \\\\\\ 2 & 4 & 3 & 3 & 5 \\end{array}\\right)\\\\\\ \\to \\left(\\begin{array}{cccc|c} \\overbrace{2}&#94;{\\times (-1)} & \\overbrace{4}&#94;{\\times (-1)} & \\overbrace{4}&#94;{\\times (-1)} & \\overbrace{2}&#94;{\\times (-1)} & \\overbrace{2}&#94;{\\times (-1)} \\\\\\ 0 & 0 & 5 & 5 & 5 \\\\\\ 0 & 6 & 3 & 1 & 11 \\\\\\ \\underline{2} & 4 & 3 & 3 & 5 \\end{array}\\right)\\to \\left(\\begin{array}{cccc|c} 2 & 4 & 4 & 2 & 2 \\\\\\ 0 & 0 & 5 & 5 & 5 \\\\\\ 0 & 6 & 3 & 1 & 11 \\\\\\ 0 & 0 & -1 & 1 & 3 \\end{array}\\right)\\to \\left(\\begin{array}{cccc|c} 2 & 4 & 4 & 2 & 2 \\\\\\ 0 & 6 & 3 & 1 & 11 \\\\\\ 0 & 0 & 5 & 5 & 5 \\\\\\ 0 & 0 & -1 & 1 & 3 \\end{array}\\right) \\\\\\ \\to \\left(\\begin{array}{cccc|c} 2 & 4 & 4 & 2 & 2 \\\\\\ 0 & 6 & 3 & 1 & 11 \\\\\\ 0 & 0 & 5 & 5 & 5 \\\\\\ 0 & 0 & -1 & 1 & 3 \\end{array}\\right)\\to \\left(\\begin{array}{cccc|c} 2 & 4 & 4 & 2 & 2 \\\\\\ 0 & 6 & 3 & 1 & 11 \\\\\\ 0 & 0 & \\overbrace{5}&#94;{\\times\\frac{1}{5}} & \\overbrace{5}&#94;{\\times\\frac{1}{5}} & \\overbrace{5}&#94;{\\times\\frac{1}{5}} \\\\\\ 0 & 0 & \\underline{-1} & 1 & 3 \\end{array}\\right)\\to \\underbrace{\\left(\\begin{array}{cccc|c} 2 & 4 & 4 & 2 & 2 \\\\\\ 0 & 6 & 3 & 1 & 11 \\\\\\ 0 & 0 & 5 & 5 & 5 \\\\\\ 0 & 0 & 0 & 2 & 4 \\end{array}\\right)}_{上三角行列} \\\\\\ \\to \\left(\\begin{array}{cccc|c} 2 & 4 & 4 & \\underline{2} & 2 \\\\\\ 0 & 6 & 3 & 1 & 11 \\\\\\ 0 & 0 & 5 & 5 & 5 \\\\\\ 0 & 0 & 0 & \\overbrace{2}&#94;{\\times(-1)} & \\overbrace{4}&#94;{\\times(-1)} \\end{array}\\right) \\to \\left(\\begin{array}{cccc|c} 2 & 4 & 4 & 0 & -2 \\\\\\ 0 & 6 & 3 & 1 & 11 \\\\\\ 0 & 0 & 5 & 5 & 5 \\\\\\ 0 & 0 & 0 & 2 & 4 \\end{array}\\right)\\to \\left(\\begin{array}{cccc|c} 2 & 4 & 4 & 0 & -2 \\\\\\ 0 & 6 & 3 & \\underline{1} & 11 \\\\\\ 0 & 0 & 5 & 5 & 5 \\\\\\ 0 & 0 & 0 & \\overbrace{2}&#94;{\\times \\left(-\\frac{1}{2}\\right)} & \\overbrace{4}&#94;{\\times \\left(-\\frac{1}{2}\\right)} \\end{array}\\right) \\\\\\ \\to \\left(\\begin{array}{cccc|c} 2 & 4 & 4 & 0 & -2 \\\\\\ 0 & 6 & 3 & 0 & 9 \\\\\\ 0 & 0 & 5 & 5 & 5 \\\\\\ 0 & 0 & 0 & 2 & 4 \\end{array}\\right)\\to \\left(\\begin{array}{cccc|c} 2 & 4 & 4 & 0 & -2 \\\\\\ 0 & 6 & 3 & 0 & 9 \\\\\\ 0 & 0 & 5 & \\underline{5} & 5 \\\\\\ 0 & 0 & 0 & \\overbrace{2}&#94;{\\times \\left(-\\frac{5}{2}\\right)} & \\overbrace{4}&#94;{\\times \\left(-\\frac{5}{2}\\right)} \\end{array}\\right)\\to \\left(\\begin{array}{cccc|c} 2 & 4 & 4 & 0 & -2 \\\\\\ 0 & 6 & 3 & 0 & 9 \\\\\\ 0 & 0 & 5 & 0 & -5 \\\\\\ 0 & 0 & 0 & 2 & 4 \\end{array}\\right) \\\\\\ \\to \\left(\\begin{array}{cccc|c} 2 & 4 & \\underline{4} & 0 & -2 \\\\\\ 0 & 6 & 3 & 0 & 9 \\\\\\ 0 & 0 & \\overbrace{5}&#94;{\\times \\left(-\\frac{4}{5}\\right)} & \\overbrace{0}&#94;{\\times \\left(-\\frac{4}{5}\\right)} & \\overbrace{-5}&#94;{\\times \\left(-\\frac{4}{5}\\right)} \\\\\\ 0 & 0 & 0 & 2 & 4 \\end{array}\\right) \\to \\left(\\begin{array}{cccc|c} 2 & 4 & 0 & 0 & 2 \\\\\\ 0 & 6 & 3 & 0 & 9 \\\\\\ 0 & 0 & 5 & 0 & -5 \\\\\\ 0 & 0 & 0 & 2 & 4 \\end{array}\\right) \\to \\left(\\begin{array}{cccc|c} 2 & 4 & 0 & 0 & 2 \\\\\\ 0 & 6 & \\underline{3} & 0 & 9 \\\\\\ 0 & 0 & \\overbrace{5}&#94;{\\times \\left(-\\frac{3}{5}\\right)} & \\overbrace{0}&#94;{\\times \\left(-\\frac{3}{5}\\right)} & \\overbrace{-5}&#94;{\\times \\left(-\\frac{3}{5}\\right)} \\\\\\ 0 & 0 & 0 & 2 & 4 \\end{array}\\right) \\\\\\ \\to \\left(\\begin{array}{cccc|c} 2 & 4 & 0 & 0 & 2 \\\\\\ 0 & 6 & 0 & 0 & 12 \\\\\\ 0 & 0 & 5 & 0 & -5 \\\\\\ 0 & 0 & 0 & 2 & 4 \\end{array}\\right) \\to \\left(\\begin{array}{cccc|c} 2 & \\underline{4} & 0 & 0 & 2 \\\\\\ 0 & \\overbrace{6}&#94;{\\times\\left(-\\frac{2}{3}\\right)} & \\overbrace{0}&#94;{\\times\\left(-\\frac{2}{3}\\right)} & \\overbrace{0}&#94;{\\times\\left(-\\frac{2}{3}\\right)} & \\overbrace{12}&#94;{\\times\\left(-\\frac{2}{3}\\right)} \\\\\\ 0 & 0 & 5 & 0 & -5 \\\\\\ 0 & 0 & 0 & 2 & 4 \\end{array}\\right) \\to \\left(\\begin{array}{cccc|c} 2 & 0 & 0 & 0 & -6 \\\\\\ 0 & 6 & 0 & 0 & 12 \\\\\\ 0 & 0 & 5 & 0 & -5 \\\\\\ 0 & 0 & 0 & 2 & 4 \\end{array}\\right) \\\\\\ \\therefore \\left(-6\\div 2,12\\div 6, -5\\div 0, 4\\div 2\\right)&#94;T =\\left(-3,2,-1,2\\right)&#94;T $$ LU 分解 漸く本題の LU 分解( LR 分解, 三角分解)について. 簡単のために式 \\(\\eqref{eq:sfour}\\) を使って LU 分解の導出をする. 式 \\(\\eqref{eq:sfour}\\) は次の式と同値である. $$ A&#94;{(0)}\\left(\\begin{array}{c}x \\\\\\ y\\end{array}\\right)=\\boldsymbol{v} \\ {\\rm where}\\ A&#94;{(0)}=\\left(\\begin{array}{cc}1 & 2 \\\\\\ 3 & 4\\end{array}\\right),\\boldsymbol{v}=\\left(\\begin{array}{c}3\\\\\\ 5\\end{array}\\right) $$ \\({A&#94;{(0)}}&#94;{-1}\\boldsymbol{v}\\) とすれば \\(\\left(x,y\\right)&#94;T\\) は求まるが, 逆行列の計算はガウスの消去法により \\(\\frac{1}{3}O(n&#94;3)\\) の時間計算量がかかる. 一定の条件下でそれよりも高速に求める方法を考えることとする. いま \\(A&#94;{(0)}\\) を徐に上三角行列にすることを考えると, ガウスの消去法の前進消去より $$ A&#94;{(1)}=L&#94;{(1)}A&#94;{(0)}=\\left(\\begin{array}{cc}1 & 2 \\\\\\ 0 & -2\\end{array}\\right) \\leftrightarrow A&#94;{(0)}={L&#94;{(1)}}&#94;{-1}A&#94;{(1)} \\ {\\rm where}\\ L&#94;{(1)}=\\left(\\begin{array}{cc}1 & 0 \\\\\\ -3 & 1\\end{array}\\right) $$ 従って $$ {L&#94;{(1)}}&#94;{-1}A&#94;{(1)}\\left(\\begin{array}{c}x \\\\\\ y\\end{array}\\right)=\\boldsymbol{v} $$ ここで, \\(\\boldsymbol{b}=A&#94;{(1)}\\left(x,y\\right)&#94;T\\) とおくと, 上の式は \\({L&#94;{(1)}}&#94;{-1}\\boldsymbol{b}=\\boldsymbol{v}\\) と同値であり, この式を用いて \\(\\boldsymbol{b}\\) について解くことができる. まずこの時間計算量を考えるとする. \\(L&#94;{(1)}\\) は元々前進消去のための行列であり, それは必ず下三角行列である. 正則な下三角行列の逆行列は下三角行列であり(証明略), いま \\(L&#94;{(1)}\\) が正則であるとする(これが特異となるような場合には後述する PLU 分解が有効)と, その計算は前進代入(上記後退代入の下三角行列バージョンと考えればよい)を実行すればよいので, 時間計算量は \\(\\frac{1}{2}O\\left(n&#94;2\\right)\\ \\because\\eqref{eq:sthird}\\) となる. その後に \\(A&#94;{(1)}\\left(x,y\\right)&#94;T=\\boldsymbol{b}\\) を \\(\\left(x,y\\right)&#94;T\\) について解くわけであるが, \\(A&#94;{(1)}\\) は上三角行列であるので, その計算にはガウスの消去法の後退代入を実行すれば良く, 従ってその時間計算量は \\(\\frac{1}{2}O\\left(n&#94;2\\right)\\ \\because\\eqref{eq:sthird}\\) である. よって, この一連の操作における時間計算量は \\(\\frac{1}{3}O\\left(n&#94;3\\right)\\) であり, 部分ピボットつきガウスの消去法を実行した場合と変わらない. しかし, \\(L U\\) を流用できる(つまり, 共通の \\(A&#94;{(0)}\\) に対し異なる右辺ベクトル \\(\\boldsymbol{v}\\) から成る連立方程式を解く)とすればどうだろう. この場合, やらなければならない計算は前進代入および後退代入のみなので, 全体の時間計算量は \\(\\frac{1}{2}O\\left(n&#94;2\\right)\\) となり, 先よりも高速に解を得ることができる. いまの説明では, 式 \\(\\eqref{eq:sfour}\\) において \\(A&#94;{(0)}\\) を \\({L&#94;{(1)}}&#94;{-1}\\) と \\(A&#94;{(1)}\\) に分解したが, これを LU 分解(\\(L={L&#94;{(1)}}&#94;{-1},U=A&#94;{(1)}\\))といい, \\(L&#94;{(i)}\\) が正則ならば, 一般の場合においても同様にしていうことができる. LU 分解(外積形式ガウス法) すべての前進消去の行列 \\(L&#94;{(i)}\\) が正則ならば \\(A\\in\\mathbb{R}&#94;{m\\times n}\\) に対する LU 分解は \\[A=A&#94;{(0)}=L U\\ {\\rm where}\\ L=\\prod_{i=1}&#94;{n-1}{L&#94;{(i)}}&#94;{-1}, U=A&#94;{(n-1)}\\] 補足すると, \\(A&#94;{(0)}\\) に対し \\(n-1\\) 回の前進消去をするというのは, \\(L&#94;{(n-1)}\\cdots L&#94;{(2)}L&#94;{(1)}A&#94;{(0)}\\) ということであり, \\(\\lambda=L&#94;{(n-1)}\\cdots L&#94;{(2)}L&#94;{(1)}\\) とおくと \\(\\lambda A&#94;{(0)}=U=A&#94;{(n-1)}\\) だから \\(A&#94;{(0)}=\\lambda&#94;{-1}U\\). ここで逆行列の公式 \\(\\left(X Y\\right)&#94;{-1}=Y&#94;{-1} X&#94;{-1}\\) より(証明略)上式となる. 一般論を得たところで, 実際に一つ LU 分解を実践してみることとする. $$ A&#94;{(0)}= \\left(\\begin{array}{ccc} 3 & 1 & 0 \\\\\\ 6 & 1 & -2 \\\\\\ -3 & 0 & 3 \\end{array}\\right)\\to \\underbrace{\\left(\\begin{array}{ccc} 1 & 0 & 0 \\\\\\ -2 & 1 & 0 \\\\\\ 1 & 0 & 1 \\end{array}\\right)}_{L&#94;{(1)}} \\left(\\begin{array}{ccc} 3 & 1 & 0 \\\\\\ 6 & 1 & -2 \\\\\\ -3 & 0 & 3 \\end{array}\\right)= \\underbrace{ \\left(\\begin{array}{ccc} 3 & 1 & 0 \\\\\\ 0 & -1 & -2 \\\\\\ 0 & 1 & 3 \\end{array}\\right) }_{A&#94;{(1)}} \\\\\\ \\to \\underbrace{ \\left(\\begin{array}{ccc} 1 & 0 & 0 \\\\\\ 0 & 1 & 0 \\\\\\ 0 & 1 & 1 \\end{array}\\right) }_{L&#94;{(2)}} A&#94;{(1)}= \\underbrace{ \\left(\\begin{array}{ccc} 3 & 1 & 0 \\\\\\ 0 & -1 & -2 \\\\\\ 0 & 0 & 1 \\end{array}\\right)}_{A&#94;{(2)}} $$ より $$L=\\left(L&#94;{(2)}L&#94;{(1)}\\right)&#94;{-1}=\\left(\\begin{array}{ccc} 1 & 0 & 0 \\\\\\ 2 & 1 & 0 \\\\\\ -1 & -1 & 1 \\end{array}\\right),U=A&#94;{(2)}$$ 実際には, すべてを減算で考えることで, \\(\\left(L&#94;{(2)}L&#94;{(1)}\\right)&#94;{-1}\\) の計算は楽に済む(つまり \\(A&#94;{0}=\\left(\\boldsymbol{a_1}&#94;T,\\boldsymbol{a_2}&#94;T,\\boldsymbol{a_3}&#94;T\\right)&#94;T\\) としたとき \\(\\underline{2}\\boldsymbol{a_1}-\\boldsymbol{a_2}, \\underline{-1}\\boldsymbol{a_1}-\\boldsymbol{a_3}, \\underline{-1}\\boldsymbol{a_2}-\\boldsymbol{a_3}\\) より \\(L\\) が導けるということ). この導出過程を見ればなんとなく LU 分解が一意となることは直感的にも納得できるが, 一応証明を与えておく. 定理 1 LU 分解された \\(L,U\\) は一意に決まる 証明 : 正則行列 \\(A\\) の LU 分解 \\(A= L U\\) に対して \\(A= L_{1}U_{1} = L_{2}U_{2} \\leftrightarrow L_{2}&#94;{-1}L_{1} = U_{2}U_{1}&#94;{-1}\\) とおく. \\(L\\) は元々下三角行列であり下三角行列の逆行列は下三角行列, また下三角行列の積は下三角行列だから \\(L_{2}&#94;{-1}L_{1}\\) は下三角行列である. \\(U\\) は元々上三角行列であり上三角行列の逆行列は上三角行列, また上三角行列の積は上三角行列だから \\(U_{2}U_{1}&#94;{-1}\\) は上三角行列である. 従って, 両行列は上および下三角行列でなければならず, それを満たす唯一の行列は対角行列であり, \\(L\\) の対角成分は元々 \\(1\\) であるから \\(L_{2}&#94;{-1}L_{1} = I = U_{2}U_{1}&#94;{-1}\\). 故に \\(L_{2}=L_{1}, U_{2}=U_{1}\\). \\(\\square\\) 次に, 次のような行列に対する LU 分解を考えてみる. \\begin{eqnarray} A=\\left(\\begin{array}{ccc} 0 & 1 & 0 \\\\\\ -8 & 8 & 1 \\\\\\ 2 & -2 & 0 \\end{array}\\right) \\end{eqnarray} 見てわかるように, 前進消去の段階で \\(-8\\div 0\\) となってしまい計算できない. しかし, これも部分ピボット選択付きガウスの消去法と同様に, 絶対値最大の値がピボットとなるように行を予め入れ替えておけば, 計算が続行できる. そのような手続きのある LU 分解は PLU 分解といわれ, 置換行列 \\(P\\in\\mathbb{R}&#94;{m\\times n}\\) をつかって, \\(A=P L U\\) とする. 以下 \\(A\\) をつかって導出してみることとする. \\(\\boldsymbol{a_1}&#94;T\\) と \\(\\boldsymbol{a_2}&#94;T\\) を入れ替えれば良いので, \\begin{eqnarray} \\underbrace{\\left(\\begin{array}{ccc} 0 & 1 & 0 \\\\\\ 1 & 0 & 0 \\\\\\ 0 & 0 & 1 \\end{array}\\right)}_{P&#94;{(1)}}A= \\underbrace{\\left(\\begin{array}{ccc} -8 & 8 & 1 \\\\\\ 0 & 1 & 0 \\\\\\ 2 & -2 & 0 \\end{array}\\right)}_{A'}\\to \\underbrace{\\left(\\begin{array}{ccc} 1 & 0 & 0 \\\\\\ 0 & 1 & 0 \\\\\\ \\frac{1}{4} & 0 & 1 \\end{array}\\right)}_{L&#94;{(1)}}A'= \\underbrace{\\left(\\begin{array}{ccc} -8 & 8 & 1 \\\\\\ 0 & 1 & 0 \\\\\\ 0 & 0 & \\frac{1}{4} \\end{array}\\right)}_{A'&#94;{(1)}} \\end{eqnarray} より $$L = {L&#94;{(1)}}&#94;{-1}=\\left(\\begin{array}{ccc}1 & 0 & 0 \\\\\\ 0 & 1 & 0 \\\\\\ -\\frac{1}{4} & 0 & 1\\end{array}\\right),U={A'}&#94;{(1)}$$ とおくと \\(A'={L&#94;{(1)}}&#94;{-1}{A'}&#94;{(1)}\\) だから $$P&#94;{(1)}A=L U$$ \\(P&#94;{(1)}\\) は元々置換行列であるから正則であり, また直行行列でもある. すなわち \\({P=P&#94;{(1)}}&#94;{-1}={P&#94;{(1)}}&#94;T\\) とおけて \\begin{eqnarray} A&=&P L U\\\\\\ \\left(\\begin{array}{ccc} 0 & 1 & 0 \\\\\\ -8 & 8 & 1 \\\\\\ 2 & -2 & 0 \\end{array}\\right)&=& \\left(\\begin{array}{ccc} 0 & 1 & 0 \\\\\\ 1 & 0 & 0 \\\\\\ 0 & 0 & 1 \\end{array}\\right) \\left(\\begin{array}{ccc} 1 & 0 & 0 \\\\\\ 0 & 1 & 0 \\\\\\ -\\frac{1}{4} & 0 & 1 \\end{array}\\right) \\left(\\begin{array}{ccc} -8 & 8 & 1 \\\\\\ 0 & 1 & 0 \\\\\\ 0 & 0 & \\frac{1}{4} \\end{array}\\right) \\end{eqnarray} ここで \\(\\boldsymbol{a}\\in\\mathbb{R}&#94;{n\\times 1},\\boldsymbol{v}\\in\\mathbb{R}&#94;{n\\times 1}\\) に対して \\(P L U \\boldsymbol{a}=\\boldsymbol{v}\\) というように, PLU 分解を用いて連立方程式解くことを考えると, \\(L\\underbrace{\\left(U\\boldsymbol{a}\\right)}_{\\boldsymbol{b}}=P&#94;{-1}\\boldsymbol{v}\\) だから先と同様にまず前進代入によって \\(\\boldsymbol{b}\\) を求め(このときの \\(P&#94;{-1}\\boldsymbol{v}\\) は \\(P&#94;{-1}=P&#94;{(1)}\\) であり, また置換行列であるので, その計算は単に \\(\\boldsymbol{v}\\) を並び替えるだけである), \\(U\\boldsymbol{a}=\\boldsymbol{b}\\) を \\(\\boldsymbol{a}\\) について後退代入によって求めればよい. さて, 数学的な言葉では, 以上のように書き下すことで十分であるが, これをプログラムで組むことを考えると, 様々な工夫やアプローチが考えられる. まず \\(L, U\\) はそれぞれ必ず上三角行列, 下三角行列であり \\(0\\) や \\(1\\) の部分をそのまま持っているのは無駄である. 従って \\(L, U\\) の値は次のように一つの行列として持っておけば十分. $$ \\left(\\begin{array}{ccc} -8 & 8 & 1 \\\\\\ 0 & 1 & 0 \\\\\\ -\\frac{1}{4} & 0 & \\frac{1}{4} \\end{array}\\right) $$ また, 置換行列 \\(P\\) はただの並び替えでなので, これも各インデックスへの対応関係をテーブルにでもしておけば十分. サンプル実装, 実行例を下記に示す. Haskell で書いたわけだが, 普通の ST モナドによる実装とリストによる実装をそれぞれ行った. クリックで実装を開く. λ > : m Data . Array Math . Matrix . LU λ > lu [[ 0 , 1 , 0 ],[ - 8 , 8 , 1 ],[ 2 , - 2 , 0 ]] :: Maybe ( PLU Array Int Double ) Just ( array ( 0 , 2 ) [( 0 , 1 ),( 1 , 0 ),( 2 , 2 )], { - 8.0 8.0 1.0 } { - 0.0 1.0 0.0 } { - 0.25 0.0 0.25 } ) λ > luST' [[ 0 , 1 , 0 ],[ - 8 , 8 , 1 ],[ 2 , - 2 , 0 ]] :: Maybe ( PLU Array Int Double ) Just ( array ( 0 , 2 ) [( 0 , 1 ),( 1 , 0 ),( 2 , 2 )], { - 8.0 8.0 1.0 } { - 0.0 1.0 0.0 } { - 0.25 0.0 0.25 } ) 連立方程式を解く. クリックで実装を開く. λ > resolveLinearEq' [[ 1 , 2 , 7 , 6 ],[ 2 , 4 , 4 , 2 ],[ 1 , 8 , 5 , 2 ],[ 2 , 4 , 3 , 3 ]] [ 6 , 2 , 12 , 5 ] :: Maybe ( Array Int Rational ) Just ( array ( 0 , 3 ) [( 0 ,( - 3 ) % 1 ),( 1 , 2 % 1 ),( 2 ,( - 1 ) % 1 ),( 3 , 2 % 1 )]) λ > plu = luST' [[ 1 , 2 , 7 , 6 ],[ 2 , 4 , 4 , 2 ],[ 1 , 8 , 5 , 2 ],[ 2 , 4 , 3 , 3 ]] :: Maybe ( PLU Array Int Double ) λ > plu Just ( array ( 0 , 3 ) [( 0 , 1 ),( 1 , 2 ),( 2 , 0 ),( 3 , 3 )], { 2.0 4.0 4.0 2.0 } { 0.5 6.0 3.0 1.0 } { 0.5 0.0 5.0 5.0 } { 1.0 0.0 - 0.2 2.0 } ) λ > fromJust plu ` assign ` ( listArray ( 0 , 3 ) [ 6 , 2 , 12 , 5 ]) :: Maybe ( Array Int Double ) Just ( array ( 0 , 3 ) [( 0 , - 3.0 ),( 1 , 2.0 ),( 2 , - 1.0 ),( 3 , 2.0 )]) λ > fromJust plu ` assign ` ( listArray ( 0 , 3 ) [ 1 , 2 , 3 , 4 ]) :: Maybe ( Array Int Double ) Just ( array ( 0 , 3 ) [( 0 , 0.6666666666666667 ),( 1 , 0.6666666666666666 ),( 2 , - 1.0 ),( 3 , 1.0 )]) λ > fromJust plu ` assign ` ( listArray ( 0 , 3 ) [ 5 , 6 , 7 , 8 ]) :: Maybe ( Array Int Double ) Just ( array ( 0 , 3 ) [( 0 , 1.666666666666667 ),( 1 , 0.8666666666666667 ),( 2 , - 0.8 ),( 3 , 1.2 )]) ところで, LU 分解をしておくと逆行列も簡単に求めることがすぐに示せる. 逆行列とはそもそも \\(A A&#94;{-1} =I\\) であり, \\(A&#94;{-1}=\\left(\\boldsymbol{a&#94;{-1}_1},\\boldsymbol{a&#94;{-1}_2},\\cdots,\\boldsymbol{a&#94;{-1}}_m\\right), I=\\left(\\boldsymbol{I_1},\\boldsymbol{I_2},\\cdots,\\boldsymbol{I_m}\\right)\\) とすると行列の積の定義より \\(A \\boldsymbol{a&#94;{-1}_i}=\\boldsymbol{I_i}\\ {\\rm where\\ } i\\in\\mathbb{Z}&#94;{+}, 1\\leq i\\leq m\\) だから, \\(A=L U\\) と分解して \\(1\\) から \\(m\\) までのすべての \\(\\boldsymbol{a&#94;{-1}}_i\\) を得てそれらをそのまま 1 つの行列とすればよい. 当然ながら, 構成される方程式のうち変わる部分は \\(\\boldsymbol{a&#94;{-1}}_i\\) と \\(I_i\\) の部分だけなので, LU 分解は一度行うだけで済む. プログラムでの実行例. クリックで実装を開く. λ > inverse' [[ 3 , 1 , 1 ],[ 5 , 1 , 3 ],[ 2 , 0 , 1 ]] :: Maybe ( Matrix Array Int Rational ) Just { 1 % 2 ( - 1 ) % 2 1 % 1 } { 1 % 2 1 % 2 ( - 2 ) % 1 } { ( - 1 ) % 1 1 % 1 ( - 1 ) % 1 } ただし, 逆行列の計算には今述べたようにすべての \\(\\boldsymbol{I&#94;{-1}}_i\\) に関して代入操作を行わなければならないので, \\(A\\boldsymbol{x}=\\boldsymbol{v}\\) といった方程式を解く目的で逆行列 \\(A&#94;{-1}\\) を求めることはただの愚行である. また, LU 分解は行列式の計算も簡単にする. \\(A= L U\\) ならば積の行列式は行列式の積(証明略)なので \\(\\left|A\\right|=\\left|L U\\right|=\\left|L\\right|\\left|U\\right|\\) であるが, 上および下三角行列の行列式は対角成分の積(証明略)であるので \\(\\left|L\\right|=1\\) である. よって \\(\\left|A\\right|=\\prod_{i=1}&#94;{n}\\boldsymbol{u}_{ii}\\) である. 置換行列 \\(P\\) を考慮すれば, いま \\(S\\) を LU 分解の過程で行の入れ替えを行った回数としたとき, \\(\\left|A\\right|=\\left|P\\right|\\left|L\\right|\\left|U\\right|=(-1)&#94;S \\prod_{i=1}&#94;{n}\\boldsymbol{u}_{ii}\\) となる. また, 後述する Crout 法では \\(U\\) のすべての対角成分を \\(1\\) とするので, その場合 \\(\\left|A\\right| = (-1)&#94;S \\prod_{i=1}&#94;{n}\\boldsymbol{l}_{ii}\\) となる. クリックで実装を開く. λ > determinant $ toMat $ listArray (( 0 , 0 ),( 2 , 2 )) [ 3 , 1 , 1 , 5 , 1 , 3 , 2 , 0 , 1 ] 2.0 λ > determinant $ toMat $ listArray (( 0 , 0 ),( 3 , 3 )) [ 1 , 2 , 7 , 6 , 2 , 4 , 4 , 2 , 1 , 8 , 5 , 2 , 2 , 4 , 3 , 3 ] 120.0 なお, LU 分解は LDU 分解ともいわれることがある. その場合, 上記の \\(U\\) に含まれる対角成分を対角行列 \\(D\\) に分離して \\(A = L D U\\) とする. $$ L D U= \\left(\\begin{array}{cccc} 1 & 0 & \\cdots & 0 \\\\\\ l_{21} & 1 & \\cdots & 0 \\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\\ l_{m1} & l_{m2} & \\cdots & 1 \\end{array}\\right) \\mathrm{diag}\\left(d_1,\\cdots,d_m\\right) \\left(\\begin{array}{cccc} 1 & u_{12} & \\cdots & u_{1n} \\\\\\ 0 & 1 & \\cdots & u_{2n} \\\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\\ 0 & 0 & \\cdots & 1 \\end{array}\\right) $$ ところで, \\(A\\in\\mathbb{R}&#94;{m\\times n}\\) が対称行列ならば, この LDU 分解は \\(A=L D L&#94;{T}\\) と計算することができる. 定理 2 \\(A=A&#94;T\\ {\\rm where}\\ A\\in\\mathbb{R}&#94;{m\\times n}\\) ならば \\(A\\) の LDU 分解は \\(A=L D L&#94;{T}\\) 証明 : \\(M&#94;T = D&#94;{-1}U\\) とし \\(A\\) の LDU 分解を \\(A= L D M&#94;T\\) とおくと \\[A = A&#94;T = \\left(L D M&#94;T\\right)&#94;T = M D L&#94;T = L U\\] ここで, 第二辺から第三辺への変形は, 積の転置は積の左右を入れ替えた転置の積なる公式を用いた. このとき \\(M\\left(D L&#94;T\\right)\\) と \\(L U\\) は LU 分解の 2 つの表現であるが, 定理 1 より LU 分解は一意であるから \\(M=L\\) でなければならない(後述する Crout 法の LU 分解ならば \\(M=L D\\) でなければならない. 導かれる結論は同じ). 従って \\(L D M&#94;T = L D L&#94;T\\). \\(\\square\\) ここまで述べてきた LU 分解の方法は, 外積形式ガウス法といわれるものであるが, LU 分解の他の方法として内積形式ガウス法(以下 Doolittle 法), クラウト法がある. 簡単のために \\(n=3\\) として, 行列 \\(X\\) を次のように下三角行列 \\(L\\in\\mathbb{R}&#94;{3\\times 3}\\) と上三角行列 \\(U\\in\\mathbb{R}&#94;{3\\times 3}\\) に分解することを考える. このとき \\(X = L' D U'\\) に対して \\(L = L' D\\) とおいて \\(X = L U'\\) というように分解できることを過程して行列 \\(L,U'\\) を導出することを Doolittle 法, また \\(U=D U'\\) とおいて \\(X = L' U\\) というように分解できることを過程して行列 \\(L' U\\) を導出することを Crout 法という. \\begin{eqnarray} X= L U'\\leftrightarrow \\left(\\begin{array}{ccc} x_{11} & x_{12} & x_{13} \\\\\\ x_{21} & x_{22} & x_{23} \\\\\\ x_{31} & x_{32} & x_{33} \\end{array}\\right)=\\left(\\begin{array}{ccc} 1 & 0 & 0 \\\\\\ l_{21} & 1 & 0 \\\\\\ l_{31} & l_{32} & 1 \\end{array}\\right)\\left(\\begin{array}{ccc} u_{11} & u_{12} & u_{13} \\\\\\ 0 & u_{22} & u_{23} \\\\\\ 0 & 0 & u_{33} \\end{array}\\right)&:=&{\\rm Doolittle\\ 法} \\\\\\ X= L' U\\leftrightarrow \\left(\\begin{array}{ccc} x_{11} & x_{12} & x_{13} \\\\\\ x_{21} & x_{22} & x_{23} \\\\\\ x_{31} & x_{32} & x_{33} \\end{array}\\right)=\\left(\\begin{array}{ccc} l_{11} & 0 & 0 \\\\\\ l_{21} & l_{22} & 0 \\\\\\ l_{31} & l_{32} & l_{33} \\end{array}\\right)\\left(\\begin{array}{ccc} 1 & u_{12} & u_{13} \\\\\\ 0 & 1 & u_{23} \\\\\\ 0 & 0 & 1 \\end{array}\\right)&:=&{\\rm Crout\\ 法} \\end{eqnarray} いま行列 \\(X\\) を Doolittle 法により LU 分解できたならば \\(L U'\\) を単に計算して \\(X=L U'\\) は次のようにかけるはずである. $$ \\left(\\begin{array}{ccc} u_{11} & u_{12} & u_{13} \\\\\\ l_{21}u_{11} & l_{21}u_{12}+u_{22} & l_{21}u_{13}+u_{23} \\\\\\ l_{31}u_{11} & l_{31}u_{12}+l_{32}u_{22} & l_{31}u_{13}+l_{32}u_{23}+u_{33} \\end{array}\\right)= \\left(\\begin{array}{ccc} 1 & 0 & 0 \\\\\\ l_{21} & 1 & 0 \\\\\\ l_{31} & l_{32} & 1 \\end{array}\\right)\\left(\\begin{array}{ccc} u_{11} & u_{12} & u_{13} \\\\\\ 0 & u_{22} & u_{23} \\\\\\ 0 & 0 & u_{33} \\end{array}\\right) $$ よって, 行列 \\(X\\) の成分で行列 \\(L, U'\\) を次のように書き換えることができる. \\begin{eqnarray} \\left(\\begin{array}{ccc} x_{11} & x_{12} & x_{13} \\\\\\ x_{21} & x_{22} & x_{23} \\\\\\ x_{31} & x_{32} & x_{33} \\end{array}\\right)&=& \\left(\\begin{array}{ccc} 1 & 0 & 0 \\\\\\ \\frac{x_{21}}{u_{11}} & 1 & 0 \\\\\\ \\frac{x_{31}}{u_{11}} & l_{32} & 1 \\end{array}\\right) \\left(\\begin{array}{ccc} u_{11} & u_{12} & u_{13} \\\\\\ 0 & u_{22} & u_{23} \\\\\\ 0 & 0 & u_{33} \\end{array}\\right)\\because \\begin{array}{l} x_{21}=l_{21}u_{11}\\leftrightarrow l_{21}=\\frac{x_{21}}{u_{11}}, \\\\\\ l_{31}\\ {\\rm についても同様} \\end{array} \\\\\\ &=& \\left(\\begin{array}{ccc} 1 & 0 & 0 \\\\\\ \\frac{x_{21}}{x_{11}} & 1 & 0 \\\\\\ \\frac{x_{31}}{x_{11}} & l_{32} & 1 \\end{array}\\right)\\left(\\begin{array}{ccc} x_{11} & x_{12} & x_{13} \\\\\\ 0 & u_{22} & u_{23} \\\\\\ 0 & 0 & u_{33} \\end{array}\\right)\\because\\ u_{11}=x_{11},u_{12}=x_{12},u_{13}=x_{13} \\\\\\ &=& \\left(\\begin{array}{ccc} 1 & 0 & 0 \\\\\\ \\frac{x_{21}}{x_{11}} & 1 & 0 \\\\\\ \\frac{x_{31}}{x_{11}} & l_{32} & 1 \\end{array}\\right)\\left(\\begin{array}{ccc} x_{11} & x_{12} & x_{13} \\\\\\ 0 & x_{22}-\\frac{x_{21}}{x_{11}}x_{12} & x_{23}-\\frac{x_{21}}{x_{11}}x_{13} \\\\\\ 0 & 0 & u_{33} \\end{array}\\right)\\because \\begin{array}{l} x_{22}=l_{21}u_{12}+u_{22} \\leftrightarrow u_{22}=x_{22}-l_{21}u_{12},\\\\\\ u_{23}\\ {\\rm についても同様} \\end{array} \\\\\\ &=& \\left(\\begin{array}{ccc} 1 & 0 & 0 \\\\\\ \\frac{x_{21}}{x_{11}} & 1 & 0 \\\\\\ \\frac{x_{31}}{x_{11}} & \\frac{x_{32}-\\frac{x_{31}}{x_{11}}x_{12}}{x_{22}-\\frac{x_{21}}{x_{11}}x_{12}} & 1 \\end{array}\\right)\\left(\\begin{array}{ccc} x_{11} & x_{12} & x_{13} \\\\\\ 0 & x_{22}-\\frac{x_{21}}{x_{11}}x_{12} & x_{23}-\\frac{x_{21}}{x_{11}}x_{13} \\\\\\ 0 & 0 & x_{33}-\\frac{x_{31}}{x_{11}}x_{13}-\\frac{x_{32}-\\frac{x_{31}}{x_{11}}x_{12}}{x_{22}-\\frac{x_{21}}{x_{11}}x_{12}}\\left(x_{23}-\\frac{x_{21}}{x_{11}}x_{13}\\right) \\end{array}\\right)\\\\\\ &\\because& \\begin{array}{l} x_{32}=l_{31}u_{12}+l_{32}u_{22}\\leftrightarrow l_{32}=\\frac{x_{32}-l_{31}u_{12}}{u_{22}}, \\\\\\ u_{33}\\ {\\rm についても同様} \\end{array} \\end{eqnarray} これをみると, 一行目, 一列目, 二行目, 二列目 \\(\\cdots\\) と展開していくことで, 芋づる式に \\(L,U'\\) が決まっていくことがわかる. この作業を一般化すると, \\(u_{ij}\\) の導出およびそれによって得られた値で \\(l_{ij}\\) を導出する部分に分けることができる. それぞれをいま漸化式で書くと \\begin{eqnarray} {\\rm Doolittle 法} &:=& \\begin{cases} \\begin{cases} u_{1k}&=&x_{1k} \\\\\\ u_{ik}&=&x_{1k}-\\sum&#94;{i-1}_{j=1}l_{ij}u_{jk},\\ \\left(i=2,3,\\cdots,k\\right) \\end{cases} \\\\\\ l_{ik}=\\frac{\\left(x_{ik}-\\sum&#94;{k-1}_{j=1}l_{ij}u_{jk}\\right)}{u_{kk}},\\ \\left(i=k+1,k+2,\\cdots,n\\right) \\end{cases} \\end{eqnarray} ただし \\(u_{kk}=0\\) の場合は計算できないので, 実際にはピボッティングを要することになるわけであるが, \\(U\\) の \\(k\\) 番目の行が \\(L\\) の対応する列の前に計算されるという Doolittle 法の性質上, このままではどの行が \\(k\\) 番目に来るのかを処理以前に知ることができない. この問題は \\(l_{ik}\\) の分子を次のように計算することで自明に克服できる. \\[s_i = x_{ik}-\\sum&#94;{k-1}_{j=1}l_{ij}u_{jk},\\ \\left(i=k,\\cdots,n\\right)\\] これにより \\(s_i\\) の最大値を求め, 対応する行を入れ替えて最大の要素を \\(k\\) 行目に入れることができる. 交換後は \\(u_{kk}=s_{k}\\) となるが, \\(U\\) の \\(k\\) 番目の行の他の要素はそれ以前と同様に計算することができ, 対応する \\(L\\) の要素は \\(l_{ik}=\\frac{s_i}{u_{kk}}\\) と得られる. Crout 法も同様に, \\(X=L' U\\) を次のように書けるはずなので, \\begin{eqnarray} \\left(\\begin{array}{ccc} l_{11} & l_{11}u_{12} & l_{11}u_{13} \\\\\\ l_{21} & l_{21}u_{12}+l_{22} & l_{21}u_{13}+l_{22}u_{23} \\\\\\ l_{31} & l_{31}u_{12}+l_{32} & l_{31}u_{13}+l_{32}u_{23}+l_{33} \\end{array}\\right)= \\left(\\begin{array}{ccc} l_{11} & 0 & 0 \\\\\\ l_{21} & l_{22} & 0 \\\\\\ l_{31} & l_{32} & l_{33} \\end{array}\\right) \\left(\\begin{array}{ccc} 1 & u_{12} & u_{13} \\\\\\ 0 & 1 & u_{23} \\\\\\ 0 & 0 & 1 \\end{array}\\right) \\end{eqnarray} 従ってこの作業の一般形は結果的に \\begin{eqnarray} {\\rm Crout 法} &:=& \\begin{cases} l_{ik}&=&x_{ik}-\\sum&#94;{k-1}_{j=1}l_{ij}u_{jk},\\ \\left(i=k,k+1,\\cdots,n\\right)\\\\\\ u_{kj}&=&\\frac{\\left(x_{kj}-\\sum&#94;{k-1}_{i=1}l_{ki}u_{ij}\\right)}{l_{kk}},\\ \\left(j=k,k+1,\\cdots,n\\right) \\end{cases} \\end{eqnarray} \\(L\\) の \\(k\\) 番目の列の要素を計算した後に最大値を求め, \\(L\\) の要素を含む最初の \\(k-1\\) 列に対応する行列の行を交換できるため, Crout 法はピボットを簡単に選択できる. 参考文献 Richard Hamming (1987) \"Numerical Methods for Scientists and Engineers (Dover Books on Mathematics)\" Dover Publications, ISBN 9780486652412 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2019/ 1月/01/LUDecomposition/","tags":"math","url":"posts/2019/ 1月/01/LUDecomposition/","title":"LU 分解"},{"text":"久しぶりにまた 1 なにか d3.js で視覚化してみたくなったのだが, このエントリがポストされる次の日は アイザック・ニュートン の誕生日らしいので, 今回はニュートン法(Newton Raphson 法)を視覚化してみることにした. 早速であるが以下がその成果物である 2 . \\(f(x)=0\\) となる関数 \\(f(x)\\) とその導関数 \\(f'(x)\\) 及びニュートン法の初期値を受け付け, 実行をクリックすると関数とニュートン法の計算過程における接線がプロットされる. デフォルトでは, \\(\\sqrt{2}\\) の値を計算するように設定してある. 入力された関数を元に数値微分をしても良かったのだが, なんとなく導関数を入力したかったので, そのようなことはしなかった. \\(f(x)=\\) \\(f'(x)=\\) 初期値 : これで終わってしまうと何とも寂しいので, 一応簡単にニュートン法について書く. ニュートン法はとても有名な方程式の近似解を求める方法の 1 つである. 連続的関数 3 \\(f(x)\\) が \\(f(x)=0\\) となるような \\(x\\) を求めるときに, 予め決めた, あるいは事前の計算で求まった切片 \\(x_{n}\\) における関数 \\(f(x)\\) への接線 \\(f'(x_{n})\\) の切片 \\(x_{n+1}\\) を用いて再帰的に \\(f(x)=0\\) に近づけていくことで求める. 同手法は非常に単純ながらも効率的な近似解法であり, 同手法から発展されたいくつかの手法が考えられている. いまニュートン法の漸化式を導出することを考える. 計算で必要となるのは \\(f'(x_{n})\\) に対する切片 \\(x_{n+1}\\) であるから, いま三点 \\(\\left(x_{n},0\\right), \\left(x_{n},f(x_{n})\\right), \\left(x_{n+1}, 0\\right)\\) の成す直角三角形について考えると, \\(f'(x_{n})=\\frac{(x_{n})}{x_{n}-x_{n+1}}\\) より \\[x_{n+1}=x_{n}-\\frac{f(x_{n})}{f'(x_{n})}\\] 例えば \\(\\sqrt{2}\\) を例にとると, \\(x&#94;2=2\\Leftrightarrow x&#94;2-2=0\\) なので \\(f(x)=x&#94;2-2,f'(x)=2x\\) とおいて \\(x_{n}-\\frac{x&#94;2_{n}-2}{2x_{n}}\\) を計算すればよい. なお \\(f'(x_{n})\\) が \\(0\\) であると, ゼロ除算になってしまうため計算することができない. この事実は, 傾きのない場合にどちらに進んでいけば良いのかわからないという直感的な考えにおいても筋が通る. また, \\(f(x)\\) の解が複数あるとき, 初期値によっては望まない解が導かれることがある. いま \\(\\sqrt{2}\\) の正の解を得たいとき, 初期値を \\(-1\\) で実行してしまうと, 得られる解は \\(-\\sqrt{2}\\) となる. 直感的には決められた初期値の傾き \\(f'(x_0)\\) によって近づいていく方向が定まってしまうからといえる. 従って同手法を適用する際は, できる限り求めたい解に近い初期値を設定するのが望ましい. なおニュートン法は 1 変数関数のみならず多変数関数に対しても同様にして解を求めることができる. あまり厳密には書かないが, まずは簡単のために 2 変数の関数 \\(f_{1}(x,y),f_{2}(x,y)\\) を用いてそれを示すこととする. \\(f_{1}(x,y),f_{2}(x,y)\\) は曲面の定義そのものであり, この 2 つの曲面の交わる曲線を辿っていくことで解が求まる. 1 変数のニュートン法の場合と同様に漸化式を求めていけば, 多変数関数に対するニュートン法の漸化式も関数の値をその傾きで割る部分が出てくるが, いま変数は複数であるので, 各方向への微小変化に対する変化量を求める必要がある. これを求めるには 全微分 をすればよいので, 結局 \\[ \\left(x_{n+1},y_{n+1}\\right)=\\left(x_{n},y_{n}\\right)&#94;T-{\\partial f(x_{n},y_{n})}&#94;{-1}\\left(f_{1}(x_{n}, y_{n}),f_{2}(x_{n},y_{n})\\right)&#94;T \\] ここで \\begin{eqnarray}\\partial f(x,y):= \\left(\\begin{array}{cc} \\frac{\\partial f_{1}(x,y)}{\\partial x} & \\frac{\\partial f_{1}(x,y)}{\\partial y} \\\\\\ \\frac{\\partial f_{2}(x,y)}{\\partial x} & \\frac{\\partial f_{2}(x,y)}{\\partial y} \\end{array}\\right) \\end{eqnarray} なお \\(\\partial f(x,y)\\) はヤコビ行列といわれる. 実際にコンピュータで計算する際には, \\({\\partial f(x_{n},y_{n})}&#94;{-1}\\left(f_{1}(x_{n}, y_{n}),f_{2}(x_{n},y_{n})\\right)&#94;T\\) を求めるのは計算量と誤差の観点から見て困難なので, \\(\\partial f(x_{n},y_{n})\\boldsymbol{a}=\\left(f_{1}(x_{n}, y_{n}),f_{2}(x_{n},y_{n})\\right)&#94;T\\) を LU 分解などで解き \\(\\left(x_n,y_n\\right)&#94;T-\\boldsymbol{a}\\) と解くことになる. 因みに, 上記で描画される接線は, 単純に ラグランジュの補完公式より \\(y-y_{1}=\\frac{y_{2}-y_{1}}{x_{2}-x_{1}}\\left(x-x_{1}\\right)\\) を用いて描いている. 具体的には接線の関数を \\(g(x&#94;{\\star})\\) としたとき, 接点と \\(y_{2}=0\\) であるときの 2 点 \\(\\left(x,f(x)\\right),\\left(x-\\frac{f(x)}{f'(x)},0\\right)\\) を使って \\begin{eqnarray} g(x&#94;{\\star})&=&\\frac{f(x)}{\\frac{f(x)}{f'(x)}}\\left(x&#94;{\\star}-x+\\frac{f(x)}{f'(x)}\\right) \\\\\\ &=&f'(x)\\left(x&#94;{\\star}-x+\\frac{f(x)}{f'(x)}\\right) \\\\\\ &=&f'(x)x&#94;{\\star}-f'(x)x+f(x) \\end{eqnarray} と導ける. 以前のエントリ, ベジェ曲線 では d3.js を用いて二次ベジェ曲線が描かれていく過程を書いた. ↩ 実装 . ここで懺悔すると, 実はグラフの描画の実装についてはそこそこ手抜きをしている. 例えば解が第 1, 2 象限であるものの関数 \\(f(x)\\) の値の多くが第 3, 4 象限にあると接線が見えない. 勿論計算結果そのものは影響しない. ↩ 連続性に関する論法 \\(\\to\\) \\(\\epsilon-\\delta\\) 論法 . ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2018/12月/24/newtonRaphson/","tags":"math","url":"posts/2018/12月/24/newtonRaphson/","title":"ニュートン法の視覚化"},{"text":"当ブログ内では, 既に確率論の話題として ベイズの定理 のエントリが存在するが, 今後同様にして確率論の話題を本ブログで取り上げる際に, 用語へのリファレンスを self-contained で張れるよう, 本エントリにて一度整理しておくこととした \\(.\\) 確率の定義 そもそも一言に「確率」といえども, それは古典的確率, 統計的確率, 公理的確率というように大別できる. 古典的確率 古典的確率は, \\(\\Omega\\) の要素数といま注目している事象の場合の数の比を用いるもので, すべての事象が等確率で発生することを前提条件とする. 理想的なサイコロの出目の確率などがこれに当てはまる. 統計的確率 統計的確率は, 「\\(\\Omega\\) の部分集合 = 事象」の発生回数と, その試行回数の比を用いるもので, 打率などがこれに当てはまる. 公理的確率 公理的確率とは, 確率の公理により定義された確率であり, 同公理における理論体系上では各事象の発生する確率が異なるものをも扱うことができる. この確率の公理では集合論, 測度論の言葉が使われるが, 同理論に関して深堀りすると本エントリの主題から大きく逸れてしまうため, ここではあまり深くは触れずに持ち出すこととしている. 集合のあつまりを一般に集合族というが, 次に示すのはその 1 種である 1 . \\(\\sigma\\)-加法族 標本空間 \\(\\Omega\\) の部分集合族 \\(\\mathcal{F}\\) が次の 3 つの性質を満足するとき, \\(\\mathcal{F}\\) は \\(\\sigma\\)-加法族という. \\(\\emptyset\\in \\mathcal{F}\\) \\(A\\in\\mathcal{F}\\Rightarrow A&#94;{c}\\in\\mathcal{F}\\) \\(\\displaystyle A_1,A_2,\\cdots\\in\\mathcal{F}\\Rightarrow \\bigcup&#94;{\\infty}_{i=1}A_i \\in\\mathcal{F}\\) ここで, \\(A&#94;{c}\\) は集合 \\(A\\) の補集合. \\(\\sigma\\)-加法族は, 空集合と補集合, 加算無限個の集合の和集合について閉じることを要請し, 確率の公理は, この \\(\\sigma\\)-加法族の関数に対して次の条件を付与する. コルモゴロフの公理 \\(\\sigma\\)-加法族 \\(\\mathcal{F}\\) 上の関数 \\(P\\) が次の 3 つの性質を満足するとき, \\(P\\) を確率関数という. \\(0\\leq P(A)\\leq 1,\\ &#94;\\forall A\\in\\mathcal{F}\\) \\(P(\\Omega) = 1\\) \\(A_1,A_2,\\cdots\\in\\mathcal{F}\\) があって, \\(\\displaystyle \\bigcap&#94;{\\infty}_{i=1}A_i = \\emptyset\\)(互いに排反) \\(\\displaystyle\\Rightarrow P\\left(\\bigcup_{i=1}&#94;\\infty A_i\\right)=\\sum_{i=1}&#94;\\infty P(A_i)\\) 可算無限個の事象が互いに排反な事象の和集合の値は, 各事象の値の和となる. なお, 標本空間を \\(\\Omega =\\left\\{x_1,x_2,\\cdots,x_n\\right\\}\\), \\(p_1,\\dots,p_n\\) がそれぞれ \\(\\displaystyle 0\\leq p_{i}\\leq 1\\) で, \\(\\displaystyle \\sum_{i=1}&#94;{n}p_{i}=1\\) であるとき, \\(\\Omega\\) の部分集合 \\(A\\) に対して関数 \\(P\\) を \\(P(A)=\\displaystyle\\sum_{\\left\\{i\\ |\\ x_i\\in A\\right\\}}p_i\\) とすると \\(P\\) は確率関数となるから, 統計的確率論の問題は公理的確率論の問題として扱うことができるといえ, 自ずと公理的確率論が統計的確率論の拡張であることがいえる. 基本的な言葉 td { width: 40px; } .min100 { min-width: 100px; } 用語 意味 表現 標本空間 試行に付随して決まる, 試行の取りうるすべての結果から成る \\(\\emptyset\\) でない集合. \\(\\Omega\\) 標本 標本空間の元. 試行の結果発生しうる個々の事柄. \\(\\omega\\in\\Omega\\) 事象 標本空間の部分集合. 試行の結果発生しうる事柄. \\(A\\subset\\Omega\\) 確率変数 ある事象が確率的に取りうる数. 確率変数 \\(X\\) の取りうる値 \\(x_1, x_2,\\cdots\\) それぞれに対応する確率 \\(p_1, p_2,\\cdots\\) が存在する場合, 隣り合う数の間に値が存在しない確率変数(サイコロの出目など)をとくに離散型確率変数といい, 離散確率変数 \\(X\\) がある値 \\(x\\) をとるとき, 標本から実現値 \\(\\mathbb{R}\\) への関数 \\(f(x)\\) を確率質量関数という. 離散型確率変数でない確率型変数を連続型確率変数という( \\(\\epsilon-\\delta\\)論法 で厳密に説明できる). \\(X\\) 実現値 確率変数がとる具体的な値. \\(x_n\\) 確率分布 確率変数がある値となる確率, 又はある集合に属する確率を与える関数( JIS 規格より). \\(P(A)\\) 「独立同一分布に従う」 確率変数 \\(X_1,X_2,\\cdots,X_n\\) が互いに 独立 で, かつそれらが同一の確率分布に従うことをいう. 注意されたいのが, 「独立同一分布」といわれる分布はない. この用例は, 「独立同一分布」という分布に従うというようにも捉えられるかもしれないが, そのような意味ではない. \\(\\rm i.i.d\\) 標本 \\(X_1,X_2,\\cdots,X_n\\) の同時の確率密度関数は \\(f(x_1,x_2,\\cdots,x_n)=g(x_1)g(x_2)\\cdots g(x_n)\\). \\(\\rm i.i.d\\), independent and identically distributed. 算術平均 相加平均 単純平均 全体の総和をそれらの個数で割った値. \\(\\displaystyle\\dfrac{1}{n}\\sum&#94;{n}_{i=1}X_i\\). 確率変数 \\(X\\) の平均: \\(\\overline{X}\\) 母平均: \\(\\mu\\) 期待値 確率変数のとりうる値にそれが起こる確率を掛けた値の総和のこと(加重平均). すなわち, 確率変数 \\(X\\) の取り得る値 \\(x\\) に関する確率 \\(P(x_i)\\) があって, \\begin{cases} \\displaystyle\\sum&#94;{n}_{i=1}x_i P(x_i) &:X {\\rm は離散的確率変数}\\\\ \\displaystyle\\int&#94;\\infty_{-\\infty} xP(x)dx &:X {\\rm は連続的確率変数} \\end{cases} 離散, 連続共に和の期待値は期待値の和(期待値の線形性) 2 : \\(\\displaystyle E\\left[\\sum_{i=1}&#94;nX_i\\right]=\\sum_{i=1}&#94;nE\\left[X_i\\right]\\), 連続の場合も同様. 離散 \\(n\\) 個の \\(P(x_1),P(x_2),\\cdots,P(x_n)\\) がすべて等しいとき \\(P_i=\\dfrac{1}{n}\\ (1\\leq i\\leq n)\\) となり, \\(\\overline{X}\\) と等しくなる. 連続 \\(f(x)=xP(x)\\) としたとき, \\(f(x)\\) は確率密度関数といわれる. 連続型確率変数がある 1 点の値をとる確率は 0 である(0 でなければ, 連続量とはいえない: \\(P(X=a)=\\int&#94;{a}_{a}f(x)dx=0\\)) から, 事象 \\(X\\) の確率については \\(a\\leq X\\leq b\\) と幅を持たせて表す必要がある. 従って, (連続量が表されたグラフを思い浮かべれば想像に容易いが)その \\([a,b]\\) 間の面積が求まれば, 事象 \\(X\\) に対する確率が求まることとなるので, 事象 \\(X\\) が \\(a\\) 以上 \\(b\\) 以下となる確率を \\(P(a\\leq X\\leq b)=\\int_a&#94;bf(x)dx\\) とかける. コルモゴロフの公理 より \\(\\int_{-\\infty}&#94;{\\infty}f(x)dx=1\\) がいえ, これを規格化条件という. 定数 \\(a\\) の期待値は \\(a\\) である: \\(E\\left[a\\right]=\\int&#94;\\infty_{-\\infty}aP(x)dx=a\\int&#94;\\infty_{-\\infty}P(x)dx\\) だから \\[E\\left[a\\right]=a\\label{eq:exaxiom1}\\tag{i}\\] 定数 \\(a\\) と確率変数 \\(X\\) の和の期待値は, 確率変数 \\(X\\) の期待値に定数 \\(a\\) を加えた値である: \\(E\\left[a+X\\right]=\\int&#94;\\infty_{-\\infty}(a+x)P(x)dx=\\int&#94;\\infty_{-\\infty}aP(x)dx+\\int&#94;\\infty_{-\\infty}xP(x)dx\\) だから \\[E\\left[a+X\\right]=a+E\\left[X\\right]\\label{eq:exaxiom2}\\tag{ii}\\] 定数 \\(b\\) と確率変数 \\(X\\) の積の期待値は, 確率変数 \\(X\\) の期待値の \\(b\\) 倍の値である: \\(E\\left[bX\\right]=\\int&#94;\\infty_{-\\infty}bxP(x)dx=b\\int&#94;\\infty_{-\\infty}xP(x)dx\\) だから \\[E\\left[bX\\right]=bE\\left[X\\right]\\label{eq:exaxiom3}\\tag{iii}\\] 定数 \\(b\\) と確率変数の積に定数 \\(a\\) を加えた値の期待値は, 確率変数 \\(X\\) の期待値の \\(b\\) 倍に \\(a\\) を加えた値である: \\(\\eqref{eq:exaxiom2},\\eqref{eq:exaxiom3}\\) より \\[E\\left[bX+a\\right]=bE\\left[X\\right]+a\\label{eq:exaxiom4}\\tag{iv}\\] 確率変数 \\(X\\) の期待値: \\(E\\left[X\\right]\\) 標本平均 \\(\\overline{X}\\) の期待値 3 : \\(\\mu\\) 条件付き確率 ある事象が起きる条件のもとで, 別のある事象が起こる確率. \\[P\\left(A\\mid B\\right)=\\dfrac{P\\left(A\\cap B\\right)}{P\\left(B\\right)}\\ \\left(\\because P\\left(A\\cap B\\right):=A\\ {\\rm および}\\ B\\ {\\rm が発生する確率}\\right)\\] 2 つの事象の確率について, 相互が一方の事象の発生確率がもう一方の事象の発生確率に影響を与えないとき, これを独立であるという. すなわち \\(P\\left(A\\mid B\\right)=P\\left(A\\right)\\) 2 つの事象について, 一方の事象が発生したときに, もう一方の事象は発生しないことがいえるとき, これを排反であるという. すなわち \\(P\\left(A\\mid B\\right)=0\\) \\(P\\left(A\\cap B\\right)=P\\left(B\\right)P\\left(A\\mid B\\right)\\) を条件付き確率の乗法定理という. ベイズの定理 \\(B\\) の下で \\(A\\) が発生する確率: \\(P\\left(A\\mid B\\right)\\) 条件付き期待値 確率変数 \\(X\\) の値が \\(x\\) であるときの \\(Y\\) の期待値. \\(E\\left[Y|X=x\\right]\\) \\[E\\left[Y|X=x\\right]=\\sum&#94;{n}_{i=1}y_i\\dfrac{P\\left(Y=y_i,X=x\\right)}{P\\left(X=x\\right)}\\] \\(E\\left[Y\\right]=E\\left[E\\left[Y|X\\right]\\right]\\) が成りたつ 4 . \\(E\\left[Y|X\\right],\\ E_Y\\left[Y|X\\right]\\) 条件付き分散 \\(V[X\\mid Y]=E[X&#94;2\\mid Y]-E[X\\mid Y]&#94;2\\) \\(V\\left[Y\\right]=E\\left[V\\left[Y|X\\right]\\right]+V\\left[E\\left[Y|X\\right]\\right]\\) が成り立つ(証明略). \\(V\\left[Y|X\\right],\\ V_Y\\left[Y|X\\right]\\) 規格化 正規化 ある関数が規格化条件を満足するように定数倍すること. 平均を引いて, 標準偏差で割る(\\(\\dfrac{X-\\mu}{\\sigma}\\)) 5 こと. 連続的確率変数を扱う場合にのみ使われる言葉. 例えば, \\(f(x)=x\\) は \\([0,1]\\) 上で \\(\\int_0&#94;1xdx=\\dfrac{1}{2}\\) となってしまうため, 規格化条件を満たさないが, 全体を 2 倍して \\(f(x)=2x\\) とすると, 全区間で積分して \\(1\\) になるので規格化条件を満たす. 従って, \\(f(x)=2x\\) は確率度関数となる. N/A 分散 標本分散 期待値とのずれを表す指標の 1 つ. ずれの総計で各々が相殺しないように二乗和をとり, その個数 \\(n\\) で割った値. すなわち, \\[\\dfrac{1}{n}\\displaystyle\\sum_{i=1}&#94;n(X_i-E\\left[X\\right])&#94;2=E\\left[(X-E\\left[X\\right])&#94;2\\right]\\] ここで, 確率変数 \\(X_1,X_2,\\cdots,X_n\\) の確率分布がすべて等しいとき, \\(\\displaystyle\\dfrac{1}{n}\\sum&#94;{n}_{i=1}\\left(X_i-\\overline{X}\\right)&#94;2=\\overline{X&#94;2}-\\overline{X}&#94;2\\) と高校数学でよくみる形式でかける. 定数の分散は \\(0\\) である: \\(V\\left[a\\right]=E\\left[\\left(a-E\\left[a\\right]\\right)&#94;2\\right]=E\\left[\\left(a-a\\right)&#94;2\\right]\\) だから \\[E\\left[0\\right]=0\\label{eq:exaxiom5}\\tag{v}\\] 定数 \\(a\\) と確率変数 \\(X\\) の和の分散は, 確率変数 \\(X\\) の分散である: \\begin{eqnarray} V\\left[a+X\\right]&=&E;\\left[\\left(a+X-E\\left[a+X\\right]\\right)&#94;2\\right] \\\\ &=&E;\\left[\\left(a+X-E\\left[a\\right]-E\\left[X\\right]\\right)&#94;2\\right] \\\\ &=&E;\\left[\\left(a+X-a-E\\left[X\\right]\\right)&#94;2\\right]\\\\ &=&E;\\left[\\left(X-E\\left[X\\right]\\right)&#94;2\\right] \\end{eqnarray} だから \\[V\\left[a+X\\right]=V\\left[X\\right]\\label{eq:exaxiom6}\\tag{vi}\\] 定数 \\(b\\) と確率変数 \\(X\\) の積の分散は, 確率変数 \\(X\\) の分散と \\(b\\) の二乗の積である: \\begin{eqnarray} V\\left[bX\\right]&=&E;\\left[\\left(bX-E\\left[bX\\right]\\right)&#94;2\\right] \\\\ &=&E;\\left[\\left(bX-bE\\left[X\\right]\\right)&#94;2\\right] \\\\ &=&E;\\left[\\left\\{b\\left(X-E\\left[X\\right]\\right)\\right\\}&#94;2\\right] \\\\ &=&E;\\left[b&#94;2\\left(X-E\\left[X\\right]\\right)&#94;2\\right] \\\\ &=&b;&#94;2E\\left[\\left(X-E\\left[X\\right]\\right)&#94;2\\right] \\end{eqnarray} だから \\[V\\left[bX\\right]=b&#94;2V\\left[X\\right]\\label{eq:exaxiom7}\\tag{vii}\\] 定数 \\(b\\) と確率変数 \\(X\\) の積と \\(a\\) の和の分散は, 確率変数 \\(X\\) の分散と定数 \\(b\\) の二乗の積である: \\(\\eqref{eq:exaxiom6}, \\eqref{eq:exaxiom7}\\) より \\[V\\left[bX+a\\right]=b&#94;2V\\left[X\\right]\\label{eq:exaxiom8}\\tag{viii}\\] 確率変数 \\(X\\) の分散: \\(V\\left[X\\right]\\) 母集団の分散: \\(\\sigma&#94;2\\) 標本分散: \\(s&#94;2\\) 標本平均の分散 6 : \\(V\\left[\\overline{X}\\right]=\\dfrac{\\sigma&#94;2}{n}\\) 分散 不偏分散 標本数 \\(n\\) で割ったのに対し, \\(n-1\\) で割った値. 標本分散の期待値が母分散に等しくなるように補正したもの (詳細は 下記 ): \\(\\displaystyle\\dfrac{1}{n-1}\\sum&#94;n_{i=1}\\left(X_i-E\\left[X\\right]\\right)&#94;2\\) \\(U&#94;2,\\hat{\\sigma}&#94;2\\) 標準偏差 分散の計算で行われた二乗を外した形. \\(\\sqrt{V[X]},\\sigma,s\\). 各記号は, 分散の記号と同様にして用いられる慣習がある. 不偏分散 上記の表で示した通り, 不偏分散は, 標本分散の期待値が母分散に等しくなるように補正したもののことをいう. 標本分散は, 標本のばらつきの指標を得ることが主な目的であったのに対して, 不偏分散は, 標本から母分散の推定値を得ることが主な目的であり, その点において両者は異なる. その目的に従って, 標本分散の期待値 \\(E\\left[s&#94;2\\right]\\) は, 母分散の \\(\\dfrac{n-1}{n}\\) 倍となっているという事実(\\(E\\left[s&#94;2\\right]=\\dfrac{n-1}{n}\\sigma&#94;2\\not =\\sigma&#94;2\\))から, 標本分散を \\(\\dfrac{n}{n-1}\\) 倍する(しかしながら, サンプル数 \\(n\\) が十分に大きいとき, 両者は近似的に等しくなることが 大数の弱法則 よりいえる). この形が不偏分散である. 不偏分散 \\[\\displaystyle\\dfrac{1}{n-1}\\sum&#94;n_{i=1}\\left(X_i-E\\left[X\\right]\\right)&#94;2\\] 以下, \\(E\\left[s&#94;2\\right]=\\dfrac{n-1}{n}\\sigma&#94;2\\) を証明する. 証明 : いま \\(\\rm i.i.d\\) 標本 \\(X_1,X_2,\\cdots,X_n\\) について考えると, この標本分散は上記の表で示した通り \\(\\displaystyle s&#94;2=\\overline{X&#94;2}-\\overline{X}&#94;2=\\dfrac{1}{n}\\sum&#94;{n}_{i=1}\\left(X_i-\\overline{X}\\right)&#94;2\\) で, 母分散は \\(\\sigma&#94;2=E\\left[\\left(X-\\mu\\right)&#94;2\\right]\\) である. ここで, \\(X_i-\\overline{X}=X_i-\\mu-\\overline{X}+\\mu\\) とおくと, \\begin{eqnarray} &=&\\dfrac{1}{n}\\left[\\left\\{\\left(X_1-\\mu\\right)-\\left(\\overline{X}-\\mu\\right)\\right\\}&#94;2+\\cdots+\\left\\{\\left(X_n-\\mu\\right)-\\left(\\overline{X}-\\mu\\right)\\right\\}&#94;2\\right] \\\\\\ &=&\\dfrac{1}{n}\\left\\{\\left(X_1-\\mu\\right)&#94;2-2\\left(X_1-\\mu\\right)\\left(\\overline{X}-\\mu\\right)+\\left(\\overline{X}-\\mu\\right)&#94;2+\\cdots+\\left(X_n-\\mu\\right)&#94;2-2\\left(X_n-\\mu\\right)\\left(\\overline{X}-\\mu\\right)+\\left(\\overline{X}-\\mu\\right)&#94;2\\right\\} \\\\\\ &=&\\dfrac{1}{n}\\sum_{i=1}&#94;n\\left(X_i-\\mu\\right)&#94;2-2\\dfrac{1}{n}\\sum_{j=1}&#94;{n}\\left(X_j-\\mu\\right)\\left(\\overline{X}-\\mu\\right)+\\left(\\overline{X}-\\mu\\right)&#94;2 \\\\\\ &=&\\dfrac{1}{n}\\sum_{i=1}&#94;n\\left(X_i-\\mu\\right)&#94;2-2\\left(\\overline{X}-\\mu\\right)&#94;2+\\left(\\overline{X}-\\mu\\right)&#94;2 \\\\\\ &=&\\dfrac{1}{n}\\sum_{i=1}&#94;n\\left(X_i-\\mu\\right)&#94;2-\\left(\\overline{X}-\\mu\\right)&#94;2 \\end{eqnarray} である. この期待値は \\begin{eqnarray} E\\left[s&#94;2\\right]&=&\\dfrac{1}{n}\\sum_{i=1}&#94;nE\\left[\\left(X_i-\\mu\\right)&#94;2\\right]-E\\left[\\left(\\overline{X}-\\mu\\right)\\right] \\\\\\ &=&\\sigma&#94;2-E\\left[\\left(\\overline{X}-\\mu\\right)&#94;2\\right] \\label{eq:second}\\tag{1} \\end{eqnarray} で, \\(\\eqref{eq:second}\\) の第二項は標本平均分散だから, \\begin{eqnarray} E\\left[s&#94;2\\right]&=&\\sigma&#94;2-\\dfrac{\\sigma&#94;2}{n}\\\\\\ &=&\\dfrac{n-1}{n}\\sigma&#94;2 \\end{eqnarray} \\(\\square\\) 正規分布, ガウス分布 上図 7 のような, 連続型の確率分布が左右対称である分布を正規分布といい, その陰関数は \\(f(x)=\\dfrac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\dfrac{1}{2}\\left(\\dfrac{x-\\mu}{\\sigma}\\right)&#94;2\\right)\\) であり, これを \\(N(\\mu,\\sigma)\\) とも書く. また, その確率密度関数は 正規分布の確率密度関数 標準偏差 \\(\\sigma\\), 母平均 \\(\\mu\\), 分散 \\(\\sigma&#94;2\\) に対して, \\[f(x)=\\dfrac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\dfrac{(x-\\mu)&#94;2}{2\\sigma&#94;2}\\right)\\label{eq:first}\\tag{2}\\] である. また \\(\\mu=0,\\sigma=1\\) である正規分布をとくに標準正規分布といい(上図青で描かれた分布がそれに該当する), その場合の陰関数は \\(f(x)=\\dfrac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\dfrac{1}{2}x&#94;2\\right)\\) となる. また, これを \\(N(\\mu,\\sigma)=N(0,1)\\) とも書く. ここで一度, 式 \\(\\eqref{eq:first}\\) が規格化条件を満たすことを確認する. 確認には, ガウス積分の公式 を用いる. 命題 : \\(\\eqref{eq:first}\\) は規格化条件を満たす. 証明 : \\(\\eqref{eq:first}\\) が規格化条件を満たすことは次の等号式を満たすことである. \\[\\displaystyle\\int_{-\\infty}&#94;{\\infty}f(x)dx=\\dfrac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}&#94;{\\infty}\\exp\\left(-\\dfrac{(x-\\mu)&#94;2}{2\\sigma&#94;2}\\right)dx\\] ここで, \\(x-\\mu=y\\) と変数変換すると \\[\\dfrac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}&#94;{\\infty}\\exp\\left(-\\dfrac{y&#94;2}{2\\sigma&#94;2}\\right)dy\\] この積分部分は ガウス積分の公式 より, \\(\\sqrt{2\\sigma&#94;2\\pi}\\) となり \\(f(x)\\) を全区間で積分すると 1 となる. よって, \\(\\eqref{eq:first}\\) は規格化条件を満たす. \\(\\square\\) 正規分布においては, 区間 \\([-\\sigma,\\sigma]\\) を 1 シグマ区間という. 平均 \\(\\pm{1\\sigma}\\) 内に収まる確率は \\(68\\) %, 平均 \\(\\pm{2\\sigma}\\) 内に収まる確率は \\(95\\) %, 平均 \\(\\pm{3\\sigma}\\) 内に収まる確率は \\(99.7\\) % であると知られている. 大数の法則 大数の法則は, 大数の法則 期待値 \\(\\mu\\) の \\(\\rm i.i.d\\) 無限列 \\(X_1,X_2,\\cdots\\) の標本平均 \\(\\displaystyle\\overline{X}=\\dfrac{1}{n}\\sum_{i=1}&#94;{n}X_i\\) と定数 \\(&#94;\\forall c\\gt 0\\) に対して, \\[\\lim_{n\\to\\infty}P\\left(\\left|\\overline{X}_{n}-\\mu\\right|\\gt c\\right)=0\\] がいえる. これを大数の弱法則という. また \\[ P\\left(\\lim_{n\\to\\infty}\\overline{X}_n=\\mu\\right)=1 \\] がいえる. これを大数の強法則という. である. なお, この法則を確率論の用語で, \\(\\overline{X}_n\\) が \\(\\mu\\) に確率収束するという. 端折って解釈すると, ある母集団から無作為抽出するサンプル数を十分に大きくしたとき, それらから成る標本の平均は, 母平均そのものとみなしてもよいという主張である. 例えば, サイコロの目の理論的な平均値は \\(\\frac{\\sum&#94;{6}_{i=1} i}{6}=3.5\\) であるが, サイコロを例えば 2 回降っただけではこの通りの平均値にならないかもしれない. しかしながら, これを無限回行えば, その平均は \\(3.5\\) に限りなく近くということである. ここでは簡単のために大数の弱法則についてのみの証明とする. そのために, まずマルコフの不等式, チェビシェフの不等式の証明を行う. マルコフの不等式 任意の確率変数 \\(X\\) と定数 \\(c\\gt 0\\) に対して, \\[ P\\left(\\left|X\\right|\\geq c\\right)\\leq \\dfrac{E\\left[\\left|X\\right|\\right]}{c}\\] 証明 : \\(X\\) を連続型確率変数とすると, 確率密度関数 \\(f_X(x)\\) に対して, \\begin{eqnarray} cP\\left(\\left|X\\right|\\geq c\\right)&=&c\\int&#94;{\\infty}_{c}f_X(x)dx \\\\\\ &\\leq&\\int&#94;{\\infty}_{c}\\left|x\\right|f_X(x)dx \\\\\\ &\\leq&\\int&#94;c_0\\left|x\\right|f_X(x)dx+\\int&#94;\\infty_c\\left|x\\right|f_X(x)dx \\\\\\ &=&\\int&#94;\\infty_0\\left|x\\right|f_X(x)dx \\\\\\ &=&E[\\left|X\\right|] \\end{eqnarray} \\(\\therefore P\\left(\\left|X\\right|\\geq c\\right)\\leq\\dfrac{E[\\left|X\\right|]}{c}\\). \\(X\\) が離散型確率変数である場合は総計により同様にして求まる. \\(\\square\\) チェビシェフの不等式 \\(E[Y]=\\mu,V[Y]=\\sigma&#94;2\\) とするとき, \\(&#94;\\forall a\\gt 0\\) に対して, \\[P\\left(\\left|Y-\\mu\\right|\\geq a\\sigma\\right)\\leq\\dfrac{1}{a&#94;2}\\Leftrightarrow P\\left(\\left|Y-\\mu\\right|\\geq a\\right)\\leq\\dfrac{\\sigma&#94;2}{a&#94;2}\\] 証明 : マルコフの不等式 より, \\(X=(Y-\\mu)&#94;2,c=a&#94;2\\sigma&#94;2\\) とすると \\begin{eqnarray} P\\left(\\left(Y-\\mu\\right)&#94;2\\geq a&#94;2\\sigma&#94;2\\right)&\\leq&\\dfrac{E\\left[\\left(Y-\\mu\\right)&#94;2\\right]}{a&#94;2\\sigma&#94;2} \\\\\\ &=&\\dfrac{\\sigma&#94;2}{a&#94;2\\sigma&#94;2} \\\\\\ &=&\\dfrac{1}{a&#94;2} \\end{eqnarray} \\(\\therefore P\\left(\\left|Y-\\mu\\right|\\geq a\\sigma\\right)\\leq\\dfrac{1}{a&#94;2}\\). \\(c=a&#94;2\\) とすると, 同様にして \\(P\\left(\\left|Y-\\mu\\right|\\geq a\\right)\\leq\\dfrac{\\sigma&#94;2}{a&#94;2}\\). \\(\\square\\) 準備が整ったので, 以下 大数の弱法則 を証明する. 証明 : 確率変数 \\(\\overline{Y}\\) を \\(\\rm i.i.d\\) 標本平均 \\(\\displaystyle\\dfrac{1}{n}\\sum_{i=1}&#94;{n}Y_i\\) とすると, 期待値の線型性より \\(E\\left[\\overline{Y}\\right]=\\mu,V\\left[\\overline{Y}\\right]=\\dfrac{\\sigma&#94;2}{n}\\). ここで, チェビシェフの不等式 より \\(P\\left(\\left|\\overline{Y}-\\mu\\right|\\geq a\\right)\\leq\\dfrac{\\dfrac{\\sigma&#94;2}{n}}{a&#94;2}\\) だから, \\(n\\to\\infty\\) のとき, 右辺は \\(0\\) に収束する. \\(\\square\\) 中心極限定理 中心極限定理は 中心極限定理 平均 \\(\\mu\\), 分散 \\(\\sigma&#94;2\\) の母集団から無作為抽出された標本平均 \\(\\overline{X}_n\\) は, 母集団の分布に無関係に, \\(n\\) が十分に大きいとき, 近似的に平均 \\(\\mu\\), 分散 \\(\\dfrac{\\sigma&#94;2}{n}\\)(標準偏差 \\(\\dfrac{\\sigma}{\\sqrt{n}}\\)) に従う. \\(\\Leftrightarrow \\rm i.i.d\\) 標本 \\(X_1,X_2,\\cdots,X_n\\) があって, \\(E\\left[X_i\\right]=\\mu,V\\left[X_i\\right]=\\sigma&#94;2\\) で, \\(n\\to\\infty\\) のとき, \\(\\overline{X}_n\\) の分布は \\(N\\left(\\mu,\\dfrac{\\sigma&#94;2}{n}\\right)\\) に近く. という定理である. 大数の弱法則 とこの中心極限定理ともにサンプル平均 \\(\\overline{X}_n\\) の振る舞いに関する定理であるが, 後者においては, サンプル平均と, 真の平均との誤差について論ずる定理である点が異なる. つまり, 大数の弱法則 より \\(\\overline{X}_n\\approx\\mu\\) であることはわかったが, その差 \\(\\overline{X}_n-\\mu\\) はどのような挙動となるのか, また \\(0\\) に近づいていくのはわかったが, どのように近づいていくのかについて論じているのが, 中心極限定理 である 8 . 中心極限定理は, それが正規分布に近似するといっているので, 起きた事象の珍しさを測るための指標として用いることができ, これが統計における検定に役立つ. また, すべての平均と分散が定義できるような分布 9 に対していえることから, 様々な事象が正規分布に従うことを正当化するための理論的根拠としてよく用いられる. 参考文献 「 第 2 章 独立確率変数列の極限定理 」 2018 年 10 月 29 日アクセス. 「 コーシー分布 」 2018 年 10 月 29 日アクセス. 「 正規分布の基礎的な知識まとめ - 高校数学の美しい物語 」 2018 年 9 月 27 日アクセス. 「 大数の法則と中心極限定理の意味と関係 - 高校数学の美しい物語 」 2018 年 10 月 29 日アクセス. 「 条件付き期待値，分散の意味と有名公式 - 高校数学の美しい物語 」 2018 年 11 月 12 日アクセス. 「 3.3 条件付き期待値 」 2018 年 11 月 12 日アクセス. \\(\\sigma\\)-加法族は, 完全加法族, 可算加法族, \\(\\sigma\\)-集合代数, \\(\\sigma\\)-集合体ともいわれる. ↩ 簡単のため, 確率変数 \\(X, Y\\) に対して \\(E\\left[X,Y\\right]=E\\left[X\\right]+E\\left[Y\\right]\\) を示して証明とする. ここで, \\(\\sum_i:=\\sum&#94;n_{i=1},\\sum_j:=\\sum&#94;n_{j=1}\\) とし, 確率変数 \\(X\\) がその取り得る値 \\(x_i\\) となる確率を \\(P(x_i)\\), 同様に \\(Y\\) がその取り得る値 \\(y_j\\) となる確率を \\(P(y_j)\\) とする. また, そのどちらもが同時に発生する確率を \\(P(x_i,y_j)\\) とする. \\begin{eqnarray} E\\left[X+Y\\right]&=&\\sum_i\\sum_j\\left(x_i+y_j\\right)P(x_i,y_j) \\\\\\ &=&\\sum_i\\sum_j x_iP(x_i,y_j)+\\sum_i\\sum_j y_jP(x_i,y_j) \\\\\\ &=&\\sum_i x_i\\sum_j P(x_i,y_j)+\\sum_j y_j\\sum_i P(x_i,y_j) \\\\\\ &=&\\sum_i x_iP(x_i)\\sum_j y_jP(y_j) \\\\\\ &=& E\\left[X\\right]+E\\left[Y\\right] \\end{eqnarray} 連続的確率変数に対しても, 積分の線型性から同様. \\(\\square\\) ↩ \\(\\eqref{eq:exaxiom3}\\) および 期待値の線形性 より \\begin{eqnarray}E\\left[\\overline{X}\\right]&=&E\\left[\\dfrac{1}{n}\\sum&#94;n_{i=1}X_i\\right] \\\\\\ &=&\\dfrac{1}{n}E\\left[X_1+\\cdots+X_n\\right] \\\\\\ &=&\\dfrac{1}{n}n\\mu \\\\\\ &=&\\mu \\end{eqnarray} \\(\\square\\) ↩ 簡単のため, 連続型確率変数 \\(X,Y\\) に対する \\(E\\left[Y\\right]=E\\left[E\\left[Y|X\\right]\\right]\\) を示して証明とする. \\(E\\left[Y\\right]\\) は条件付き期待値の定義から $$E\\left[Y\\right]=\\int&#94;\\infty_{-\\infty}\\int&#94;\\infty_{-\\infty}yf(x,y)dxdy$$ ここで, \\(f(x,y)\\) は \\(X,Y\\) の同時確率密度関数である. 従って, \\begin{eqnarray}E\\left[Y\\right]&=&\\int&#94;\\infty_{-\\infty}\\int&#94;\\infty_{-\\infty}yf(x,y)dxdy \\\\\\ &=&\\int&#94;\\infty_{-\\infty}\\int&#94;\\infty_{-\\infty}y\\dfrac{f(x,y)}{f(x)}f(x)dxdy \\\\\\ &=&\\int&#94;\\infty_{-\\infty}\\left[\\int&#94;\\infty_{-\\infty}yf(y|x)dx\\right]f(x)dx \\\\\\ &=& \\int&#94;\\infty_{-\\infty}E\\left[X|y\\right]f(x)dydx \\\\\\ &=&E\\left[E\\left[Y|X\\right]\\right]\\end{eqnarray} \\(\\square\\) ↩ 平均 \\(\\mu\\), 分散 \\(\\sigma&#94;2\\) の確率変数 \\(X\\) を正則化した変数 \\(Z=\\dfrac{X-\\mu}{\\sigma}\\) の期待値と分散を確認してみると, 平均は \\(\\eqref{eq:exaxiom2}, \\eqref{eq:exaxiom3}\\) より \\begin{eqnarray}E\\left[Z\\right]&=&E\\left[\\dfrac{X-\\mu}{\\sigma}\\right] \\\\\\ &=&\\dfrac{1}{\\sigma}E\\left[X-\\mu\\right] \\\\\\ &=& \\dfrac{1}{\\sigma}\\left(E\\left[X\\right]-\\mu\\right) \\\\\\ &=&\\dfrac{1}{\\sigma}\\left(\\mu-\\mu\\right) \\\\\\ &=&0\\end{eqnarray} 分散は \\(\\eqref{eq:exaxiom6}, \\eqref{eq:exaxiom7}\\) より \\begin{eqnarray}V\\left[Z\\right]&=&V\\left[\\dfrac{X-\\mu}{\\sigma}\\right] \\\\\\ &=&\\dfrac{1}{\\sigma&#94;2}V\\left[X-\\mu\\right] \\\\\\ &=&\\dfrac{1}{\\sigma&#94;2}V\\left[X\\right] \\\\\\ &=&\\dfrac{\\sigma&#94;2}{\\sigma&#94;2} \\\\\\ &=& 1\\end{eqnarray} となり標準正規分布に従うことがわかる. ↩ \\(\\eqref{eq:exaxiom7}\\) および 期待値の線形性 より \\begin{eqnarray}V\\left[\\overline{X}\\right]&=&V\\left[\\dfrac{1}{n}\\sum&#94;n_{i=1}X_i\\right] \\\\\\ &=&\\dfrac{1}{n&#94;2}V\\left[X_1+\\cdots+X_n\\right] \\\\\\ &=&\\dfrac{1}{n&#94;2}n\\sigma&#94;2 \\\\\\ &=&\\dfrac{\\sigma&#94;2}{n}\\end{eqnarray} \\(\\square\\) ↩ matplotlib 等で 生成 . 標準偏差 \\(\\sigma\\) を \\([1,5]\\) としたとき. ↩ 参考文献 から一部引用: ベーシックな大数の弱法則は中心極限定理から導出することができます。→ The Laws of Large Numbers Compared (snip) しかし，より一般的な（仮定を弱めた）大数の弱法則は中心極限定理から導出することはできません。つまり「中心極限定理が大数の法則を包含している」と言うことはできないのです。 ↩ 平均, 分散が定義できない分布の例としてよく挙げられるものの 1 つ: コーシー分布. ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2018/10月/28/probabilityTerms/","tags":"math","url":"posts/2018/10月/28/probabilityTerms/","title":"確率論で用いられる言葉の整理"},{"text":"以前のエントリ, ガウス積分の公式とその証明 で, 暗に極座標での微小面積が \\(rdrd\\theta\\) であるとして書いていたので, その内容についても一応書いておこうというのと, 筆者自身の学習/再整理も兼ねて, ヤコビアンに関して書くこととした( ただ, 筆者は数学科でも化学科でも, ましてや理学部系の人でもありません. 極力ないようにはしていますが, もし間違い等ありましたらご教示くださるとありがたいです ). 極座標の微小面積 まず唐突であるが, 直交座標から極座標へ移行する際に, その微小面積はどうなるかについて考察する. 上図 1 は, \\(1\\times 1\\times 1\\) の立方体があって, その断面をそれぞれ極座標と直交座標で示しているだけであるが, この断面図のマスの広がり方を見るだけで, 少なくとも極座標における微小面積が \\(drd\\theta\\) とはならないことに納得できる. 単に \\(drd\\theta\\) としてしまうと, \\(r\\) が大きくなればなるほど微小面積も伸びて大きくなっていってしまうだろうというラフな想像がつく. ここで微小面積を導出するために, \\(r,\\theta\\) をともに少しだけ動かして, その幅をそれぞれ \\(\\Delta r,\\Delta \\theta\\) で表した, 次のような配置を考える 2 . \\(r\\) の距離と \\(\\theta\\) の角度で構成された面積, つまり上図の \\(\\Delta s\\) が微小面積に対応することがわかる. \\(\\Delta s\\) の面積は, 単に全体の扇形の面積から, \\(r\\) と \\(\\Delta\\theta\\) で構成された扇形の面積を引けばよいので, \\[\\Delta s=\\dfrac{1}{2}\\left(r+\\Delta r\\right)&#94;2\\Delta\\theta-\\dfrac{1}{2}r&#94;2\\Delta\\theta =r\\Delta r\\Delta\\theta+\\dfrac{1}{2}\\left(\\Delta r\\right)&#94;2\\Delta\\theta\\] \\(\\displaystyle\\lim_{\\Delta\\theta,\\Delta r\\to 0} \\) を考えれば, 微小量 \\(\\Delta r\\Delta\\theta\\) の高次の項を無視してよい. よってこれを微小増分に書き換えれば, \\(\\Delta s\\) は \\(rdrd\\theta\\) となることがいえる. …というように, ここまでは幾何学的なイメージを用いて, 直交座標と極座標間における微小面積の遷移について考察したが, 異なる座標系への変換をしようとする度にいちいち図などを用いて考察するのは面倒であり, 従って, より機械的/一般的にこれを実行する手法について考えることは自然な流れと言える. よって, 以降はそれを主題として話を進めていく. ところで微積分では, 今もそうして行ったように, 極限の概念を多大に用いるので, ここで本題に入る前にその定義に関して触れておくこととする. \\(\\epsilon-\\delta\\) 論法 \\(\\epsilon-\\delta\\) 論法とは簡単にいえば, 無限小, 無限大といった実数の範囲では定義できない曖昧な概念を, 実数値のみを用いて議論する方法で, 同論法上で極限の式との同値関係を示した定義が次のとおりである. \\(\\epsilon-\\delta\\) 論法の定義する極限の式との同値関係 \\(f\\) を実数の部分集合 \\(D\\) で定義された実数値関数, \\(c\\) を \\(D\\) の極限点, \\(L\\) を実数としたとき, \\[\\displaystyle \\lim_{x\\to c}f(x)=L\\Leftrightarrow\\left(&#94;\\forall\\epsilon\\gt 0,&#94;\\exists\\delta\\gt 0,&#94;\\forall x\\in D,0\\lt\\left|x-c\\right|\\lt\\delta\\Rightarrow\\left|f(x)-L\\right|\\lt\\epsilon\\right)\\] \\(D=[a,b]\\) または \\(D=\\mathbb{R}\\) ならば, 閉じた実区間と実数直線は完全集合となり, \\(c\\) は自動的に極限点であるという条件が満たされるので, 簡単のためにこれを \\(D=\\mathbb{R}\\) として書き直すと, \\(\\epsilon-\\delta\\) 論法は \\[&#94;\\forall\\epsilon\\gt 0,&#94;\\exists\\delta\\gt 0,\\ {\\rm s.t.}\\ &#94;\\forall x\\in\\mathbb{R}, \\left|x-c\\right|\\lt\\delta\\Rightarrow\\left|f(x)-L\\right|\\lt\\epsilon\\] となる. 日本語で記述すると「任意の実数 \\(&#94;\\forall x\\in\\mathbb{R}\\) に対して, \\(\\left|x-c\\right|\\lt\\delta\\) を満たすならば, すべての正の実数 \\(\\epsilon\\) に対して \\(\\left|f(x)-L\\right|\\lt\\epsilon\\) を満たすような \\(\\delta\\) が存在する.」となる. つまりこの言葉で, 関数 \\(f(x)\\) が \\(x=c\\) で連続であることの定義をいうことができるのである. これをグラフで表すと, 次のように描けるだろう. 関数 \\(y=f(x)\\) のとる値を赤の線として, \\(x=c\\) のときの Y 座標の値を \\(L\\) とし, いま \\(\\epsilon\\) を適当に取ってきて, \\(c\\) からの幅 \\(\\delta\\) を \\(L\\) との幅よりも小さくなるようにとると By User:HiTe [ Public domain ], from Wikimedia Commons となり, これは, さきに書いた論理式を満たすことがわかる. 上図の \\(\\epsilon\\) を見ると, この値はそこそこの大きさがあるように見えるが, これをさらに小さい値で取ったとしても, \\(\\delta\\) をそれよりもさらに小さい幅で取ることができる(=上の論理式が満たされる). 従って, 上で描いた関数 \\(f(x)\\) は \\(x=c\\) で連続であると言える. 逆に, \\(\\delta\\) をそれよりもさらに小さい幅で取ることができないのならば, それは連続でないといえることもわかる. いまこれらを言うのに, 極限の概念を用いることはなかった. このようにして, 表向きに極限を用いずとも, 関数の連続性の定義ができたということが, \\(\\epsilon-\\delta\\) 論法の主要な存在意義の 1 つである 3 . ところで, この「任意の実数 \\(&#94;\\forall x\\in\\mathbb{R}\\) に対して, \\(\\left|x-c\\right|\\lt\\delta\\) を満たすならば, すべての正の実数 \\(\\epsilon\\) に対して \\(\\left|f(x)-L\\right|\\lt\\epsilon\\) を満たすような \\(\\delta\\) が存在する.」というのは, \\(x\\) を \\(c\\) に近づけていくとき, \\(f(x)\\) 自体が \\(L\\) と同じであろうがなかろうが, \\(L\\) でない他のどのような値と比べても, より \\(L\\) に近づいていくものであるともいえる. そのようにより近づいていく値を, その値そのものと同値であるとみなすことが, \\(\\epsilon-\\delta\\) 論法における極限であるともいえるのである. つまり, \\(\\epsilon-\\delta\\) 論法は, どんなに小さな任意の \\(\\epsilon\\) を考えても, \\(\\left|x-c\\right|\\lt\\delta\\) であるとき, \\(\\left|f(x)-L\\right|\\lt\\epsilon\\) になるような \\(\\delta\\) があるならば, 関数 \\(f(x)\\) の \\(x\\to c\\) の極限値 \\(\\displaystyle\\lim_{x\\to c}f(x)\\) を \\(L\\) と同値とみなす . より一般的な変数変換 極限に関して厳密な定義ができたところで, 本題に入るが, 問題そのものを的確に把握することは, 問題を解く上で最も重要な過程であるので, 異なる座標系への移行という行為が一体どういうことなのかについてここで整理しておく. 異なる座標系への移行とは何か 唐突であるが, \\(D\\) を \\(x,y\\) 平面の閉領域として, \\[ \\int\\int_{D}(x-y)e&#94;{x+y}dxdy, D=\\left\\{(x,y)|0\\leq x+y\\leq 2, 0\\leq x-y\\leq 2\\right\\} \\] の積分値を計算せよと言われたら, どのように解けば良いのだろうか. そのまま計算するよりも, \\(u=x+y,v=x-y\\) とおくと楽なので, いま\\(D\\) に変わる新しい領域 \\(E\\) を \\(u,v\\) 平面の閉領域として \\[ \\int\\int_{E}ve&#94;ududv, E=\\left\\{(u,v)|0\\leq u\\leq 2,0\\leq v\\leq 2\\right\\} \\] と書きたくなるが, この積分値は元の領域と等しくない 4 . 1 次元のときの変数変換を思い出せば, 例えば \\(x=\\phi(t)\\) と変数変換したときに, \\[\\displaystyle\\int_{x_1}&#94;{x_2}f(x)dx\\not =\\int_{t_1}&#94;{t&#94;2}f(\\phi(t))dt\\] で \\[\\displaystyle\\int_{x_1}&#94;{x_2}f(x)dx =\\int_{t_1}&#94;{t&#94;2}f(\\phi(t))\\phi'(t)dt\\] だったのと同様, 変数変換における双方の対応関係から成る比率で, 埋めあわせをしなければならなかった. 2 重積分においてこの比率は, 元の領域との 面積比 に相当することになる. つまり, その一般解を得ることで, 異なる座標系間での移行が可能となるのである. 幾何学的なアプローチ 微積分学的な言葉を使ったアプローチを行う前に, 図形的意味を重視してまず書くこととする. そもそも重積分というのは, ある座標系における微小面積と, ある関数 \\(f\\) との値の積の総和の極限を取ることであった. \\(u,v\\) 座標系というものがあれば, その座標系/定義域における微小面積で, 今述べた操作を行うのである. というわけで, まず直交座標から一般の座標系への写像となる関数を, \\(x=\\phi(u,v), y=\\psi(u,v)\\) として考察することとする. 早速であるが, \\(u\\) とそこから少し動いた \\(u+\\Delta u\\), \\(v\\) とそこから少し動いた \\(v+\\Delta v\\) から成る四角形について考える. これが, \\(u,v\\) 座標系における微小面積である. この四角形のそれぞれの頂点は, 直交座標の言葉で(\\(\\phi, \\psi\\) 関数を使って), \\begin{array}{l} O\\left(\\phi(u,v),\\psi(u,v)\\right) \\\\\\ A\\left(\\phi(u+\\Delta u, v), \\psi(u+\\Delta u,v)\\right) \\\\\\ B\\left(\\phi(u,v+\\Delta v), \\psi(u,v+\\Delta v)\\right) \\\\\\ C\\left(\\phi(u+\\Delta u,v+\\Delta v), \\psi(u+\\Delta,v+\\Delta v)\\right) \\end{array} などと書き表わせる(頂点それぞれに, 適当に記号を割り振った. また, わかり易さのために頂点 \\(C\\) を書いたが, 今回これは使わない). さて, これらの頂点から成る四角形は, 極限の基で近似的に平行四辺形となるということを予めここで言ってしまおう. 従って, その平行四辺形の面積 \\(S\\) を求めるために, \\(\\left(\\overrightarrow{OA}, \\overrightarrow{OB}\\right)\\) の行列式を求めることとする 5 . まず, \\(\\overrightarrow{OA}\\) について考える. これは単に, \\(A\\) の座標から \\(O\\) の座標を引けば良いが, これは 偏微分 そのもので, 線形近似により, \\begin{eqnarray} \\phi(u+\\Delta u, v)-\\phi(u,v)&\\approx&\\dfrac{\\partial \\phi}{\\partial u}\\Delta u \\\\\\ \\psi(u+\\Delta u, v)-\\psi(u,v)&\\approx&\\dfrac{\\partial \\psi}{\\partial u}\\Delta u \\end{eqnarray} と書ける. 従って, \\(\\overrightarrow{OB}\\) についても同様に, \\begin{eqnarray} \\overrightarrow{OA}&\\approx&\\left(\\dfrac{\\partial \\phi}{\\partial u}\\Delta u,\\dfrac{\\partial \\psi}{\\partial u}\\Delta u\\right) \\\\\\ \\overrightarrow{OB}&\\approx&\\left(\\dfrac{\\partial \\phi}{\\partial v}\\Delta v,\\dfrac{\\partial \\psi}{\\partial v}\\Delta v\\right) \\end{eqnarray} と書ける. あとは, これらから成る行列の行列式の絶対値を求めれば良いから, \\begin{eqnarray} S&\\approx&\\left|{\\rm det}\\left( \\begin{array}{cc} \\dfrac{\\partial \\phi}{\\partial u}\\Delta u&\\dfrac{\\partial \\phi}{\\partial v}\\Delta v \\\\\\ \\dfrac{\\partial \\psi}{\\partial u}\\Delta u&\\dfrac{\\partial \\psi}{\\partial v}\\Delta v \\end{array} \\right)\\right| \\\\\\ &\\approx&\\left|{\\rm det}\\left( \\begin{array}{cc} \\dfrac{\\partial \\phi}{\\partial u}&\\dfrac{\\partial \\phi}{\\partial v} \\\\\\ \\dfrac{\\partial \\psi}{\\partial u}&\\dfrac{\\partial \\psi}{\\partial v} \\end{array} \\right)\\right|\\Delta u\\Delta v \\end{eqnarray} \\(\\Delta u, \\Delta v\\) の無限小の極限をとり, 微小増分の式に書き換えれば, \\begin{eqnarray} &\\approx&\\left|{\\rm det}\\left( \\begin{array}{cc} \\dfrac{\\partial \\phi}{\\partial u}&\\dfrac{\\partial \\phi}{\\partial v} \\\\\\ \\dfrac{\\partial \\psi}{\\partial u}&\\dfrac{\\partial \\psi}{\\partial v} \\end{array} \\right)\\right|dudv\\label{eq:jacobian}\\tag{1} \\end{eqnarray} \\(\\eqref{eq:jacobian}\\) の行列式の絶対値がヤコビアンである. いま求めた式 \\(\\eqref{eq:jacobian}\\) は, 後に述べている全微分といわれる操作に相当している. 全微分 全微分は, 偏微分に関してもう一度考えることで納得できる. (先に線形代数的アプローチで, 偏微分は自明なものとして使ってしまったが)そもそも偏微分はなんだったかといえば, 多変数関数の特定の変数以外を定数と捉えて微分することであった. つまり, 偏微分 \\(U\\) を \\(R&#94;n\\) の開部分集合とし, 函数 \\(f:U\\to R\\) に対して, \\({\\bf x}=\\left(x_1, \\cdots, x_n\\right) \\in U\\) の \\(i\\) 番目の変数 \\(x_i\\) における \\(f\\) の偏微分は \\[\\displaystyle \\dfrac{\\partial}{\\partial x_i}f({\\bf x}) := \\lim_{\\Delta x_i\\to 0}\\dfrac{f\\left(x_1,\\cdots,x_i+\\Delta x_i,\\cdots,x_n\\right)-f\\left(x_1,\\cdots,x_i,\\cdots,x_n\\right)}{\\Delta x_i}\\] である. 要するに, \\(f\\) が 2 変数関数であれば, \\begin{eqnarray} \\frac{\\partial f(x, y)}{\\partial x} &:=& \\lim_{\\Delta \\to 0} \\frac{f(x + \\Delta, y) - f(x, y)}{\\Delta}\\\\\\ \\frac{\\partial f(x, y)}{\\partial y} &:=& \\lim_{\\Delta \\to 0} \\frac{f(x, y + \\Delta) - f(x, y)}{\\Delta} \\end{eqnarray} である. これを踏まえて, 2 変数関数における全微分を導出することを考える. 簡単に言ってしまえば, 偏微分が 2 変数以上の関数のただ 1 つを変数とみなして, その微小変化に対する変化量を求めることであったのに対し, 全微分は, 全ての変数の微小変化に対する変化量を求めることである. まず変数 \\(x, y\\) が各々で微小量 \\(\\Delta x,\\Delta y\\) だけ変化するとき, その全体の変化量 \\(\\Delta f\\) を次のように表せる. \\begin{eqnarray} \\Delta f&=&f(x+\\Delta x, y+\\Delta y)-f(x,y) \\\\\\ &=&f(x+\\Delta x, y+\\Delta y)-f(x,y+\\Delta y)+f(x,y+\\Delta y)-f(x,y) \\label{eq:first}\\tag{2} \\end{eqnarray} 式 \\(\\eqref{eq:first}\\) の改行位置を変えるとわかりやすいが, \\begin{eqnarray} \\Delta f&=&f(x+\\Delta x, y+\\Delta y)-f(x,y+\\Delta y) \\label{eq:second}\\tag{3}\\\\\\ &+&f(x,y+\\Delta y)-f(x,y) \\label{eq:third}\\tag{4} \\end{eqnarray} いま, それぞれの部分に着目すると, \\(\\eqref{eq:second}\\) 部分は \\(x\\) のみを変化させたときの \\(f\\) の変化量で, \\(\\eqref{eq:third}\\) 部分は \\(y\\) のみを変化させたときの \\(f\\) の変化量となっていることがわかる. この式 \\(\\eqref{eq:first}\\) をさらに変形させると, \\begin{eqnarray} \\displaystyle \\Delta f&=&\\dfrac{f(x+\\Delta x, y+\\Delta y)-f(x,y+\\Delta y)}{\\Delta x}\\Delta x \\\\\\ &+&\\dfrac{f(x,y+\\Delta y)-f(x,y)}{\\Delta y}\\Delta y \\end{eqnarray} この式が微分の定義式と酷似していることに気づけば, \\(\\Delta x,\\Delta y\\) の無限小の極限をとり, 微小増分の式に書き換えて, \\begin{eqnarray} \\displaystyle df&=&\\lim_{dx,dy\\to 0}\\dfrac{f(x+dx, y+dy)-f(x,y+dy)}{dx}dx \\label{eq:fourth}\\tag{5} \\\\\\ &+&\\lim_{dx,dy\\to 0}\\dfrac{f(x,y+dy)-f(x,y)}{dy}dy \\label{eq:fifth}\\tag{6} \\end{eqnarray} \\(\\displaystyle\\lim_{dx,dy\\to 0}\\) を考えると, \\(\\eqref{eq:fourth}\\) 部分はもはや \\(\\displaystyle\\lim_{dx,dy\\to 0}\\dfrac{f(x+dx, y)-f(x,y)}{dx}\\) と同然であるので, すべての値 \\(\\eqref{eq:fourth},\\eqref{eq:fifth}\\) が, 特定以外の変数を変化させない微分となっていることがわかる. ここで, 記号 \\(\\partial\\) を導入して, いまの式を \\[df=\\dfrac{\\partial f}{\\partial x}dx+\\dfrac{\\partial f}{\\partial y}dy\\label{eq:sixth}\\tag{7}\\] と書くと, これが全微分/完全微分の定義になる. 多変数関数 \\(f\\) の無限小変化を式 \\(\\eqref{eq:sixth}\\) のように表せるとき, 多変数関数 \\(f\\) はその変数において全微分可能であるという. 全積分とヤコビアン 先に \\(x=\\phi(u,v), y=\\psi(u,v)\\) としていたので, \\(x,y\\) の全微分は \\begin{eqnarray} dx&=&\\dfrac{\\partial\\phi}{\\partial u}du+\\dfrac{\\partial\\phi}{\\partial v}dv \\\\\\ dy&=&\\dfrac{\\partial\\psi}{\\partial u}du+\\dfrac{\\partial\\psi}{\\partial v}dv \\end{eqnarray} となる. いまこれを行列で表すと, \\begin{eqnarray} \\begin{pmatrix} dx \\\\\\ dy \\end{pmatrix}= \\begin{pmatrix} \\dfrac{\\partial\\phi}{\\partial u}&\\dfrac{\\partial\\phi}{\\partial u} \\\\\\ \\dfrac{\\partial\\psi}{\\partial v}&\\dfrac{\\partial\\psi}{\\partial v} \\end{pmatrix} \\begin{pmatrix} du \\\\\\ dv \\end{pmatrix} \\end{eqnarray} となる. この行列の行列式 \\begin{eqnarray} {\\rm det} \\left( \\begin{array}{cc} \\dfrac{\\partial\\phi}{\\partial u}&\\dfrac{\\partial\\phi}{\\partial v} \\\\\\ \\dfrac{\\partial\\psi}{\\partial u}&\\dfrac{\\partial\\psi}{\\partial v} \\end{array} \\right) \\end{eqnarray} はヤコビアンといわれ(\\(\\eqref{eq:jacobian}\\) と同じ), \\(\\dfrac{\\partial(\\phi,\\psi)}{\\partial{u,v}}\\), また \\({\\rm J}(u, v)\\) と表される. 一般に, ヤコビアン \\(n\\) 変数関数の全微分を行列で表した式 \\begin{eqnarray} \\begin{pmatrix} f_1 \\\\ \\vdots \\\\ f_n \\end{pmatrix}= \\begin{pmatrix} \\dfrac{\\partial f_1}{\\partial x_1}&\\cdots&\\dfrac{\\partial f_1}{\\partial x_n} \\\\ \\vdots&\\ddots&\\vdots \\\\ \\dfrac{\\partial f_n}{\\partial x_1}&\\cdots&\\dfrac{\\partial f_n}{\\partial x_n} \\end{pmatrix} \\begin{pmatrix} dx_1 \\\\ \\vdots \\\\ dx_n \\end{pmatrix} \\end{eqnarray} の行列の行列式 \\begin{eqnarray} {\\rm det}\\left( \\begin{array}{ccc} \\dfrac{\\partial f_1}{\\partial x_1}&\\cdots&\\dfrac{\\partial f_1}{\\partial x_n} \\\\ \\vdots&\\ddots&\\vdots \\\\ \\dfrac{\\partial f_n}{\\partial x_1}&\\cdots&\\dfrac{\\partial f_n}{\\partial x_n} \\end{array}\\right) \\end{eqnarray} を \\(\\dfrac{\\partial(f_1,\\cdots,f_n)}{\\partial(x_1,\\cdots,x_n)}\\) また \\({\\rm J}(x_1,\\cdots,x_n)\\) と書く. 冒頭で述べた直交座標から極座標への変換をこのヤコビアンを使って導くならば, まず二次元直交座標系から二次元極座標系への対応関係は, \\begin{eqnarray} \\begin{pmatrix} x \\\\ y \\end{pmatrix}= \\begin{pmatrix} r \\cos\\theta \\\\ r \\sin\\theta \\end{pmatrix} \\end{eqnarray} で, 二次元極座標の変数は \\(r, \\theta\\) なのでこれをヤコビアンに与えて, \\begin{eqnarray} J(r,\\theta)={\\rm det}\\left(\\begin{array}{cc} \\cos\\theta & -r\\sin\\theta \\\\\\ \\sin\\theta & r\\cos\\theta \\end{array}\\right)=r \\end{eqnarray} 一般の 2 重積分は \\[\\int\\int_D f(x,y)dxdy=\\int\\int_E f\\left(\\phi(u,v),\\psi(u,v)\\right)J(u,v)dudv\\] なので, 極座標における全体の微小面積は \\(rdrd\\theta\\) となり, 冒頭で行った図形的解釈のもとに導き出した解と一致することがわかる. 「異なる座標系への移行とは何か」の冒頭で挙げた例題 \\[\\int\\int_{D}(x-y)e&#94;{x+y}dxdy, D=\\left\\{(x,y)|0\\leq x+y\\leq 2, 0\\leq x-y\\leq 2\\right\\}\\] も, \\(u=x+y, v=x-y\\) とおいてヤコビアンに与えれば, \\begin{eqnarray} {\\rm J}(u,v)&=&{\\rm det}\\left(\\begin{array}{rr} \\dfrac{1}{2}&\\dfrac{1}{2} \\\\\\ \\dfrac{1}{2}&-\\dfrac{1}{2}\\end{array}\\right)&=&-\\dfrac{1}{2} \\end{eqnarray} 絶対値を考えれば良いので, \\begin{eqnarray} &=&\\left|{\\rm det}\\left(\\begin{array}{rr} \\dfrac{1}{2}&\\dfrac{1}{2} \\\\\\ \\dfrac{1}{2}&-\\dfrac{1}{2}\\end{array}\\right)\\right|&=&\\dfrac{1}{2} \\end{eqnarray} \\begin{eqnarray} \\therefore\\int\\int_D(x-y)e&#94;{x+y}dxdy&=&\\int&#94;2_0\\int&#94;2_0ve&#94;u\\dfrac{1}{2}dudv \\\\\\ &=&\\dfrac{1}{2}\\int&#94;2_0\\left[ve&#94;u\\right]&#94;2_0dv \\\\\\ &=&\\dfrac{1}{2}\\int&#94;2_0\\left(ve&#94;2-v\\right)dv \\\\\\ &=&\\dfrac{1}{2}\\left[\\dfrac{e&#94;2}{2}v&#94;2-\\dfrac{1}{2}v&#94;2\\right]&#94;2_0 \\\\\\ &=&e&#94;2-1 \\end{eqnarray} 参考文献 \" Why Does dxdy = rdrd(theta)? Why Not Just drd(theta)? \" 2018 年 10 月 4 日アクセス. 「 GeoGebraを使ってε-δ論法を可視化してみた 」 2018 年 10 月 4 日アクセス. 「 微分の順序 」 2018 年 10 月 4 日アクセス. 「 全微分 」 2018 年 10 月 4 日アクセス. \" The Jacobian & Determinants - Euler, Erdős \" 2018 年 10 月 4 日アクセス. 図は matplotlib 等で 生成 . ↩ 図は draw.io で作成. ↩ 完全に蛇足であるが, 連続性の定義は, 他の様々な前提のための重要な要素となりうる. 例えば, いま, \\(f_x:=\\dfrac{\\partial f}{\\partial x}, f_y:=\\dfrac{\\partial f}{\\partial y}\\) という記法を導入すると, 関数 \\(f(x,y)\\) の偏導関数 \\(f_{x}(x,y), f_{y}(x,y)\\) がそれぞれ偏微分可能であるとき, 4 つの 2 次偏導関数, \\begin{eqnarray} f_{xx}&=&\\dfrac{\\partial&#94;2f}{\\partial x&#94;2}&=&\\dfrac{\\partial}{\\partial x}\\dfrac{\\partial f}{\\partial x} \\\\\\ f_{xy}&=&\\dfrac{\\partial&#94;2f}{\\partial y\\partial x}&=&\\dfrac{\\partial}{\\partial y}\\dfrac{\\partial f}{\\partial x} \\\\\\ f_{yx}&=&\\dfrac{\\partial&#94;2f}{\\partial x\\partial y}&=&\\dfrac{\\partial}{\\partial x}\\dfrac{\\partial f}{\\partial y} \\\\\\ f_{yy}&=&\\dfrac{\\partial&#94;2f}{\\partial y&#94;2}&=&\\dfrac{\\partial}{\\partial y}\\dfrac{\\partial f}{\\partial y} \\\\\\ \\end{eqnarray} を考えることができるが, \\(f\\) にこの \\(f_{xy}, f_{yx}\\) が存在して, ともに連続であるといえれば, 偏微分の順序交換法則(\\(f_{xy}=f_{yx}\\)) が成り立つことを示せる. この証明は, 平均値の定理 を補題として証明した上で行わなければならなく大変だが, 参考文献 にわかりやすい証明がされている. ↩ 正しい解答は末尾にて. ↩ 補足: 2 つの二次元ベクトル \\(a_1, a_2\\) から成る 2 次正方行列の行列式の絶対値は, \\(a_1,a_2\\) が定める平行四辺形の面積に等しいのであった. ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2018/10月/04/jacobian/","tags":"math","url":"posts/2018/10月/04/jacobian/","title":"ヤコビアン"},{"text":"当ブログ内でガウス積分(オイラー＝ポアソン積分)の公式を用いる際に self-contained でリファレンスを張るためと, 個人的な学習の記録として, 本エントリにてガウス積分の公式とその証明について書く 1 \\(.\\) 筆者自身にとっての分かりやすさを優先しているため, 若干冗長的な記述があるかもしれない点に注意. ガウス積分の公式 \\(x\\in\\mathbb{R}\\) のとき \\[\\displaystyle\\int_{-\\infty}&#94;{\\infty}e&#94;{-x&#94;2}dx=\\sqrt{\\pi}\\] 証明 : \\[I=\\displaystyle\\int_{-\\infty}&#94;{\\infty}e&#94;{-x&#94;2}dx\\] とおく. ここで, 最終的に \\(\\pi\\) を出現させるために, 直交座標系から極座標系への移行を行いたい. そのために, まず二乗して \\[I&#94;2=\\displaystyle\\left(\\int_{-\\infty}&#94;{\\infty}e&#94;{-x&#94;2}dx\\right)&#94;2= \\left(\\int_{-\\infty}&#94;{\\infty}e&#94;{-x&#94;2}dx\\right)\\cdot\\left(\\int_{-\\infty}&#94;{\\infty}e&#94;{-x&#94;2}dx\\right) \\] 文字を変えても積分値に変わりはないから \\[I&#94;2=\\left(\\int_{-\\infty}&#94;{\\infty}e&#94;{-x&#94;2}dx\\right)\\cdot\\left(\\int_{-\\infty}&#94;{\\infty}e&#94;{-y&#94;2}dy\\right)= \\int_{-\\infty}&#94;{\\infty}\\int_{-\\infty}&#94;{\\infty}e&#94;{-\\left(x&#94;2+y&#94;2\\right)}dxdy\\] \\(x=r\\cos\\theta,\\ y=r\\sin\\theta, dx\\ dy=rdrd\\theta\\) とし 2 \\begin{eqnarray} I&#94;2&=&\\int_{0}&#94;{2\\pi}\\int_{0}&#94;{\\infty}e&#94;{-r&#94;2}rdrd\\theta \\\\\\ &=&\\int_{0}&#94;{2\\pi}d\\theta\\int_{0}&#94;{\\infty}re&#94;{-r&#94;2}dr \\\\\\ &=&2\\pi\\left[\\dfrac{1}{2}e&#94;{-r&#94;2}\\right]&#94;{\\infty}_{0} \\\\\\ &=&\\pi \\end{eqnarray} もともと \\(I\\) は被積分関数の関数形であり, 定義域は \\(I > 0\\) だから, \\(I=\\sqrt{\\pi}\\). \\(\\square\\) 2 乗して \\(x&#94;2+y&#94;2=r&#94;2\\) 3 を出現させ, 極座標での表現を開始する流れは, 胸熱であった. さて, 以下はガウス積分の公式に関連した, いくつかの等式について示すこととする. ガウス積分の類似形 1 \\(x\\in\\mathbb{R}, a\\in\\mathbb{R}&#94;{+}\\) のとき, \\[\\displaystyle\\int_{-\\infty}&#94;{\\infty}e&#94;{-ax&#94;2}dx=\\sqrt{\\dfrac{\\pi}{a}}\\] 証明 : \\(y=\\sqrt{a}x, dy=\\sqrt{a}dx\\) とし, \\[\\int_{-\\infty}&#94;{\\infty}e&#94;{-ax&#94;2}dx=\\int_{-\\infty}&#94;{\\infty}e&#94;{-y&#94;2}\\cdot\\dfrac{1}{\\sqrt{a}}dy=\\dfrac{1}{\\sqrt{a}}\\int_{-\\infty}&#94;{\\infty}e&#94;{-y&#94;2}dy\\label{eq:first}\\tag{1}\\] \\(\\eqref{eq:first}\\) の最右辺をみると ガウス積分の公式 と全く同じなので, \\(\\eqref{eq:first}=\\sqrt{\\dfrac{\\pi}{a}}\\). \\(\\square\\) ガウス積分の類似形 2 \\(x\\in\\mathbb{R}, a\\in\\mathbb{R}&#94;{+}\\) のとき, \\[\\displaystyle\\int_{0}&#94;{\\infty}e&#94;{-ax&#94;2}dx=\\dfrac{1}{2}\\sqrt{\\dfrac{\\pi}{a}}\\] 証明 : 単に ガウス積分の類似形 1 の半分の領域となるだけなので, \\(\\displaystyle\\int_{0}&#94;{\\infty}e&#94;{-ax&#94;2}dx=\\dfrac{1}{2}\\sqrt{\\dfrac{\\pi}{a}}\\). \\(\\square\\) 参考文献 「 ガウス積分の公式の 2 通りの証明 」 2018 年 9 月 26 日アクセス. 「 C. 極座標 」 2018 年 9 月 26 日アクセス. 証明内では, フビニの定理 を暗黙に使っている. 恥ずかしながら, 筆者は測度論について全くの素人であるので, これを暗に用いることはあまりよくないと思うのだが, これが シグマの二重和が分解できることの一般形 であると理解して, 今回はこれを用いた. ↩ 補足: 極座標系において, \\(\\theta\\) の変域は \\([0,2\\pi]\\), \\(r\\) の変域は \\([0,\\infty]\\) である. また, 極座標での微小面積は \\(drd\\theta\\) ではなく \\(rdrd\\theta\\) であることに注意. これについては, 後日のエントリ, ヤコビアン にて取り扱っている. ↩ 一応書いておくと, この裏付けは三平方の定理より \\(\\cos&#94;2+\\sin&#94;2=1\\). ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2018/ 9月/26/GaussianIntegral/","tags":"math","url":"posts/2018/ 9月/26/GaussianIntegral/","title":"ガウス積分の公式とその証明"},{"text":"Haskell で低レイヤーのネットワークプログラミングをそういえばしたことがなかったので, 何か実装してみたかったのだが特別ネタも思いつかないので, とりあえずイーサヘッダ, IP ヘッダ等を含む, 生の ICMP Echo/Reply パケットを扱ってみることとした. ICMP パケットは IP パケットであるので, 通常は ICMP パケット部分のみを構築して PF_INET 等で開いたソケットに送りつけたり, recv 等すれば送受信においては必要十分であるが, これではあまり面白みがないので, リンクレイヤーから扱うこととした. 生の ICMP パケットを扱うということは, ICMP データの自作はもちろん, イーサヘッダ, IP ヘッダの自作が必要となる. またイーサヘッダを自作するということは, MAC アドレスを解決しなければならないので, 最低限 ARP パケットの送受信および解析機能の自作が必要となることを意味する. ARP パケットの自作を要するということは, デフォルトゲートウェイやサブネット環境などを取得する機能も必要である. これらを自作してみた. 環境 環境は, 本エントリ末尾に記載のリポジトリ内にある Vagrantfile の通りで, ごく普通の Ubuntu 18.04 仮想マシンである. テスト用途として, 同一プライベートネットワーク上にもう 1 つ同 OS のノードを用意している. ARP まずは冒頭で述べた理由より, ARP パケットの作成, 送受信および解析の機能を実装する必要がある. ARP に関しては, RFC 826 を再確認しつつ実装した. これは 以前 C++ で実装した ことがあったので, とくに困ることはなかったが, Haskell では, とくにリンクレイヤにおいては, その肝心なパケットの送受信の手段があまり充実していないようで, それには少々戸惑った. たとえば, 本エントリ執筆時点で, 同レイヤーのパケット送受信を Network.Socket モジュール等で実行することは不可能である. 当初は単に PF_PACKET , SOCK_RAW 等で開いたソケットに書き込もうと思っていたので, これは FFI で呼び出すしかないかと思ったが, ふと libpcap の Haskell ラッパーである pcap モジュールの存在を知り, これを利用させて頂くこととした. 今回簡単のため, ARP キャッシュを単に /proc/net/arp を読むことで済ませており, この点で手抜き仕様となっているので, 今後自前で ARP キャッシュを実装するか, /proc/net/arp との共和の良い方法を検討するかしたい. この実装による副産物として, 同一ネットワーク上の IP アドレスを指定すると, その MAC アドレスが得られる arp-exe という小さなアプリケーションができた. $ sudo stack --allow-different-user exec arp-exe -- eth2 192 .168.33.12 # リポジトリ内記載の vagrant 環境上で Just 08 :00:27:8b:b4:ae サブネットの判定とデフォルトゲートウェイの取得 目的対象ノードの MAC アドレスを取得する必要性は先に述べた通りで, いまそれが同一ネットワーク上にあるならば, 単にそのノードを指定して ARP を送出すればよいのであるが, そうでない場合, デフォルトゲートウェイに委託しなければならない 1 . よって, まず実行ホストの NIC に対応するデフォルトゲートウェイをルーティングテーブル等から知る必要がある. 今回は Linux 上での動作を前提としているので, /proc/net/route を読めばよい. 次に, 目的対象ノードが到達範囲内にあるかどうかを判定するために, 自身のサブネットを取得する必要がある. Linux 上でこれを行う方法としては, getifaddrs 等を呼び出すことが考えられるが, 既存のモジュール等でこれを自由に扱う手立てはどうにもないようであった. これは仕方がないので, FFI を利用して getifaddrs を呼び出し, 取得することとした. その他 その他はざっくりいえば, IP ヘッダ, ICMP データをそれぞれ RFC に記述のとおり並べたり, 読んだりすればよい. 結局, 詳細は下記リポジトリを参照されたい. 実装 実装は, 次のリポジトリで管理している. 冒頭でも述べた通り, リポジトリ内にある Vagrantfile の環境上で動作を確認している. falgon/network-basal - Low layer network packet utilities これには先に述べた arp-exe のほかに, 実行可能なアプリケーションとして, ping-exe と ping-exe2 が含まれている. ping-exe2 が本エントリで述べたように, イーサネットフレームを丸々扱い, ICMP Echo の送出および ICMP Echo Reply の受信を行う. $ sudo stack --allow-different-user exec ping-exe2 -- --help usage: ping-exe [ -c count ] [ -t timeout ] [ -i wait ] host $ sudo stack --allow-different-user exec ping-exe2 -- -c 1 8 .8.8.8 PING 8 .8.8.8: 56 data bytes 64 bytes from google-public-dns-a.google.com: icmp_seq = 1 ttl = 63 time = 11 .432482s --- ping statics --- 1 packets transmitted, 1 received, 0 % packet loss 一方, ping-exe は PF_INET で開いたソケットを利用して, つまり ICMP データのみを構築して ICMP Echo の送出および ICMP Echo Reply の受信を行う. 冒頭で述べたような立場からすれば, これの実装に対しては特に意味はないのであるが, 一応, 同様にして動くということをみるために作ってみた. 感想 Haskell でまとまったプログラムを書いたことは, 今回と エルガマル暗号の実装 以外ではあまりなかったため, 学びがあった. ネットワークに関しても, やはり実装することでかなり整理がついたように思える. リンクレイヤーも慣れてきた感じがあるので, 気が向き次第, 今度はルーターとかを作れればよいな等と思っている. これに関するコンパクトで的を得た回答: ARP request outside of LAN ; Target machine or router response? - Stack Exchange 2018 年 9 月 3 日アクセス. ↩","loc":"posts/2018/ 9月/15/scratchPacket/","tags":"Haskell","url":"posts/2018/ 9月/15/scratchPacket/","title":"Haskell でリンクレイヤーにおける ICMP パケットの構築, 送受信および解析による ping の実装"},{"text":"参考文献 1 では, 高木貞治氏の書いた 解析概論 の緒言として示されている三角関数の古典的な導入法の問題点と, それに対する合理的な導入, 定義に関する記述があり, 興味深かったので読んでいたのだが, ふと高校数学 Ⅲ の「普通な」加法定理や積和, 和積の公式, 導関数の導出などが頭から抜けていたので, 復習がてら書くことにした. 一応, このエントリで言う三角関数 \\(\\cos\\theta,\\sin\\theta\\) の定義は高校数学の範囲で言われる定義と同様であり, 次のとおりである. 高校数学における \\(\\cos\\theta,\\sin\\theta\\) の定義 直行座標平面上の原点 \\(O\\left(0,0\\right)\\) を中心とする半径 \\(1\\) の円 \\(C\\) の \\(x\\geq 0,y\\geq 0\\) の部分を \\(C_{+}\\) としたとき, 弧度法によると, 点 \\(A\\left(1,0\\right)\\), \\(C_{+}\\) 上の点 \\(P\\left(x,y\\right)\\) を角 \\(A O P\\) が \\(\\theta\\ \\left(0\\lt\\theta\\leq\\frac{\\pi}{2}\\right)\\) となるようにとれば, 孤 \\(A P\\) の長さは 角 \\(A O P\\) そのもの, すなわち \\(\\theta\\) である. このとき \\(x=\\cos\\theta,y=\\sin\\theta\\) である. よくよく考えてみれば, この定義 では, 孤 \\(A P\\) の長さおよび実数 \\(0\\lt\\theta\\leq\\frac{\\pi}{2}\\) に対し孤 \\(A P\\) の長さが \\(\\theta\\) となる \\(C_{+}\\) 上の点 \\(P\\) が存在することについて, 特に説明しておらず, 定義としては不十分な点があることが考えられる. 参考文献 1 にはこの問題に対する考察が綴られており, 読みやすい文体で書かれているので興味があれば読んでみることを勧める. 本エントリはそのような意味で, 特に面白みもなくただ単に高校数学 Ⅲ までの三角関数の内容を復習しているだけのものとなっているので, その点は悪しからず. 加法定理 この間で余弦定理を暗に認めたものとして利用する. 単位円上の二点 \\(P\\left(\\cos p,\\sin p\\right),Q\\left(\\cos q,\\sin q\\right)\\) がある. 上図のように, 原点 \\(O\\) に対し, \\(O P\\) と \\(x\\) 軸の成す角を \\(p\\), \\(O Q\\) と \\(x\\) 軸の成す角を \\(q\\) とする. 線分 \\(P Q\\) の長さを座標成分で表すと, \\begin{eqnarray} P Q&#94;2&=&\\left(\\cos q-\\cos p\\right)&#94;2+\\left(\\sin q-\\sin p\\right)&#94;2\\\\\\ &=&\\cos&#94;2 q-2\\cos q\\cos p+\\cos&#94;2 p+\\sin&#94;2 q-2\\sin q\\sin p+\\sin&#94;2 p\\\\\\ &=&\\left(\\sin&#94;2 p+\\cos&#94;2 p\\right)+\\left(\\sin&#94;2 q+\\cos&#94;2 q\\right)-2\\cos q\\cos p-2\\sin q\\sin p\\\\\\ &=&2-2\\left(\\sin p\\sin q+\\cos p\\cos q\\right)\\label{eq:first}\\tag{1} \\end{eqnarray} また, 余弦定理より \\begin{eqnarray} P Q&#94;2&=&O P&#94;2+O Q&#94;2-2 O P\\cdot O Q\\cos\\left(p-q\\right)\\\\ &=&1&#94;2+1&#94;2-2\\cdot 1\\cdot 1\\cdot \\cos\\left(p-q\\right)\\\\ &=&2-2\\cos\\left(p-q\\right)\\label{eq:second}\\tag{2} \\end{eqnarray} \\(\\eqref{eq:first},\\eqref{eq:second}\\) より \\[2-2\\cos\\left(p-q\\right)=2-2\\left(\\cos p\\cos q+\\sin p\\sin q\\right)\\leftrightarrow \\cos\\left(p-q\\right)=\\cos p\\cos q+\\sin p\\sin q\\label{eq:third}\\tag{3}\\] ここで, \\(\\eqref{eq:third}\\) の \\(q\\) を \\(q+\\frac{\\pi}{2}\\) とすると, 三角関数の定義より \\[ \\cos\\left\\{p-\\left(q+\\frac{\\pi}{2}\\right)\\right\\}=\\cos p\\cos\\left(q+\\frac{\\pi}{2}\\right)+\\sin p\\sin\\left(q+\\frac{\\pi}{2}\\right)\\leftrightarrow\\sin\\left(p-q\\right)=\\sin p\\cos q-\\cos p\\sin q \\] \\(q=-q\\) とおくと \\[\\sin\\left(p+q\\right)=\\sin p\\cos q+\\cos p\\sin q\\label{eq:fourth}\\tag{4}\\] \\(\\square\\) 三角関数の導関数 まず \\(f(x)=\\sin x\\) の導関数 \\(f'(x)\\) について, 導関数の定義より \\begin{eqnarray} f'(x)&=&\\lim_{h\\to 0}\\frac{f(x+h)-f(x)}{h}\\\\ &=&\\lim_{h\\to 0}\\frac{\\sin(x+h)-\\sin x}{h}\\\\ &=&\\lim_{h\\to 0}\\frac{\\sin x\\cos h+\\cos x\\sin h-\\sin x}{h}\\ \\because{\\rm 加法定理}\\ \\eqref{eq:fourth}\\ {\\rm より}\\label{eq:sixth}\\tag{5}\\\\ &=&\\lim_{h\\to 0}\\frac{\\sin x\\left(\\cos h-1\\right)+\\cos x\\sin h}{h}\\\\ &=&\\lim_{h\\to 0}\\left\\{\\frac{\\sin x\\left(\\cos h-1\\right)}{h}+\\frac{\\cos x\\sin h}{h}\\right\\}\\\\ &=&\\lim_{h\\to 0}\\left(\\sin x\\underbrace{\\frac{\\cos h - 1}{h}}_{A}+\\cos x\\frac{\\sin h}{h}\\right)\\label{eq:fifth}\\tag{6} \\end{eqnarray} 項 \\(A\\) について \\begin{eqnarray} \\frac{\\cos h-1}{h}\\cdot\\frac{\\cos h+1}{\\cos h+1}&=&\\frac{\\cos&#94;2h-1}{h\\left(\\cos h+1\\right)}\\\\ &=&\\frac{-\\sin&#94;2 h}{h\\left(\\cos h+1\\right)}\\ \\because\\sin&#94;2+\\cos&#94;2=1\\\\ &=&\\frac{-\\sin h\\cdot\\sin h}{h\\left(\\cos h+1\\right)}\\cdot\\frac{h}{h}\\\\ &=&-\\frac{\\sin h}{h}\\cdot\\frac{\\sin h}{h}\\cdot\\frac{h}{\\cos h+1} \\end{eqnarray} ここで, \\(\\displaystyle\\lim_{h\\to 0}-\\frac{\\sin h}{h}\\cdot\\frac{\\sin h}{h}\\cdot\\frac{h}{\\cos h+1}=0\\) だから, \\(\\eqref{eq:fifth}\\) より \\[f'(x)=\\sin x\\cdot 0+\\cos x\\cdot 1=\\cos x\\label{eq:tenth}\\tag{7}\\] 次に \\(f(x)=\\cos x\\) の導関数 \\(f'(x)\\) について, 導関数の定義より \\begin{eqnarray} f'(x)&=&\\lim_{h\\to 0}\\frac{f(x+h)-f(x)}{h}\\\\ &=&\\lim_{h\\to 0}\\frac{\\cos(x+h)-\\cos x}{h}\\\\ &=&\\lim_{h\\to 0}\\frac{\\cos x\\cos h-\\sin x\\sin h-\\cos x}{h}\\ \\because{\\rm 加法定理}\\ \\eqref{eq:third}\\ {\\rm より}\\label{eq:ninth}\\tag{8}\\\\ &=&\\lim_{h\\to 0}\\frac{\\cos x\\left(\\cos h-1\\right)-\\sin x\\sin h}{h}\\\\ &=&\\lim_{h\\to 0}\\left\\{\\frac{\\cos x\\left(\\cos h-1\\right)}{h}-\\frac{\\sin x\\sin h}{h}\\right\\}\\\\ &=&\\lim_{h\\to 0}\\left(\\cos x\\frac{\\cos h - 1}{h}-\\sin x\\frac{\\sin h}{h}\\right)\\\\ &=&\\cos x\\cdot 0-\\sin x\\cdot 1\\\\ &=&-\\sin x\\label{eq:eleventh}\\tag{9} \\end{eqnarray} 次に \\(f(x)=\\tan x\\) の導関数 \\(f'(x)\\) について, これは \\(f'(x)=\\left(\\tan x\\right)'=\\left(\\frac{\\sin x}{\\cos x}\\right)'\\) だから \\begin{eqnarray} f'(x)&=&\\left(\\frac{\\sin x}{\\cos x}\\right)'\\\\ &=&\\frac{\\left(\\sin x\\right)'\\cos x-\\sin x\\left(\\cos x\\right)'}{\\cos&#94;2 x}\\\\ &=&\\frac{\\cos x\\cos x-\\sin x\\left(-\\sin x\\right)}{\\cos&#94;2 x}\\ \\because\\eqref{eq:tenth},\\eqref{eq:eleventh}\\ {\\rm より}\\\\ &=&\\frac{\\cos&#94;2 x+\\sin&#94;2 x}{\\cos&#94;2 x}\\\\ &=&\\frac{1}{\\cos&#94;2 x} \\end{eqnarray} 最後に \\(f(x)=\\frac{1}{\\tan x}\\) の導関数 \\(f'(x)\\) について, これは \\(f'(x)=\\frac{1}{\\tan x}=\\left(\\frac{\\cos x}{\\sin x}\\right)'\\) だから \\begin{eqnarray} f'(x)&=&\\left(\\frac{\\cos x}{\\sin x}\\right)'\\\\ &=&\\frac{\\left(\\cos x\\right)'\\sin x-\\cos x\\left(\\sin x\\right)'}{\\sin&#94;2 x}\\\\ &=&\\frac{-\\sin x\\sin x-\\cos x\\cos x}{\\sin&#94;2 x}\\ \\because\\eqref{eq:tenth},\\eqref{eq:eleventh}\\ {\\rm より}\\\\ &=&-\\frac{\\sin&#94;2x+\\cos&#94;2x}{\\sin&#94;2x}\\\\ &=&-\\frac{1}{\\sin&#94;2x} \\end{eqnarray} 和積の公式を用いた方法 \\(\\eqref{eq:sixth},\\eqref{eq:ninth}\\) の部分では加法定理を用いたが, 加法定理より導出できる和積の公式を用いても同様にして導出できる. \\(\\eqref{eq:fourth}\\) より \\begin{eqnarray} \\sin\\left(p+q\\right)&=&\\sin p\\sin q+\\cos p\\sin q\\label{eq:seventh}\\tag{10}\\\\ \\sin\\left(p-q\\right)&=&\\sin p\\sin q-\\cos p\\sin q\\label{eq:eightth}\\tag{11} \\end{eqnarray} \\(\\eqref{eq:seventh}+\\eqref{eq:eightth}\\) より \\[\\sin\\left(p+q\\right)+\\sin\\left(p-q\\right)=2\\sin p\\cos q\\leftrightarrow \\sin p\\cos q=\\frac{\\sin\\left(p+q\\right)+\\sin\\left(p-q\\right)}{2}\\label{eq:thirteenth}\\tag{12}\\] また, \\(\\eqref{eq:third}\\) より \\begin{eqnarray} \\cos\\left(p+q\\right)&=&\\cos p\\cos q-\\sin p\\sin q\\label{eq:fifteenth}\\tag{13}\\\\ \\cos\\left(p-q\\right)&=&\\cos p\\cos q+\\sin p\\sin q\\label{eq:sixteenth}\\tag{14} \\end{eqnarray} \\(\\eqref{eq:fifteenth}-\\eqref{eq:sixteenth}\\) より \\[\\cos\\left(p+q\\right)-\\cos\\left(p-q\\right)=-2\\sin p\\sin q\\leftrightarrow \\sin p\\sin q=-\\frac{\\cos\\left(p+q\\right)-\\cos\\left(p-q\\right)}{2}\\label{eq:seventeenth}\\tag{15}\\] \\(\\eqref{eq:thirteenth},\\eqref{eq:seventeenth}\\) は積和の公式といわれる (あともう 1 つ積和の公式と言われるものがあるが, 今回は利用しないので省略). ここで, \\(\\eqref{eq:thirteenth}\\) に対し \\(p=\\frac{x-y}{2},q=\\frac{x+y}{2}\\) とすると, \\begin{eqnarray} \\sin\\frac{x-y}{2}\\cos\\frac{x+y}{2}&=&\\frac{\\sin\\left(\\frac{x-y}{2}+\\frac{x+y}{2}\\right)+\\sin\\left(\\frac{x-y}{2}-\\frac{x+y}{2}\\right)}{2}\\\\ &=&\\frac{\\sin x-\\sin y}{2} \\end{eqnarray} ゆえに \\[\\sin x-\\sin y=2\\cos\\frac{x+y}{2}\\sin\\frac{x-y}{2}\\label{eq:twelvth}\\tag{16}\\] また \\(\\eqref{eq:seventeenth}\\) に対し \\(p=\\frac{x+y}{2},q=\\frac{x-y}{2}\\) とすると, \\begin{eqnarray} \\sin\\frac{x+y}{2}\\sin\\frac{x-y}{2}&=&-\\frac{\\cos\\left(\\frac{x+y}{2}+\\frac{x-y}{2}\\right)-\\cos\\left(\\frac{x+y}{2}-\\frac{x-y}{2}\\right)}{2}\\\\ &=&-\\frac{\\cos x-\\cos y}{2} \\end{eqnarray} ゆえに \\[\\cos x-\\cos y=-2\\sin\\frac{x+y}{2}\\sin\\frac{x-y}{2}\\label{eq:fourteenth}\\tag{17}\\] \\(\\eqref{eq:twelvth},\\eqref{eq:fourteenth}\\) が和積の公式である (あともう 2 つ和積の公式と言われるものがあるが, 今回は利用しないので省略). \\(\\eqref{eq:twelvth}\\) をつかって \\(\\displaystyle f'(x)=\\lim_{h\\to 0}\\frac{\\sin\\left(x+h\\right)-\\sin x}{h}\\) を変形すると, \\begin{eqnarray} f'(x)&=&\\lim_{h\\to 0}\\frac{\\sin\\left(x+h\\right)-\\sin x}{h}\\\\ &=&\\lim_{h\\to 0}\\frac{2\\cos\\left(\\frac{2x+h}{2}\\right)\\sin\\frac{h}{2}}{h}\\ \\because\\eqref{eq:twelvth}\\\\ &=&\\lim_{h\\to 0}\\frac{\\cos\\left(\\frac{2x+h}{2}\\right)\\sin\\frac{h}{2}}{\\frac{h}{2}}\\\\ &=&\\cos\\left(\\frac{2x}{2}\\right)\\\\ &=&\\cos x \\end{eqnarray} と \\(\\eqref{eq:tenth}\\) と同様の結果が得られる. また, \\(\\eqref{eq:fourteenth}\\) をつかって \\(\\displaystyle f'(x)=\\lim_{h\\to 0}\\frac{\\cos\\left(x+h\\right)-\\cos x}{h}\\) を変形すると, \\begin{eqnarray} f'(x)&=&\\lim_{h\\to 0}\\frac{\\cos\\left(x+h\\right)-\\cos x}{h}\\\\ &=&\\lim_{h\\to 0}\\frac{-2\\sin\\left(\\frac{2x+h}{2}\\right)\\sin\\frac{h}{2}}{h}\\ \\because\\eqref{eq:fourteenth}\\\\ &=&\\lim_{h\\to 0}-\\frac{\\sin\\left(\\frac{2x+h}{2}\\right)\\sin\\frac{h}{2}}{\\frac{h}{2}}\\\\ &=&-\\sin\\left(\\frac{2x}{2}\\right)\\\\ &=&-\\sin x \\end{eqnarray} と \\(\\eqref{eq:eleventh}\\) と同様の結果が得られる. 参考文献 『 三角関数とは何か 』2018 年 9 月 6 日アクセス. 高木貞治 (1983) 『解析概論』岩波書店 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2018/ 9月/06/The_definition_of_Trignometric_function/","tags":"math","url":"posts/2018/ 9月/06/The_definition_of_Trignometric_function/","title":"三角関数の公式の導出"},{"text":"D-Bus とはメッセージバスシステムであり, アプリケーション間で互いにやりとりを行うためのプロセス間通信実装の 1 つである. システムデーモン(新しいハードウェアデバイスの追加やプリンタキューの変更などのイベント等)と, ユーザー単位のログインセッションデーモン(ユーザーアプリケーション間の一般的なIPC)を提供する 1 . 現代的な Linux カーネルの init プロセスにて起動される systemd デーモンおよびその補助デーモンは, D-Bus にいくつかの API を公開している. 私の観測範囲内において, C や Python, Go 等でこれらを利用する例はそこそこ見たことがあるのだが, Haskell での取り組みは一切見たことがなかったので, 少々これらで遊んで見た日記として本エントリに記す. D-Bus API の確認 実行環境は, 次の通りである. $ uname -a Linux vagrant 4 .15.0-20-generic #21-Ubuntu SMP Tue Apr 24 06:16:15 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux $ systemd --version systemd 237 +PAM +AUDIT +SELINUX +IMA +APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ +LZ4 +SECCOMP +BLKID +ELFUTILS +KMOD -IDN2 +IDN -PCRE2 default-hierarchy = hybrid D-Bus に公開されている API を利用する際は, とくに高度なラッパーライブラリを用いないような場合においては, dbus-send あるいは gdbus 等で全体の構造, インタフェース, メソッドおよびフィールドメンバーを確認するとよい. $ function syst (){ r = $( gdbus introspect --system --dest org.freedesktop.systemd1 --object-path /org/freedesktop/systemd1 ) ; echo ${ r } | head -n $1 && echo \"More than\" $(($( echo ${ r } | wc -l ) - $1 )) \"lines...\" ; } $ syst 10 node /org/freedesktop/systemd1 { interface org.freedesktop.DBus.Peer { methods: Ping () ; GetMachineId ( out s machine_uuid ) ; signals: properties: } ; interface org.freedesktop.DBus.Introspectable { methods: More than 397 lines... このインタフェース表記の意味するところに関する詳細は, D-bus 仕様の Type System セクション 2 に記載されている. D-Bus の Haskell バインドの利用 dbus が利用できる. 例えば, 以下に示す StartUnit , StopUnit は, $ gdbus introspect --system --dest org.freedesktop.systemd1 --object-path /org/freedesktop/systemd1 | grep -e StartUnit -e StopUnit -w -A 2 StartUnit ( in s arg_0, in s arg_1, out o arg_2 ) ; -- StopUnit ( in s arg_0, in s arg_1, out o arg_2 ) ; 次のようにして呼び出せる. {-# LANGUAGE OverloadedStrings #-} import DBus import DBus.Client import Data.Int ( Int32 ) type Unit = String type Mode = String type SignalNum = Int32 systemdObjectPath :: ObjectPath systemdObjectPath = objectPath_ \"/org/freedesktop/systemd1\" systemdInterfaceName :: InterfaceName systemdInterfaceName = interfaceName_ \"org.freedesktop.systemd1.Manager\" systemdDestination :: BusName systemdDestination = busName_ \"org.freedesktop.systemd1\" methodSub :: String -> MethodCall methodSub = methodCall systemdObjectPath systemdInterfaceName . memberName_ systemdCall :: Client -> MethodCall -> IO [ Variant ] systemdCall = ( . ) ( fmap methodReturnBody ) . call_ controlUnit :: String -> Client -> Unit -> Mode -> IO [ Variant ] controlUnit med cli unit mode = systemdCall cli ( methodSub med ) { methodCallDestination = Just systemdDestination , methodCallBody = map toVariant [ unit , mode ] } startUnit :: Client -> Unit -> Mode -> IO [ Variant ] startUnit = controlUnit \"StartUnit\" stopUnit :: Client -> Unit -> Mode -> IO [ Variant ] stopUnit = controlUnit \"StopUnit\" 以下に示す ListUnitsByNames 3 は, $ gdbus introspect --system --dest org.freedesktop.systemd1 --object-path /org/freedesktop/systemd1 | grep ListUnitsByNames -w -A 1 ListUnitsByNames ( in as arg_0, out a ( ssssssouso ) arg_1 ) ; 次のようにして呼び出せる. listUnitsByNames :: IsValue a => Client -> [ a ] -> IO [ Variant ] listUnitsByNames cli var = systemdCall cli ( methodSub \"ListUnitsByNames\" ) { methodCallDestination = Just systemdDestination , methodCallBody = [ toVariant var ] } 動作確認のためのユニットを適当に置いておく 4 . $ mkdir -p /opt/writehello/bin $ sudo sh -c \"echo \\\"#\\!/bin/bash\\nwhile :\\ndo\\n\\tsleep 3\\n\\techo \\\"hello\\\"\\ndone\\\"\" > writehello.sh $ sudo chmod +x /opt/writehello/bin/writehello.sh $ sudo sh -c \"echo \\\"[Unit]\\nDescription = hello daemon\\nConditionPathExists = /opt/writehello/bin/writehello.sh\\n\\n[Service]\\nExecStart = /opt/writehello/bin/writehello.sh\\nRestart = always\\nType = simple\\n\\n[Install]\\nWantedBy = multi-user.target\\\"\" > /etc/systemd/system/writehello.service $ sudo chmod -x /etc/systemd/system/writehello.service $ sudo chmod o-w /etc/systemd/system/writehello.service $ sudo systemd-analyze verify /etc/systemd/system/writehello.service Attempted to remove disk file system, and we can ' t allow that. $ sudo systemctl daemon-reload $ sudo systemctl start writehello.service && journalctl -f -u writehello.service & sleep 10 && sudo kill $! && sudo systemctl stop writehello.service [ 1 ] 2001 -- Logs begin at Fri 2018 -08-17 16 :19:05 UTC. -- Aug 17 16 :19:13 vagrant systemd [ 1 ] : Started hello daemon. Aug 17 16 :19:16 vagrant writehello.sh [ 1989 ] : hello Aug 17 16 :19:19 vagrant writehello.sh [ 1989 ] : hello Aug 17 16 :19:22 vagrant writehello.sh [ 1989 ] : hello 先の関数らから writehello.service ユニットを制御する. module Main where import DBus.Client ( connectSystem ) import System.Environment ( getArgs ) import Control.Monad ( mapM_ , ( <=< )) main :: IO () main = do client <- connectSystem args <- getArgs mapM_ ( print <=< flip ( startUnit client ) \"replace\" ) args print =<< listUnitsByNames client args 引数に writehello.service を指定してスーパーユーザで実行すると, 次のような出力が得られる. [ Variant ( ObjectPath \"/org/freedesktop/systemd1/job/1053\" )] [ Variant [( \"writehello.service\" , \"hello daemon\" , \"loaded\" , \"active\" , \"running\" , \"\" , ObjectPath \"/org/freedesktop/systemd1/unit/writehello_2eservice\" , 0 , \"\" , ObjectPath \"/\" )]] 停止も忘れずに. mapM_ ( print <=< flip ( stopUnit client ) \"replace\" ) args なお, 本エントリにおける一連の実装とその他の systemd D-Bus API を利用したいくつかの snippets を, 下記リポジトリにて管理している. もしよければ. r0ki/systemdplhs - Snippets collection that controls systemd from D-Bus with Haskell. 説明は 公式ページ から. ↩ \" D-Bus Specification\", https://dbus.freedesktop.org/doc/dbus-specification.html#type-system 2018 年 8 月 17 日アクセス. ↩ Note: ListUnitsByName は systemd v230 以上を要する. ↩ systemd-analyze verify の結果で, Attempted to remove disk file system, and we can't allow that. というメッセージが出力されているが, これは systemd 237-4 および 238 でのバグ( #8592 )との報告がある. ↩","loc":"posts/2018/ 8月/17/controlSystemdByDBusAndHaskell/","tags":"Haskell","url":"posts/2018/ 8月/17/controlSystemdByDBusAndHaskell/","title":"Haskell で D-Bus から systemd unit を制御する"},{"text":"クラウド上でなにか作れというような大学の課題で, 入力パラメータに応じて AWS EC2 インスタンス及びネットワーク周辺と distcc の環境構築を実行して, その上で分散コンパイルをして S3 へアップロードできれば, そこそこクラウドでやった意味があるといえるのかななどと思いつき, 軽い気持ちで作ってみた記録. 構成 構成そのものはかなり単純だと思う. はじめに, いくつかのパラメータを指定する. 数は多いが, AWS EC2 の環境構築に最低限必要となるような要素に限られているはず. ここで指定したパラメータに応じて, 環境を構築する. その際, AWS のユーザーデータ 1 機能を使って, distcc とコンパイラ 2 のセットアップ, ホストインスタンス(実際にコンパイルを実行するインスタンス)の決定, 各インスタンスの環境構築における進捗の同期等を行い, ビルドスクリプトを実行する. 一応, ここに酷いアクティビティ図がある. 実装 実装は, 次のリポジトリで管理している. falgon/edcc - Simple and tiny comprehensive management tool for distributed compilation using distcc on AWS EC2 . まず, 起動したインスタンスのすべてに必要となるパッケージのインストールやセットアップを実行する必要があるが, これは構成にて述べたように, AWS EC2 の機能のうちの 1 つである, ユーザーデータ 1 を利用して実行することとした. 予め使用言語に対する指定として, Go で実装することを定められていたので, 今回の実装を Go で行ったことに対する深い意味合いは特別ないが, とりあえずそこまで深く考えず Go の便利な標準パッケージ, text/template を利用して, 一程度の情報伝達を行うこととした. text/template は, かなりお手軽に 設定ファイルの生成 のほか, トークンの衝突さえなければ, コードに直接埋め込むことができるので, それを元にコードの生成をすることもでき, 大変良い. ビルドスクリプトおよびセットアップスクリプトは, それぞれ, ビルド実行のスクリプト 3 と, ユーザーデータとして渡される, 必要パッケージのセットアップスクリプト 4 のことを示している. ビルドスクリプトは, 以下に示す変数を利用して任意に記述してもらう 5 ものとして, セットアップスクリプトは, 殆どの場合, 中身を弄る必要はないと思われる. 今のところ, 各スクリプトは bash スクリプトとして記述する必要がある. それぞれで利用できる変数は, 次の通りである. 大体各変数の予測はつくだろうし, 説明にもあるとおりなのだが, 一点, 必ずビルドスクリプト内に記述しなければならないのは, {{.build_success}} または {{.build_failed}} である. これは, {{.Include_WriteStatus}} を予め記述しておくことで利用できるようになる. それぞれビルドの成功, また失敗といった結果を通知するための命令(内部はただの bash 関数)であるが, このどちらをも指定しなかった場合, ビルドはまだ終わっていないと認識して, 永遠に停止することはない(マネジメントコンソールや awscli などで自分でクリーンナップを行う必要がある.). この仕様は, Travis CI を利用しているときに, ステータスコードが 0 以外の場合においても, 処理を続行したいときが個人的には何度かあったことに由来している. また, セットアップの進捗をインスタンス間でどのように同期するかであるが, EC2 においても各メタ情報を HTTP リクエストで取得できることを真似て, 各インスタンスで nginx による HTTP サーバ 6 を稼働させ, そのトップページに自身の状態の JSON を出力しておき, それを curl で得るということにした. 結局, そのほかの詳細はリポジトリ内の README を見てほしい. 実行例は次の通りである. 感想 とにかく時間のない中であったので, 妥協してしまった点がいくらかあり, その点で個人的には悔しい部分があるが, 今回の実装で大分総合的に EC2 関係の IaaS やら SaaS 周りを活用できたかと思うので, 取り組めたこと自体には満足をしている. 別の話題だが, 講義内で利用する AWS リソースの支払いは, ありがたい事に大学側が持っていてくれていたのだが, これでもう講義が終わってしまうので, 犬が西向きゃ尾は東というものであるが, 続けて自分で本格的に取り組むのには, ある程度の出費が必要となる. 今のところ, まだ無料利用枠は残っているので, それを利用できることが救いであるが, 講義でよく使っていた t2.medium と無料利用枠対象の t2.micro とでは, やはり処理性能に若干の違いを感じる. なんだか今回のエントリには, やたらと諺が出てきて自分も奇怪に感じるが, まあこれは, 起きて半畳寝て一畳, 天下取っても二合半ということなのだろう. \" Running Commands on Your Linux Instance at Launch\" https://docs.aws.amazon.com/ AWSEC2 /latest/UserGuide/user-data.html 2018 年 8 月 15 日アクセス. ↩ ↩ デフォルト( setup.sh )では GCC 8.1.0 ↩ 例として, 厳密性を多いに省けば, Travis CI で実行される, .travis.yml の script セクションようなもの. ↩ 同じく, Travis CI で実行される, .travis.yml の install セクションのようなもの. ↩ build_script_example/ にいくつかのサンプルがある. ↩ このとき 80 番ポートを利用するが, デフォルトの設定では VPC を 10.0.0.0/16, サブネットを 10.0.0.0/24 とし, 80 番ポートのインバウンド設定を, セキュリティグループにより 10.0.0.0/24 と設定するので, 外部からの HTTP アクセスに対して応答することはない. よって, インスタンスの状態がインターネットに漏れてしまうといった懸念は必要ない. なお自動構築時, このサブネット中にすべてのインスタンスを設定するため, 自ずと分散コンパイルを行うインスタンスの最大数は 256 となる. それよりも増やしたいのであれば, 単にパラメータを変えればよいが, あまり台数を増やしても, 然程効果はないと思われる. ↩","loc":"posts/2018/ 8月/15/aws_ec2_distcc/","tags":"golang","url":"posts/2018/ 8月/15/aws_ec2_distcc/","title":"AWS EC2 の各種環境を自動構築して distcc による分散コンパイルを実行する"},{"text":"ウェブアプリケーションが EC2 上で動作していて, そのコンテンツ内容を S3 バケットによって管理しているシチュエーションにおいて, S3 バケットの状態を即座にそのウェブアプリケーションに反映させたいという事例はよくあると思う(ステージング云々は, 一旦置いておくとして). 本エントリは, AWS SNS による HTTP リクエストをトリガーに, S3 バケットの状態を EC2 上のコンテンツへ即座に反映するための構造と簡単な実装について取り上げる. システムの全体構造 上記の要件を達成する方法はいくつかあるだろうが, 今回は次のような構造を取ることとした. 今回 EC2 インスタンス上では, Nginx および Go で実装したウェブアプリケーションサーバを Fast- CGI で動かすこととした. S3 にコンテンツをアップロードしたり削除等の操作をすると, SNS トピックに対して通知を発行する. SNS はこれに対して, 設定したエンドポイント(今回は EC2 インスタンス) へ HTTP POST リクエストを発行し, EC2 インスタンスはこれに応じて, S3 バケットと同期を実行する. 至ってシンプルな構造である. 実装 EC2 インスタンスで稼働するシンプルなウェブサーバの実装, および各種設定ファイルは, 次のリポジトリの通りである. falgon/tinyGoWebServer - Tiny Go Web Server. AWS SNS + S3 + EC2 + Nginx Fast- CGI technology automatically synchronizes content on S3 bucket. なお, S3 バケットとの同期処理が失敗した場合, 別の SNS トピックを用いて, 失敗の旨のメールを管理者に送信するようにしてある. リポジトリ内の README にも記してあるが, 同期を実行するスクリプト, およびウェブサーバの実行ファイルは, systemd で管理することを前提として, Filesystem Hierarchy Standard に従い, 配置することとした.","loc":"posts/2018/ 8月/01/aws_sns_s3_ec2/","tags":"golang","url":"posts/2018/ 8月/01/aws_sns_s3_ec2/","title":"AWS SNS + S3 でバケット内の状態を即座に EC2 に反映するまで"},{"text":"ベイズの定理の導出から, モンティ・ホール問題への応用まで. ベイズの定理の導出 事象 \\(A\\) が発生する確率を「\\(P(A) = A\\) が発生する確率 \\(\\div\\) すべての事象の数」と書くとき, ベイズの定理は ベイズの定理 事象 \\(B\\) のもとで事象 \\(A\\) が発生する確率 \\[P(A\\mid B)=\\dfrac{P(B\\mid A)P(A)}{P(B)}\\ \\left(P(B)\\gt 0\\right)\\] と定義される. 以下ベイズの定理を導出する. 例として, 起こり得る全ての事象の数を \\(200\\) , 事象 \\(A\\) , 事象 \\(B\\) (以下単に \\(A\\) , \\(B\\) と書く)が発生した回数をそれぞれ \\(60,\\ 40\\) とし, \\(A\\) および \\(B\\) が発生した確率を \\(10\\) とする. 簡単のために, この事象関係を表すベン図を次に示す 1 . まず, \\(A\\) および \\(B\\) が発生する確率 \\(P(A\\cap B) = P(B\\cap A)\\) を求める. \\(A,\\ B\\) がそれぞれ発生する確率は, \\begin{array}{lcl} P(A)&=&\\dfrac{60}{200}=\\dfrac{3}{10}\\\\\\ P(B)&=&\\dfrac{40}{200}=\\dfrac{1}{5} \\end{array} である 2 . \\(B\\) の下で \\(A\\) が発生する確率と, \\(A\\) の下で \\(B\\) が発生する確率は, \\begin{array}{lclcl} P(A\\mid B)&=&\\dfrac{10}{40}&=&\\dfrac{1}{4}\\\\\\ P(B\\mid A)&=&\\dfrac{10}{60}&=&\\dfrac{1}{6} \\end{array} である. そもそも, \\(B\\) が発生しなければ, \\(A\\) および \\(B\\) が発生するということはないし, \\(A\\) が発生しなければ, \\(B\\) および \\(A\\) が発生するということはないので, \\begin{array}{lclclcl} P(A\\cap B)&=&P(A\\mid B)P(B)&=&\\dfrac{1}{4}\\cdot\\dfrac{1}{5}&=&\\dfrac{1}{20}\\\\\\ P(B\\cap A)&=&P(B\\mid A)P(A)&=&\\dfrac{1}{6}\\cdot\\dfrac{3}{10}&=&\\dfrac{1}{20} \\end{array} である. あとは変形すれば良いだけで, \\begin{array}{lcl} P(A\\mid B)P(B)&=&P(A\\cap B)\\\\\\ P(A\\mid B)&=&\\dfrac{P(A\\cap B)}{P(B)}\\\\\\ P(A\\mid B)&=&\\dfrac{P(B\\mid A)P(A)}{P(B)} \\end{array} モンティ・ホール問題 確率論的な話となるとよく挙げられる有名な問題, モンティ・ホール問題をベイズの定理で解く. モンティ・ホール問題は, (snip)プレーヤーの前に閉まった3つのドアがあって、1つのドアの後ろには景品の新車が、2つのドアの後ろには、はずれを意味するヤギがいる。プレーヤーは新車のドアを当てると新車がもらえる。プレーヤーが1つのドアを選択した後、司会のモンティが残りのドアのうちヤギがいるドアを開けてヤギを見せる。 ここでプレーヤーは、最初に選んだドアを、残っている開けられていないドアに変更してもよいと言われる。プレーヤーはドアを変更すべきだろうか？(snip) ゲームのルール: 3つのドア (A, B, C) に（景品、ヤギ、ヤギ）がランダムに入っている。 プレーヤーはドアを1つ選ぶ。 モンティは残りのドアのうち1つを必ず開ける。 モンティの開けるドアは、必ずヤギの入っているドアである。 モンティはプレーヤーにドアを選びなおしてよいと必ず言う。 — モンティ・ホール問題 - wikipedia いま, この問題をモンティがヤギのドアを開けた後に, プレーヤーが景品のドアを開ける条件付き確率問題とし, プレーヤーが初手で \\(A\\) を選択, それに対しモンティが \\(B\\) を選択したとする 3 . モンティが \\(B\\) を選択したということは, 景品のドアは \\(A\\) または \\(C\\) である. すなわち, プレーヤーが \\(A\\) を選択し, この選択を変えずに \\(A\\) が景品のドアである確率は \\(P(A\\mid B)\\), 選択を変え \\(C\\) が景品のドアである確率は \\(P(C\\mid B)\\) と書ける. このそれぞれの条件付き確率を, 上で導出したベイズの定理の式に当てはめて求めればよい 4 . モンティは, プレーヤーが選択した \\(2\\) つのドア以外のどちらかを選択するから, \\(P(B)=\\dfrac{1}{2}\\) である. プレーヤーが初手で選ぶ段階では, 景品のドアを選ぶ確率は均等であるから, \\(P(A)=P(C)=\\dfrac{1}{3}\\) である. これらを基に, まず \\(P(A\\mid B)\\) について式にすると, \\begin{array}{lclclcl} P(A\\mid B) &=& \\dfrac{P(B\\mid A)P(A)}{P(B)} &=& \\dfrac{\\dfrac{1}{2}\\cdot\\dfrac{1}{3}}{\\dfrac{1}{2}}&=&\\dfrac{1}{3} \\end{array} \\(P(A\\mid B)\\) とは先も述べたように, \\(A\\) が景品のドアであると踏んだときに, それが景品のドアである確率である. よって, \\(A\\) が景品のドアであれば, モンティは \\(B\\) と \\(C\\) どちらを選択しても良いことになるので, \\(P(B\\mid A)=\\dfrac{1}{2}\\) である. から上式のようになる. 次に, \\(P(C\\mid B)\\) について式にすると, \\begin{array}{lclclcl} P(C\\mid B) &=& \\dfrac{P(B\\mid C)P(C)}{P(B)}&=&\\dfrac{1\\cdot \\dfrac{1}{3}}{\\dfrac{1}{2}}&=&\\dfrac{2}{3} \\end{array} \\(P(C\\mid B)\\) とは先も述べたように, \\(C\\) が景品のドアであると踏んだときに, それが景品のドアである確率である. よって, \\(C\\) が景品のドアであれば, モンティは \\(B\\) しか選ぶことができないから, \\(P(B\\mid C)=1\\) である. から上式のようになる. よって, ドアの選択を変えるべきであるという解が導かれる. Wikipedia にも似たような図があるが, 折角なので, \\(1000\\) 回モンティ・ホール問題を試行した場合において, 選択を変えて景品のドアを当てた回数と, 選択を変えずに景品のドアを当てた回数をプロットしてみた 5 . 当たり前ではあるのだが, この図からも, \\(C\\) に変えた方が当たる回数が多くなっていることを確認できる. 図は matplotlib_venn 他で 生成 . ↩ 自明であるが, これを \\(P(A)=P(A\\mid\\Omega), P(B)=P(B\\mid\\Omega)\\) と書くこともできる. ↩ 他のどのようなドアの組み合わせをとっても, プレーヤーが \\(1\\) つドアを選択し, モンティが \\(1\\) つヤギのドアを選択するという規則には影響しないから, この前提による一般性の欠如を懸念する必要はない. ↩ 注: 一応述べておくと, ベイズの定理で使われている変数 \\(A, B, C\\) は, このドア \\(A, B, C\\) とは無関係である. ↩ 図は matplotlib で 生成 . ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2018/ 7月/26/bayestheorem/","tags":"math","url":"posts/2018/ 7月/26/bayestheorem/","title":"ベイズの定理"},{"text":"以前の記事, エルガマル暗号 では, エルガマル暗号に関する諸々の前提の説明と, その実装について示した. 同エントリ内で, フェルマーの小定理 1 については取り扱ったものの, その一般形であるオイラーの定理およびカーマイケルの定理について 特に触れなかった ため, 本エントリでそれらに関してまとめる. しばしば値の確認には, 簡単のため Haskell を使う. オイラーの定理 いま, フェルマーテスト を定義したとき, \\(FT_n(a)\\) をパスするには(すなわち, フェルマーの小定理が示す合同式が成り立つには), 要件として, 既約剰余類郡 \\(\\mathbb{Z}&#94;{\\ast}_n\\) の各要素と \\(&#94;\\exists a\\ \\in\\mathbb{Z}\\) の積が全て異なり, \\(\\bmod n\\) の既約代表系のすべての積と合同でなければならない. たとえば, 法 \\(n=8\\) による合同関係で構成する剰余類の完全代表系 2 は \\(0,1,2,3,4,5,6,7\\) であるが, \\(a=2\\) としてしまうと, 既約剰余類郡が構成できていないので, 次のようにしても完全代表系が得られない(積をわざわざ示していないが, 非合同でないことは, 各要素の積が全て異なっていない時点で明白である). Prelude > [ x * 2 ` rem ` 8 | x <- [ 0 .. 7 ]] [ 0 , 2 , 4 , 6 , 0 , 2 , 4 , 6 ] そこで, 先に述べた剰余類の既約代表系を考える. これは \\(\\phi(8)=4\\) 個 3 で, \\(1,3,5,7\\) である. これを同じように, \\(\\left\\{1\\cdot a,\\ 3\\cdot a,\\ 5\\cdot a,\\ 7\\cdot a\\right\\}\\) とし, 先の要件を確認すると, この補題2 より, \\(\\bmod 8\\) で全体として \\(\\left\\{1,3,5,7\\right\\}\\) と一致していて, \\[1\\cdot 3\\cdot 5\\cdot 7\\equiv 1\\cdot 3\\cdot 5\\cdot 7\\cdot a&#94;4\\pmod{8}\\label{eq:first}\\tag{1}\\] \\(\\gcd(1\\cdot 3\\cdot 5\\cdot 7,8)=1\\) だから, \\(1\\cdot 3\\cdot 5\\cdot 7\\) を約して, \\[a&#94;4\\equiv 1\\pmod{8}\\label{eq:second}\\tag{2}\\] これは, \\(\\gcd(a,n)=1\\) ということの他に, \\(a\\) および \\(n\\) の値に依存した論ではない. すなわち, オイラーの定理 \\[a&#94;{\\phi(n)}\\equiv 1\\pmod{n}\\ \\left(2\\leq n\\in\\mathbb{Z}&#94;{+},\\ \\gcd(a,n)=1\\right)\\] がいえる 4 . * Main > euler'sTheorem n = [ a ` modExp ` ( totient n ) $ n | a <- [ 2 .. ], gcd a n == 1 ] * Main > all ( == 1 ) $ take 100 $ euler'sTheorem 8 True \\(n\\) が素数 \\(p\\) であるとき, \\(\\phi(p)=p-1\\) で, フェルマーの小定理 1 となる 5 . ラグランジュの定理 いま述べた オイラーの定理 は, ラグランジュの定理を使っても証明できる. ラグランジュの定理は, ラグランジュの定理 有限郡 \\(G\\) の部分郡 \\(H\\) の位数 \\(\\mid H\\mid\\) は, \\(G\\) の位数 \\(\\mid G\\mid\\) の約数となる. \\[\\mid G\\mid\\ =\\ \\mid G:H\\mid \\mid H\\mid\\] である. 証明 : 有限郡 \\(G\\) の部分郡 \\(H\\) による類別が \\(\\displaystyle G=\\bigcup_i&#94;r a_iH\\) であるとき, \\(\\mid G\\mid=r\\mid H\\mid\\) といえる. この \\(r\\) は \\(r=\\mid G:H\\mid\\) そのものなので, \\(\\mid G\\mid\\ =\\ \\mid G:H\\mid\\mid H\\mid\\). \\(\\square\\) ごく直感的な定理である. これを使えば, オイラーの定理 は次のように証明できる. 補題1 : 有限郡 \\(G\\) とその元 \\(&#94;\\forall g\\in G\\) に対し, \\(g&#94;{\\mid G\\mid}=e\\) . \\(e\\in G\\) は単位元. 証明 : 巡回部分郡 \\(H=\\lt g\\gt\\) の元 \\(g\\) の位数 \\(\\mid H\\mid\\) は, 巡回して \\(g&#94;i=e\\) となる最小の \\(i\\in\\mathbb{N}\\) であるといえる. すなわち \\[g&#94;{\\mid H\\mid}=e\\] ここで, 商集合の位数を両辺に次のように与える. \\[\\left(g&#94;{\\mid H\\mid}\\right)&#94;{\\mid G:H\\mid}=(e)&#94;{\\mid G:H\\mid}\\] 左辺は指数法則により, また右辺は単位元の繰り返しだから, これを次のようにかける. \\[g&#94;{\\mid H\\mid\\mid G:H\\mid}=e\\] ラグランジュの定理より \\[g&#94;{\\mid G\\mid}=e\\] \\(\\square\\) オイラーの定理の証明 : オイラーの定理 を仮定したとき, 脚注 2 より剰余類 \\(\\overline{a}\\) は法 \\(n\\) に関する既約剰余類郡 \\(\\mathbb{Z}&#94;{\\ast}_{n}\\) に含まれる. \\(\\mid\\mathbb{Z}&#94;{\\ast}_{n}\\mid=\\phi(n)\\) だから補題 1 より \\(\\overline{a}&#94;{\\phi(n)}=\\overline{a&#94;{\\phi(n)}}=\\overline{1}\\). \\(\\square\\) カーマイケルの定理 オイラーの定理 で用いる \\(\\phi\\) 関数は, \\(a&#94;{m}\\equiv 1\\pmod{n}\\ (m\\in{N}, \\gcd(a,n)=1\\) を成立させる最小の整数 \\(m\\) を持ち得ない. たとえば, \\(n=8\\) では, 先の通り確かに \\(m=\\phi(8)=4\\) で合同式が満足できたが, \\(m=2\\) としても, これを満足できる. * Main > all ( == 1 ) $ take 100 $ [ a ` modExp ` 2 $ 8 | a <- [ 2 .. ], gcd a 8 == 1 ] True カーマイケルの \\(\\lambda\\) 関数は, 与えられた整数 \\(n\\) に対して同合同式を満足する最小の \\(m\\) を定義より自明に与える. カーマイケルの \\(\\lambda\\) 関数 扱う文字を全て整数とし, \\(\\lambda(n)\\) は \\begin{array}{lcl} \\DeclareMathOperator{\\lcm}{lcm} \\lambda(1)&:=&1\\\\ \\lambda(2)&:=&1\\\\ \\lambda(4)&:=&4\\\\ \\lambda(2&#94;k)&:=&\\phi(2&#94;k)\\ \\left(0\\leq k\\leq 2\\right)\\\\ \\lambda(2&#94;k)&:=&2&#94;{k-2}=\\dfrac{\\phi(2&#94;k)}{2}\\ \\left(e\\geq 3\\right)\\\\ \\lambda(p&#94;h)&:=&\\phi(p&#94;h)=(p-1)\\cdot p&#94;{h-1}\\ \\left(p\\ is\\ an\\ odd\\ prime, h\\geq 1\\right)\\\\ \\lambda\\left(2&#94;kp_1&#94;{h_1}p_2&#94;{h_2}p_3&#94;{h_3}\\cdots p_t&#94;{h_t}\\right)&:=&\\lcm\\left(\\lambda(2&#94;k),\\lambda(p_1&#94;{h_1}),\\lambda(p_2&#94;{h_2}),\\lambda(p_3&#94;{h_3}),\\cdots,\\lambda(p_t&#94;{h_t})\\right)\\ \\left(p_n\\ is\\ an\\ odd\\ prime, k\\geq 0, h_n\\geq 1\\right) \\end{array} と定義する. カーマイケルの定理 \\[a&#94;{\\lambda(n)}\\equiv 1\\pmod{n}\\ (2\\leq n\\in\\mathbb{Z}&#94;{+},\\ \\gcd(a,n)=1)\\] 実装して確かめよう. * Main > let carmichael'sLambda n = head [ k | k <- [ 1 .. ], and [( m ` modExp ` k $ n ) < 2 | m <- [ 1 .. n ] gcd m n < 2 ]] * Main > let carmichael'sTheorem n = [ a ` modExp ` ( carmichael'sLambda n ) $ n | a <- [ 2 .. ], gcd a n == 1 ] * Main > all ( == 1 ) $ take 100 $ carmichael'sTheorem 8 True 証明: フェルマーの小定理 ↩ ↩ 補足. 郡 \\(G\\) とその部分郡 \\(H\\) があるとき, \\(H\\) は郡であるから単位元 \\(e\\in H\\) を含む. よって, \\(&#94;\\exists a\\in G\\) の剰余類を \\(aH=\\left\\{ah\\mid h\\in H\\right\\}\\) としたとき(簡単のため, 左剰余類として式をおいたが, これに深い意味はない.), \\(a=ae\\in aH\\) より \\(a\\in aH\\) である. この \\(a\\) を剰余類 \\(aH\\) の代表という. また郡 \\(G\\) は, 異なる \\(a_i\\) を代表とした剰余類 \\(a_iH\\) によって類別できる(\\(\\displaystyle G=\\bigcup_i a_iH\\)). この \\(\\mid G:H\\mid\\) 個の類別に対して, 各剰余類から代表の元を取り, 構成した集合を, \\(G\\) の \\(H\\) に対する代表系という. ↩ ↩ ここで, \\(\\phi\\) は, オイラーのトーシェント関数 . ↩ コード内の totient と modExp は, それぞれ以前の投稿のうち, オイラーのトーシェント関数の実装部分 と, カーマイケル数を得るための実装 を利用. ↩ この補足は冗長的かもしれないが, \\(n\\) が素数 \\(p\\) である場合, \\(\\mathbb{Z}_p&#94;{\\ast}\\) が構成されるから, これから取った代表は素数 \\(p\\) と互いに素であることから, 既約代表である. この事実も, 一般に \\(\\eqref{eq:first}\\) から \\(\\eqref{eq:second}\\) へのような式変形が実行できることとの整合を示す. ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2018/ 7月/25/EulersAndCarmichelsTheorem/","tags":"math","url":"posts/2018/ 7月/25/EulersAndCarmichelsTheorem/","title":"オイラーの定理とカーマイケルの定理"},{"text":"本エントリでは, VPC - EC2 で MASTER 側のヘルスが確認できなくなったときに, VRRP を用いてフェールオーバし, 一定度の可用性担保を実現する場合について 1 取り上げる. VRRP の実装としては keepalived を用いることとする. 前提 次のシチュエーションを前提としている. インスタンスが 2 つ以上作成済みで, 24, 80 番ポートを SG の設定で開けてあり, どちらにおいても apache2 と keepalived が稼働している. keepalived.conf にそれぞれ MASTER と BACKUP が設定済みで, VPC - EC2 のルートテーブルにて, いまの設定にあわせて 1 つに VIP (192.168.1.1/32) が設定してある. このシチュエーションがオンプレミス環境上の話であれば, 何の問題もなく, これでフェールオーバが実現できるのだが, AWS EC2 でこれを実現するためには, AWS のルートテーブル側の VIP ターゲットをも貼り直す操作が必要となり, この操作については, ある程度自分で実装しなければならない. いくらか調べて見ると, awscli で同様の環境を作っている事例を多く見るのだが, 本エントリでは諸事情より AWS SDK for go を使って, 操作することとした. 設定と実装 結論からいえば, keepalived はユニキャストに対応しているので, それらの設定を行い, 互いに監視して, MASTER または BACKUP となったときに自動でルートテーブルを操作すれば良い. もう少し細かく言えば, 冗長構成のうち監視対象となるインスタンスのプライベート IP を設定すれば良い. そのついでに, VIP が設定されていることを簡単に取得できるように, VIP が設定されたインスタンスにタグを設定するようにしたい. さらに, 毎度 keepalived.conf を作成するのは手間を要するので, 冗長構成の中から監視対象や VIP などを自動検出して, keepalived.conf を生成するようにもしたい. ということで, これらの要件を自動化するべく実装した. VKUVC - VPC - EC2 + Keepalived Utilities = VRRP on Cloud リポジトリには各種説明と, デモビデオへのリンクが貼ってある. もしよければ. 余談 今回 keepalived.conf の生成のために, はじめて text/template パッケージを用いた. といっても簡単な使い方しかしていないので, 今回のような事例の他にも, まだまだ応用範囲は広そうだが, それにしても中々便利であった. また今回で golang を使ってなにかモノを作ったのは 2 回目 であるが, 段々と慣れてきたような気もする. とくに, AWS SDK に関しては, まあ元々使いやすいのは十分にあるのだが, 以前よりも大分勝手がわかってきた気がする. 普通にロードバランサもあるので, 選択肢としてこれに限るというわけではない. ↩","loc":"posts/2018/ 7月/23/ec2failover/","tags":"golang","url":"posts/2018/ 7月/23/ec2failover/","title":"VRRP on AWS VPC - EC2"},{"text":"学校の関係で MySQL を触る機会が増えてきたので, MySQL の C++ 向けライブラリを一度触っておこうという忘備録. sql_executor.hpp main.cpp Makefile docker-compose.yml これを実行すると, 次のように, 実在しそうでしなさそうな, 妙に怪しい雰囲気 1 の一覧が出力される. |顧客番号| C001 |氏名| 青山 花子 |郵便番号| 958-3626 |住所| 大分県横浜市瀬谷区台場12丁目23番18号 勝どきコーポ435 |電話番号| 090-3537-6380 |顧客番号| C002 |氏名| 廣川 翔太 |郵便番号| 297-3630 |住所| 群馬県西多摩郡奥多摩町平須賀14丁目5番2号 コーポ台東850 |電話番号| 88-1940-6921 |顧客番号| C003 |氏名| 田辺 浩 |郵便番号| 596-4390 |住所| 大分県いすみ市虎ノ門虎ノ門ヒルズ森タワー31丁目11番1号 |電話番号| 080-4923-6200 |顧客番号| C004 |氏名| 井上 知実 |郵便番号| 903-5859 |住所| 岩手県北区箪笥町7丁目6番2号 高田馬場クレスト753 |電話番号| 090-1267-5646 |顧客番号| C005 |氏名| 浜田 明美 |郵便番号| 644-0375 |住所| 北海道武蔵野市蟇沼41丁目6番4号 パレス南赤田445 |電話番号| 090-3897-3724 見てのとおり, docker-compose を使って MySQL コンテナを立てて, そこに要求を投げる. 内容は, データベースを新たに作成してテーブル, 値を追加して, 追加項目を全て SELECT するだけ 2 . C++ には RAII があるので, コード中でもそうなのだが SET AUTOCOMMIT = 0 , START TRANSACTION のあとに, COMMIT をし忘れるなんてことを防げるのが良い. 一応 SQL 文が格納されている Range かイテレータを渡せば順次実行, 単一の SQL を渡せばもちろんそれを実行するようにしている. 実際に必要に迫られているわけではないのでなんとも言えないが, 現時点では, それなりに気持ちよく書ける程度にラッピングできたような気がする 3 . 1 点この Connector/C++ に対する不満を申し上げるとすれば, C++11 までにしか未だ対応していない点だろう. しかし久しぶりに C++ 書いた. なんだろうこの実家感は. この個人情報と思わしきリストは, コード内のコメントにも書いたが, 偽の個人情報をランダムに生成する Python 製の ライブラリ で自動生成したものである. 同ライブラリは日本語だけでなく, 様々な国の様式に沿ったそれらしき文字列を提供してくれるので, hoge や foo 等に飽きたら, これを使えば良いのではないのだろうか :p ↩ なお, このインクルードしている Srook というものは, 私の自作ライブラリです. このブログに移行してくる前のブログでは, よく取り扱っていました. ↩ playing::cppconn とかいうふざけた名前空間だが. ↩","loc":"posts/2018/ 7月/20/cppdemysql/","tags":"C++","url":"posts/2018/ 7月/20/cppdemysql/","title":"Connector/C++ で MySQL を操作"},{"text":"エルガマル暗号が離散対数問題の応用であることは認知していたものの, きっちりと自分でまとめたことが無かったと思うので, それに関連する諸々の前提についてもふまえて, 一度書くことにした. また, その処理系を 実装した . 本エントリでは, 同暗号プロトコルの話の前にまず前提を示し, その後, 実装するという観点から見た要点を示す. ※ 内容にはできる限り注意を払っておりますが, 筆者は暗号プロトコル等に関する専門家ではないため, 注意してください. 間違った箇所, 不自然な箇所等があれば, ご報告いただけると幸いです. ユークリッドの互除法 これは, とても有名なアルゴリズムだと思われるので, わざわざ特別取り上げる必要はないようにも思ったのだが, 本エントリでは最大公約数を存分に利用するので, これを自明として取り上げないのも頂けない. したがって, 簡単に説明, 証明をして終わりとする. ユークリッドの互除法は, ユークリッドの互除法 \\(2\\) つの自然数 \\(a, b\\in\\mathbb{N}\\) の最大公約数を求めるアルゴリズム. である. 最大公約数を求める方法として, 素因数分解をひたすら行うのには, 計算量的に限界がある. そこで, 古代ギリシャの数学者ユークリッドは, この問題を幾何学的に考察した(図示された例は調べるとたくさんある). たとえば \\(a=12345678,\\ b=87654321\\) の最大公約数を求めるとする(以下これを \\(\\gcd(a,b)=c\\) と書く). これをユークリッドの互除法は, \\begin{array}{rr} 87654321&=&12345678\\cdot 7&+&1234575\\\\\\ 12345678&=&1234575\\cdot 9&+&1234503\\\\\\ 1234575&=&1234503&+&72\\\\\\ 1234503&=&72\\cdot 17145&+&63\\\\\\ 72&=&63&+&9\\\\\\ 63&=&\\underbrace{9}_{c}\\cdot 7 \\end{array} より \\(\\gcd(a,b)=9\\) というように解く. これで最大公約数を求まる根拠を以下証明する. 補題 1 \\(\\gcd(a,b)=\\gcd(a-b, b)=\\gcd(a-2b,b)=\\gcd(a-3b,b)=\\cdots\\ (a, b\\in\\mathbb{N})\\) が成り立つ. 証明 : \\(a,\\ b\\) の公約数を \\(d\\) とすると, \\(d\\mid a\\land d\\mid b \\Rightarrow d\\mid a-b\\) . また \\(a-b\\) と \\(b\\) の公約数を \\(e\\) とすると, \\(e\\mid a-b\\land e\\mid b\\Rightarrow e\\mid (a-b)+b=e\\mid a\\) . \\(\\therefore\\) 公約数の全体が一致するから, 最大公約数も一致して, \\(\\gcd(a,b)=\\gcd(a-b,b)\\) . これを繰り返すと \\[ \\gcd(a,b)=\\gcd(a-b,b)=\\gcd(a-2b,b)=\\gcd(a-3b,b)=\\cdots \\] \\(\\square\\) 命題 1 ユークリッドの互除法により \\(c\\) が最大公約数となる. 証明 : \\(a, b\\in\\mathbb{Z}&#94;{+}\\) があるとき, 除算は \\(a=bq+r,\\ 0\\leq r\\lt b\\) と表せる. 補題 1 より, \\(\\gcd(a,b)=\\gcd(a-bq,b)=\\gcd(b,r)\\) がいえる. ここで, \\begin{array}{ll} a&=&bq_1+r_1& (0\\lt r_1\\lt b),& \\gcd(a,b)&=&\\gcd(b,r_1)\\\\\\ b&=&r_1q_2+r_2& (0\\lt r_2\\lt r_1),& \\gcd(b,r_1)&=&\\gcd(r_1,r_2)\\\\\\ r_1&=&r_2q_3+r_3& (0\\lt r_3\\lt r_2),& \\gcd(r_1,r_2)&=&\\gcd(r_2,r_3)\\\\\\ \\cdots &&& \\cdots &&& \\cdots \\\\\\ r_i&=&r_{i+1}q_{i+2}+r_{i+2}& (0\\lt r_{i+2}\\lt r_{i+1}),& \\gcd(r_i,r_{i+1})&=&\\gcd(r_{i+1},r_{i+2})\\\\\\ \\cdots &&& \\cdots &&& \\cdots \\\\\\ r_{n-2}&=&r_{n-1}q_n+r_n&(0\\lt r_n\\lt r_{n-1}),&\\gcd(r_{n-2},r_{n-1})&=&\\gcd(r_{n-1},r_n)\\\\\\ r_{n-1}&=&r_nq_{n+1}&& \\gcd(r_{n-1},r_n)&=&r_n \\end{array} として, \\((n+1)\\) 回で割り切れたとすると, \\(r_n\\) が最大公約数 \\(c\\) となる. \\(\\square\\) ガロア体 ある集合に対して, 加法および乗法における結合律の満足と分配律の成立が両立する演算を定義する. この公理を体の公理といい, それを満たす集合を体, とくに位数が有限である体を有限体, ガロア体といい, これを素数 \\(p\\) を位数として \\(GF(p)\\) と書く. このような体は位数を素数で構成すると簡単に構成でき 1 , これを素体という. いま, \\(k\\in\\mathbb{Z}\\) と合同な整数の全体を \\(\\overline{k}\\) と表し, これを \\(k\\) を含む剰余類という. なお, 一般に \\(a\\equiv b\\pmod{c} \\Leftrightarrow \\overline{a}=\\overline{b}\\) である. ガロア体は, \\(\\mathbb{Z}/p\\mathbb{Z}\\)(以下これを簡単のため, \\(\\mathbb{Z}_p\\) と書く.) を整数を \\(p\\) で割った余りから構成される素体として, 次のように構成することで, その同型となる. \\[\\mathbb{Z}_p=\\left\\{\\overline{0},\\cdots, \\overline{p-1} \\pmod{p} \\right\\}\\] 例えば, \\(GF(2) = \\{0, 1\\}\\) であり, このときの四則演算は「整数の世界で四則演算をして, それを \\(2\\) で割った余り」と定義する 2 . なおこの演算規則は加算が XOR に, 乗算が AND に対応する. Prelude > : m + Data . Bits Prelude Data . Bits > let finitef :: Int -> [ Int ]; finitef p = [ x ` mod ` p | x <- [ 0 .. p - 1 ]] Prelude Data . Bits > finitef 2 [ 0 , 1 ] Prelude Data . Bits > map (` mod ` 2 ) ( finitef 2 ) == ( map (` xor ` 0 ) $ finitef 2 ) True Prelude Data . Bits > map ((` mod ` 2 ) . ( + 1 )) ( finitef 2 ) == ( map (` xor ` 1 ) $ finitef 2 ) True Prelude Data . Bits > map ((` mod ` 2 ) . ( * 0 )) ( finitef 2 ) == ( map ( .&. 0 ) $ finitef 2 ) True Prelude Data . Bits > map (` mod ` 2 ) ( finitef 2 ) == ( map ( .&. 1 ) $ finitef 2 ) True オイラーの \\(\\phi\\) 関数 オイラーの \\(\\phi\\) (トーシェント)関数は, 正整数 \\(n\\) に対する \\(1\\) から \\(n\\) までの自然数のうち \\(n\\) と互いに素なものの個数を \\(\\phi(n)\\) として与えることによって定まる乗法的関数 3 である. この関数は \\(p_i\\) を \\(n\\) の素因数として, 次の式で定義できる 4 . オイラーの \\(\\phi\\) 関数 \\[\\phi(n)=n\\displaystyle\\prod_{i=1}&#94;k(1-\\dfrac{1}{p_i})\\] 例えば \\(\\phi(14) = 6\\) である( \\(14 = 2 \\cdot 7\\) だから, \\(14\\left(1-\\dfrac{1}{2}\\right)\\left(1-\\dfrac{1}{7}\\right) = 6\\) . これを列挙すると, \\(1,3,5,9,11,13\\) ). 特に, \\(n\\) が素数である場合, \\(1\\) から \\(n-1\\) のうち \\(n\\) の素因数である \\(n\\) を因数としてもつことはないから \\(\\phi(n) = n - 1\\ \\left(n\\ is\\ prime\\right)\\) が成り立つ. 以下で, 先頭から \\(100\\) 個の素数 \\(p_i=p_0,p_1,p_2,\\cdots,p_{99}\\ \\left(p\\ is\\ prime\\right)\\) に対して, \\(\\phi(p_i)=p_i - 1\\) であることを確認する. {-# OPTIONS_GHC -Wall #-} module Main where import Data.Numbers.Primes ( primes ) import Data.List ( nub ) import Data.Tuple.Extra ( first , second , dupe ) import Data.Ratio (( % ), numerator ) primeFactors :: Int -> [ Int ] primeFactors = flip go primes where go _ [] = [] go n xxs @ ( x : xs ) | n < ( x &#94; ( 2 :: Int )) = [ n | n > 1 ] | otherwise = let ( d , r ) = n ` quotRem ` x in if r == 0 then x : go d xxs else go n xs totient :: Int -> Int totient = numerator . uncurry ( * ) . first ( % 1 ) . second ( foldr ( \\ x acc -> ( x % x - 1 % x ) * acc ) 1 . nub . primeFactors ) . dupe main :: IO () main = print $ and $ take 100 [ totient p == ( p - 1 ) | p <- primes ] フェルマーの小定理 補題 2 奇素位数 $p$ のガロア体 \\( GF (p)\\) の既約剰余類郡を \\(\\mathbb{Z}&#94;{\\ast}\\_{p}=\\left\\{\\overline{1},\\overline{2},\\cdots,\\overline{p-1}\\right\\}\\) としたとき, \\(&#94;\\exists b,&#94;\\exists c \\in \\mathbb{Z}&#94;{\\ast}\\_{p} \\left(b \\neq c\\right)\\) があって, \\(ba\\equiv ca\\pmod{p}\\) となる \\(a \\in \\mathbb{Z}&#94;{\\ast}\\_{p}\\ \\left(\\gcd(a, p)=1\\right)\\) は存在せず, \\(\\mathbb{Z}&#94;{\\ast}\\_{p}\\) の異なる項は非合同. 証明 : \\(\\gcd(a, p) = 1\\) であるから \\(ba\\equiv ca\\pmod{p}\\) の両辺から \\(a\\) を約せて \\(b\\equiv c\\pmod{p}\\) . \\(b < p\\) および \\(c < p\\) から従い \\(b = c\\) となり不条理. \\(\\square\\) フェルマーの小定理 \\(p\\) が素数 \\(\\Rightarrow\\ &#94;\\forall a\\ \\left(\\gcd(a,p) = 1\\right)\\) に対して, \\[a&#94;{p-1}\\equiv 1\\pmod{p}\\label{eq:second}\\tag{2}\\] 証明 : 補題 2 より従って, \\(\\mathbb{Z}&#94;{\\ast}_{p}\\) の各要素と \\(a\\) の積は全て異なり, かつ \\(\\mathbb{Z}&#94;{\\ast}_{p}\\) はそれらで尽くされる. また, それらの積の \\(\\pmod{p}\\) は \\(\\pmod{p}\\) の既約代表系 \\(\\{1, 2, \\cdots, p-1\\}\\) のすべての積と合同: $$1\\cdot 2\\cdot\\cdots\\cdot(p-1)\\equiv (a)(2a)\\cdots(p-1)a\\pmod{p}$$ $$(p-1)!\\equiv (p-1)!\\cdot a&#94;{p-1}\\pmod{p}$$ \\(\\gcd((p-1)!, p) = 1\\) であるから, 両辺からこれを約し, \\[a&#94;{p-1}\\equiv 1\\pmod{p} \\] \\(\\square\\) 簡単に確認 5 . Prelude > : m + Data . Numbers . Primes Prelude Data . Numbers . Primes > let fermatLT :: Integer -> [ Integer ]; fermatLT p = [ a &#94; ( p - 1 ) ` mod ` p | a <- [ 1 .. p - 1 ], gcd p a == 1 ] Prelude Data . Numbers . Primes > and $ map (( all ( 1 == )) . fermatLT ) $ take 50 primes True 原始元 位数 \\(n \\in\\mathbb{Z}&#94;{+},\\ a \\in\\mathbb{Z},\\ \\gcd(n, a) = 1\\) に対して \\(a&#94;d\\equiv 1\\pmod{n}\\) のような最小の \\(d\\in\\mathbb{Z}&#94;{+}\\) を \\(a\\) の\\(\\pmod{n}\\) での位数 6 といい, これを \\(d=\\DeclareMathOperator*{\\ord}{ord}\\ord_n(a)\\) と書く. ただし, 以下添え字 \\(n\\) は明確である場合には省くこととする. たとえば \\(p=7\\) としたときの \\(1 \\leq a\\leq 6\\) の \\(a\\) の冪 \\(\\pmod 7\\) を一覧にすると次のとおりである. Prelude > let f p = foldr ( \\ x acc -> [ a &#94; x ` mod ` p | a <- [ 1 .. p - 1 ]] : acc ) [] [ 1 .. p ] Prelude > mapM_ print $ f 7 [ 1 , 2 , 3 , 4 , 5 , 6 ] [ 1 , 4 , 2 , 2 , 4 , 1 ] [ 1 , 1 , 6 , 1 , 6 , 6 ] [ 1 , 2 , 4 , 4 , 2 , 1 ] [ 1 , 4 , 5 , 2 , 3 , 6 ] [ 1 , 1 , 1 , 1 , 1 , 1 ] [ 1 , 2 , 3 , 4 , 5 , 6 ] 6 乗ですべて \\(\\equiv 1\\pmod{7}\\) というのが, 先に述べたフェルマーの小定理 \\(\\eqref{eq:second}\\) であるが, それよりも前に \\(\\equiv 1\\pmod{7}\\) となる数があることがわかる. これをいま述べた \\(\\DeclareMathOperator*{\\ord}{ord}\\ord\\) で表せば, \\(\\DeclareMathOperator*{\\ord}{ord} \\ord(1)=1, \\ord(2)=3, \\ord(3)=6, \\ord(4)=3, \\ord(5)=6, \\ord(6)=2\\) である. また, この結果が \\(\\phi(6) = 2\\) と整合であることが確認できる. \\(\\DeclareMathOperator*{\\ord}{ord}\\ord(3), \\ord(5)\\) が他と相違なる部分は, \\(1\\) から \\(6\\) までの数がちょうど \\(1\\) 回ずつ現れることである. このように, 原始根 \\(\\pmod{n}\\) での位数が \\(\\phi(n)\\) である整数 を \\(n\\) の原始根という. 同様に, 原始元とは, 奇素数 \\(p\\) と元 \\(a \\in \\mathbb{Z}&#94;{+} \\left(a < p\\right)\\) があって, \\(p\\) を法とする剰余類で累乗していくと, \\(1\\) から \\(p-1\\) のすべての元をつくす郡(巡回郡)を構成する元 \\(a\\) をいう. これは, \\(a&#94;{p-1}\\) で初めて \\(a&#94;{n} \\equiv 1\\pmod{p}\\) となるような元 \\(a\\) (生成元であるから) 位数が \\(p-1\\) となる元 \\(a\\) ともいえる. とくになにも考えず, 与えられた素数 \\(p\\) に対する \\(GF(p)\\) の原始元を素朴に生成してみる. {-# OPTIONS_GHC -Wall #-} module Main where import Data.List ( findIndices ) import Data.Numbers.Primes ( primes ) primitiveElem :: Integer -> [ Integer ] primitiveElem p = go [(( a &#94; n ` mod ` p ) == 1 , a ) | a <- [ 2 .. p - 1 ], n <- [ 1 .. p - 1 ]] where go [] = [] ; go xs @ ( x : _ ) = let d = drop ( fromIntegral ( p - 1 )) xs in case findIndices fst $ take ( fromIntegral ( p - 1 )) xs of [ i ] | i == fromIntegral ( p - 2 ) -> snd x : go d _ -> go d main :: IO () main = mapM_ ( print . primitiveElem ) $ take 100 $ drop 1 primes 実行結果 7 . 上の冪の一覧のとおり, 素数 \\(p\\) を位数とするガロア体はその原始元を \\(a\\) として $$GF(p)= \\left\\{0, 1, a, a&#94;{2}, \\cdots, a&#94;{p-2}\\label{eq:third}\\tag{3}\\right\\}$$ と構成されることがわかる. \\(p=7\\) であれば, 原始根は \\(\\phi(6)=2\\) であり, その \\(1\\) つは \\(g=3\\) であるからこの冪乗 \\(n\\equiv g&#94;{f}\\pmod{7}\\) で \\(p-1=6\\) までの全て, すなわち先の \\(\\DeclareMathOperator*{\\ord}{ord}\\ord(3)\\) の縦の列が得られる. Prelude > [ 3 &#94; x ` mod ` 7 | x <- [ 1 .. 6 ]] [ 3 , 2 , 6 , 4 , 5 , 1 ] 離散対数問題 \\(\\eqref{eq:third}\\) を前提とし \\(g&#94;{f}\\equiv n\\pmod{p}\\ \\left(1\\leq n \\leq p-1\\right)\\) を満たす \\(f\\) は \\(0\\leq f\\leq p-2\\) のうち, ただ \\(1\\) つだけ存在する. これを \\(n\\) の指数または離散対数といい, \\(f=\\log_{g}n\\pmod{p}\\) および \\(\\DeclareMathOperator*{\\Ind}{Ind}f=\\Ind_{g}(n)\\) と書く. この \\(n\\) を真数, または離散真数という. 以下は, \\(3\\leq p \\leq 19\\ \\left(p\\ is\\ prime\\right)\\) でその最小の原始根 \\(g\\) の冪乗 \\(n\\equiv g&#94;f\\pmod{p}\\) の昇順を \\(x\\) 軸, \\(\\DeclareMathOperator*{\\Ind}{Ind}f=\\Ind_{g}(n)\\) を \\(y\\) 軸として, それぞれの各離散対数をプロットした図 8 である. これを見てもわかるように, \\(f\\) の値に規則性は見られず, 予測困難な振る舞いをすることがわかる. 例えば, \\(p=19,\\ g=2,\\ n=3\\) とすると Prelude > head [ f | f <- [ 0 .. 17 ], 2 &#94; f ` mod ` 19 == 3 ` mod ` 19 ] 13 より \\(f=13\\) であることがわかる. この場合, まだ \\(p\\) が小さい素数であるからこそ, このような総当たりで解が得られるのだが, 大きな \\(p\\) に対する総当たりでは, 実用的な時間で解を得ることができない. これを離散対数問題という. エルガマル暗号は, \\(g\\) と \\(f\\) から \\(n\\) を求めることは容易であるが, いま述べたように \\(g\\) と \\(n\\) から \\(f\\) を求めることは困難であるという事実を利用することで, 公開鍵暗号方式としての成立および暗号学的安全性の担保を確立する 9 . 暗号の生成と解読 以上を前提として, 暗号の生成とその解読方法について示す. 受信者は下準備として次の手順で公開鍵と秘密鍵を生成する: 大きな素数 \\(p\\) を選ぶ. \\(\\phi(p-1)\\) 個の \\(p\\) の原始根のうち, 任意の \\(1\\) つ \\(g\\) を選ぶ. 任意の正整数 \\(a\\in\\mathbb{Z}&#94;{+},\\ \\left(a < p\\right)\\) を選ぶ. \\(y\\equiv g&#94;a\\pmod{p}\\) を計算する. 公開鍵を \\(\\left\\{p, g, y\\right\\}\\), 秘密鍵を \\(\\left\\{a\\right\\}\\) とする. 平文の列を \\(x_1,x_2,\\cdots,x_t\\ \\left(x_i < p\\right)\\), 最初の平文を \\(x\\) とし, 発信者は次の手順で暗号文を生成する: 任意の正整数 \\(k\\in\\mathbb{Z}&#94;{+}\\) を選ぶ. \\(\\alpha\\equiv g&#94;k\\pmod{p}\\) を計算する. \\(z\\equiv y&#94;k\\pmod{p}\\) と \\(\\beta\\equiv xz\\pmod{p}\\) を計算し, \\(x\\) に対する \\(\\gamma =\\left\\{\\alpha,\\ \\beta\\right\\}\\) を得る. \\(x_t\\) に到達するまで 1 から 3 の手順を繰り返す. 到達すれば, 暗号文の生成は完了である. 受信者は次の手順で暗号を解く: \\(\\gamma\\) から \\(x\\) を得るためには, \\(y&#94;k\\) を要する. 秘密鍵 \\(a\\) を使い, \\(z\\equiv y&#94;k \\equiv \\left(g&#94;a\\right)&#94;k\\equiv\\left(g&#94;k\\right)&#94;a\\equiv\\alpha&#94;a\\pmod{p}\\) と計算する. \\(x\\equiv \\dfrac{\\beta}{z}\\pmod{p}\\) であるので, \\(\\pmod{p}\\) で \\(z\\) のモジュラ逆数 \\(zq\\equiv 1\\pmod{p},\\ q\\equiv\\dfrac{1}{z}\\pmod{p}\\) を計算する. \\(x\\equiv\\dfrac{\\beta}{z}\\equiv\\beta q\\equiv u\\pmod{p}\\ \\left(u< p\\right)\\) を計算する. ここで, \\(x< p\\) であるから, この結果が平文である. 実際にこれを手計算で実行してみる. \\(p=97\\) とする. 従って \\(g=5\\) となる. ここで \\(a=7\\) とする. \\(y\\equiv 5&#94;7\\pmod{97}\\) より \\(y\\equiv 5&#94;7\\equiv 40\\pmod{97}\\) だから, 公開鍵は \\(\\left\\{97,5,40\\right\\}\\), 秘密鍵は \\(\\left\\{7\\right\\}\\) である. 次に暗号文を作成する. 平文は, 次のアスキーコードで表現された文字列とする. Prelude > : m + Data . Char Prelude Data . Char > map ord \"OK\" [ 79 , 95 ] ここで \\(x=79,\\ k = 5\\) とする. \\(\\alpha\\equiv 5&#94;5\\equiv 21\\pmod{97}\\) また \\(z\\equiv 40&#94;5\\equiv 10\\pmod{97}\\) より \\(\\beta\\equiv 79\\cdot 10\\equiv 14\\pmod{97}\\) . 従って, \\(\\gamma=\\left\\{21, 14\\right\\}\\) となる. \\(x=95\\) にも同様の計算( \\(k\\) は毎度ランダムに選ぶ. 次は \\(k=6\\) であったとした.)を施して, 全体の暗号文を [21, 14, 8, 73] とする. これを解読する. \\(z\\equiv 21&#94;7\\equiv 10\\pmod{97}\\) で, \\(z\\equiv y&#94;k\\pmod{97}\\) . \\(10q\\equiv 1\\pmod{97}\\) だから \\(q\\equiv\\dfrac{1}{10}\\equiv 68\\pmod{97}\\) . ここで \\(u\\equiv 14\\cdot 68\\equiv 97\\pmod{p}\\) で, \\(u< p\\) だから \\(x\\equiv u\\pmod{p}\\) . よって \\(1\\) 文字目は \\(79\\) . 同様に \\(2\\) 文字目も計算し, 全体の平文が手に入る. 解読の段階で \\(a=7\\) を知らなかった場合, 離散対数問題を解くことに相当するため, 平文を得るのは非常に困難となる. 実装 ここからは, これをプログラムとして実装することを考える. 第一に必要となるものは, 大きな素数の生成器である. 方法としては, ランダムに奇数を生成し, Miller-Rabin 素数判定法などの確率的素数判定法を用いることが実例として多い 10 ので, ひとまず素数生成には Miller-Rabin 素数判定法を使うこととする. フェルマーテスト, Miller-Rabin 素数判定法 Miller-Rabin 素数判定法は, フェルマーテストの改良と言えるので, まずその説明から行う. フェルマーテストは, 先に述べたフェルマーの小定理 \\(\\eqref{eq:second}\\) の対偶 11 を利用した判定方法であるといえる. フェルマーテスト \\(FT_n(a): =\\gcd(a, n)=1\\) を満たす \\(n \\in\\mathbb{Z}&#94;{+}\\) と底 \\(a\\in\\mathbb{Z}&#94;{+}\\) があって, \\(a&#94;{n-1}\\equiv 1\\pmod{n}\\) が成り立つか. この答えが yes であるとき \\(n\\) は \\(FT_n(a)\\) をパスしたといえば, フェルマーの小定理は, 「 \\(n\\) が素数ならば, \\(n\\) は \\(&#94;\\forall a\\left(\\gcd(a,n)=1\\right)\\) に対する \\(FT_n(a)\\) をパスした」といい, この対偶をとると,「\\(FT_n(a)\\) をパスしない \\(\\gcd(a,n)=1\\) の \\(a\\) があれば, \\(n\\) は素数ではない」といえる. たとえば, \\(n=15\\) とすると \\(2&#94;{15-1}\\equiv 2&#94;{14}\\equiv 4\\not\\equiv 1\\pmod{15}\\) であるから \\(15\\) は素数ではない. しかしながら, \\(&#94;\\forall a\\left(\\gcd(a,n)=1\\right)\\) に対して \\(FT_n(a)\\) をパスしても \\(n\\) が素数であるとは断言できない. このような カーマイケル数 \\(&#94;\\forall a\\left(\\gcd(n, a)=1\\right)\\) に対して \\(FT_n(a)\\) をパスする合成数 をカーマイケル数という. 一般的に, そのような \\(n\\) は少ないことが知られている. ところで, カーマイケル数は奇数である. 命題 2 カーマイケル数は奇数 証明 : \\(a&#94;n\\equiv a\\pmod{n}\\) に \\(a=n-1\\) を代入すると \\((-1)&#94;n\\equiv -1\\pmod{n}\\) となるが, このとき \\(n\\) を偶数とすると \\(1\\equiv -1\\pmod{n}\\) となってしまい不条理. \\(\\therefore\\) 背理により題意は示された. \\(\\square\\) 一方, \\(a\\) を底とする偽素数 \\(\\gcd(n, a)=1\\) のある \\(a\\) に対して \\(FT_n(a)\\) をパスする合成数 を \\(a\\) を底とする偽素数という. 以下で, 取り敢えず \\(200\\) 個の偽素数(結果的にはカーマイケル数)を 得てみた 12 . {-# OPTIONS_GHC -Wall #-} module Main where import Data.Numbers.Primes ( primes ) import Data.Bits ( Bits , ( .&. ), shiftR ) {-# INLINE modExp #-} modExp :: ( Integral a , Bits a ) => a -> a -> a -> a modExp = go 1 where go r _ 0 _ = r go r x n m | n .&. 1 == 1 = go ( r * x ` rem ` m ) ( x * x ` rem ` m ) ( n ` shiftR ` 1 ) m | otherwise = go r ( x * x ` rem ` m ) ( n ` shiftR ` 1 ) m {-# INLINE isFermat #-} isFermat :: ( Integral a , Bits a ) => a -> a -> Bool isFermat n b = modExp b ( n - 1 ) n == 1 pseudoprimes :: [ Integer ] pseudoprimes = go [ x | x <- [ 2 .. ], odd x ] [ x | x <- primes , odd x ] where tryFermat n t = all ( isFermat n ) $ take t [ x | x <- [ 2 .. n - 1 ], gcd x n == 1 ] go [] _ = [] go _ [] = [] go ( x : xs ) ( p : ps ) | x == p = go xs ps | otherwise = if tryFermat x 100 then x : go xs ( p : ps ) else go xs ( p : ps ) -- Testing 100 times main :: IO () main = print $ take 200 pseudoprimes 実行結果. [ 561 , 1105 , 1729 , 2465 , 2821 , 6601 , 8911 , 10585 , 15841 , 29341 , 41041 , 46657 , 52633 , 62745 , 63973 , 75361 , 101101 , 115921 , 126217 , 162401 , 172081 , 188461 , 252601 , 278545 , 294409 , 314821 , 334153 , 340561 , 399001 , 410041 , 449065 , 488881 , 512461 , 530881 , 552721 , 656601 , 658801 , 670033 , 748657 , 825265 , 838201 , 852841 , 997633 , 1024651 , 1033669 , 1050985 , 1082809 , 1152271 , 1193221 , 1461241 , 1569457 , 1615681 , 1773289 , 1857241 , 1909001 , 2100901 , 2113921 , 2433601 , 2455921 , 2508013 , 2531845 , 2628073 , 2704801 , 3057601 , 3146221 , 3224065 , 3581761 , 3664585 , 3828001 , 4335241 , 4463641 , 4767841 , 4903921 , 4909177 , 5031181 , 5049001 , 5148001 , 5310721 , 5444489 , 5481451 , 5632705 , 5968873 , 6049681 , 6054985 , 6189121 , 6313681 , 6733693 , 6840001 , 6868261 , 7207201 , 7519441 , 7995169 , 8134561 , 8341201 , 8355841 , 8719309 , 8719921 , 8830801 , 8927101 , 9439201 , 9494101 , 9582145 , 9585541 , 9613297 , 9890881 , 10024561 , 10267951 , 10402561 , 10606681 , 10837321 , 10877581 , 11119105 , 11205601 , 11921001 , 11972017 , 12261061 , 12262321 , 12490201 , 12945745 , 13187665 , 13696033 , 13992265 , 14469841 , 14676481 , 14913991 , 15247621 , 15403285 , 15829633 , 15888313 , 16046641 , 16778881 , 17098369 , 17236801 , 17316001 , 17586361 , 17812081 , 18162001 , 18307381 , 18900973 , 19384289 , 19683001 , 20964961 , 21584305 , 22665505 , 23382529 , 25603201 , 26280073 , 26474581 , 26719701 , 26921089 , 26932081 , 27062101 , 27336673 , 27402481 , 28787185 , 29020321 , 29111881 , 31146661 , 31405501 , 31692805 , 32914441 , 33302401 , 33596641 , 34196401 , 34657141 , 34901461 , 35571601 , 35703361 , 36121345 , 36765901 , 37167361 , 37280881 , 37354465 , 37964809 , 38151361 , 38624041 , 38637361 , 39353665 , 40160737 , 40280065 , 40430401 , 40622401 , 40917241 , 41298985 , 41341321 , 41471521 , 42490801 , 43286881 , 43331401 , 43584481 , 43620409 , 44238481 , 45318561 , 45877861 , 45890209 , 46483633 , 47006785 , 48321001 , 48628801 , 49333201 ] 続いて, Miller-Rabin 法について述べる. 前述したように, Miller-Rabin 法は, フェルマーテストの改良である. そもそも, いま判定する \\(n\\) は奇数である前提をおいて十分であるから \\(n-1\\) は偶数となり, かつ \\((n-1) \\div 2\\) の結果は整数とすることができる. したがって \\[\\displaystyle a&#94;{n-1}\\equiv 1\\pmod{n}\\Rightarrow {\\underbrace{\\left(a&#94;{(n-1)/2}\\bmod n\\right)}_{x}}&#94;2 \\equiv 1\\pmod{n}\\label{eq:fourth}\\tag{4}\\] がいえる. 例えば, \\(\\eqref{eq:fourth}\\) の右側の式に着目し, \\(n=35\\) とすると, \\(x\\) は \\(\\overline{1},\\overline{6},\\overline{29},\\overline{34}\\) が \\(2\\) 乗すると \\(\\overline{1}\\) となるため, 有りうる. しかし, \\(n\\) が奇素数であるとき, その剰余類は \\(\\pm{\\overline{1}}\\) しか有りえないのである. これは, 次の命題の証明によって証明される. 命題 3 法 \\(n\\) が奇素数であるとき, その剰余において「\\(1\\) の自明でない平方根は存在しない. \\(\\Leftrightarrow\\ x\\) は \\(\\pm{1}\\) しか存在しえない.」. 証明 : \\(n\\) を法とした剰余において \\(1\\pmod{n}\\) の非自明な平方根を \\(x\\) とすると \\[x&#94;2\\equiv 1\\pmod{n}=x&#94;2-1\\equiv 0\\pmod{n}=\\left(x-1\\right)\\left(x+1\\right)\\equiv 0\\pmod{n}\\] において, \\(n\\) は素数であるから \\(x-1\\) または \\(x+1\\) で割り切れなければならないが, \\(x\\) が \\(\\pm{1}\\) でないとすると, \\(x-1\\) も \\(x+1\\) も \\(n\\) で割り切れず矛盾. \\(\\therefore\\) 背理により, 題意は示された. \\(\\square\\) Miller-Rabin 法は, この性質を利用して, つまり \\(1\\pmod{n}\\) の自明でない平方根を求めることで, 合成数を判別する. 先に述べたように \\(n-1\\) は偶数であるから, 何度か必ず \\(2\\) で割り切ることができる. 割り切る回数を \\(s\\) とすると, $$n-1 = 2&#94;s \\cdot d\\ (s\\in\\mathbb{N}, d\\ is\\ odd)\\label{eq:fifth}\\tag{5}$$ と表せる. このときの \\(d\\) は, \\(n-1\\) を繰り返し \\(2\\) で割った結果そのものである. フェルマーの小定理 \\(\\eqref{eq:second}\\) を \\(\\eqref{eq:fifth}\\) と関連づけると, $$a&#94;{n-1}\\equiv a&#94;{2&#94;s\\cdot d}\\equiv 1\\pmod{n}$$ がいえる. 命題 3 より, この平方根は \\(\\pm{1}\\pmod{n}\\) である. つまり, Miller-Rabin 素数判定法 \\(&#94;\\forall a \\in \\mathbb{Z}&#94;{\\ast}_{n}\\) について $$a&#94;d\\equiv 1\\pmod{n}$$ または $$a&#94;{2&#94;r\\cdot d}\\equiv -1\\pmod{n}\\ (0\\leq r\\leq s-1)$$ が成り立つ. これは, 予め \\(a&#94;d\\) から始めて次々に \\(2\\) 乗して得られる列 \\(a&#94;d,\\underbrace{\\cdots, a&#94;{2&#94;{s-1}\\cdot d}}_{s}, a&#94;{2&#94;s\\cdot d}=a&#94;{n-1}\\) を想像すると, 考えるに容易い. 例として, 先に確認できた最小のカーマイケル数である \\(561\\) をこのミラーラビン法で判定してみるとする. \\(n=561,\\ a=2\\) としたとき, \\(561-1=2&#94;4\\cdot 35\\) であるから, \\(2&#94;{35}\\equiv 263\\pmod{561}\\) , \\(2&#94;{2\\cdot 35}\\equiv 263&#94;2\\equiv 166\\pmod{561}\\) , \\(2&#94;{4\\cdot 35}\\equiv 166&#94;2\\equiv 67\\pmod{561}\\) , \\(2&#94;{8\\cdot 35}\\equiv 67&#94;2\\equiv 1\\pmod{561}\\) より条件を満たさない. よって \\(a=2\\) により, \\(n=561\\) が合成数であることがわかった. いま述べたように, この手続きで \\(n\\) が合成数であることがわかったとき, \\(a\\) を witness と言い, そうでないとき \\(a\\) を strong liar , \\(n\\) を strong pseudoprime という 13 . すべての合成数には, 多くの witness である \\(a\\) が存在することが知られているが, そのような \\(a\\) を生成する簡単な方法はまだ知られていない 14 ため, この \\(a\\) は, いま例で述べたように \\(&#94;\\forall a\\in \\mathbb{Z}&#94;{\\ast}_{n}\\) または \\(&#94;\\forall a\\in \\left(\\mathbb{Z}&#94;{\\ast}_{n}\\setminus \\left\\{1 \\right\\}\\right)\\) からランダムに取って, 何度かの試行を行うこととなる. しかし \\(n\\) が小さい場合, 特定のいくつかの witness によるテストで十分であることが知られており 15 , その場合, すべての \\(a<2\\left(\\ln n\\right)&#94;2\\) を試みる必要はない. 以下にミラーラビン法を用いた素数生成の実装例を示す. 今述べたように, 特定のいくつかの witness マジックナンバーを利用することで, 演算の高速化を図っている. なおミラーラビン法の試行回数に関してであるが, 下記の実装では, \\(t\\) を試行回数, \\(|p|\\) を得たい素数 \\(p\\) のビット長としたとき, \\(|p|\\geq 3072\\) で \\(t=64\\) , \\(3071\\geq |p|\\geq2048\\) で \\(t=56\\) , それ以外を \\(t=40\\) とした 16 . ただし, \\(n\\) の値がマジックナンバーに当てはまる値であった場合, いま設定した試行回数を無視して, より少ない回数で試行を実行することとしている. -- miller.hs {-# OPTIONS_GHC -Wall #-} module Main where import Data.Tuple.Extra ( first , second , dupe ) import Data.Bool ( bool ) import Data.Bits ( Bits , ( .&. ), ( .|. ), shiftR ) import Control.Monad.Fix ( fix ) import System.Random ( Random , randomRs , newStdGen , randomRIO ) import System.IO.Unsafe ( unsafePerformIO ) import Control.Monad ( void ) import System.Environment ( getArgs ) type BitSize = Int {-# INLINE witnesses #-} witnesses :: ( Num a , Enum a , Ord a , Random a ) => Int -> a -> IO [ a ] witnesses t n | n < 2047 = return [ 2 ] | n < 1373653 = return [ 2 , 3 ] | n < 9080191 = return [ 31 , 73 ] | n < 25326001 = return [ 2 , 3 , 5 ] | n < 3215031751 = return [ 2 , 3 , 5 , 7 ] | n < 4759123141 = return [ 2 , 7 , 61 ] | n < 1122004669633 = return [ 2 , 13 , 23 , 1662803 ] | n < 2152302898747 = return [ 2 , 3 , 5 , 7 , 11 ] | n < 3474749660383 = return [ 2 , 3 , 5 , 7 , 11 , 13 ] | n < 341550071728321 = return [ 2 , 3 , 5 , 7 , 11 , 13 , 17 ] | n < 3825123056546413051 = return [ 2 , 3 , 5 , 7 , 11 , 13 , 17 , 19 , 23 ] | n < 18446744073709551616 = return [ 2 , 3 , 5 , 7 , 11 , 13 , 17 , 19 , 23 , 29 , 31 , 37 ] | n < 318665857834031151167461 = return [ 2 , 3 , 5 , 7 , 11 , 13 , 17 , 19 , 23 , 29 , 31 , 37 ] | n < 3317044064679887385961981 = return [ 2 , 3 , 5 , 7 , 11 , 13 , 17 , 19 , 23 , 29 , 31 , 37 , 41 ] | otherwise = take t . randomRs ( 2 , pred n ) <$> newStdGen {-# INLINE millerRabin' #-} millerRabin' :: Int -> Integer -> Bool millerRabin' t n = unsafePerformIO $ millerRabin t n millerRabin :: Int -> Integer -> IO Bool millerRabin _ 0 = return False millerRabin _ 1 = return False millerRabin t n | even n = return $ n == 2 | otherwise = all ( \\ a -> ( uncurry ( || ) . first ( == 1 ) . second ( == pred n ) . dupe . flip (` modExp ` q ) n ) a || any (( == pred n ) . flip ( modExp a ) n . ( * q ) . ( 2 &#94; )) [ 0 .. pred k ]) <$> witnesses t n where ( k , q ) = first ( pred . length ) . second ( fst . last ) . dupe $ takeWhile (( == 0 ) . snd ) $ iterate ((` quotRem ` 2 ) . fst ) ( pred n , 0 ) {-# INLINE genRndPrime #-} genRndPrime :: BitSize -> IO Integer genRndPrime b = let t | b > 3071 = 64 | b > 2047 = 56 | otherwise = 40 in fix $ \\ loop -> uncurry ( bool loop ) . first return . second ( millerRabinV t ) . dupe =<< ( .|. 1 ) <$> randomRIO ( 2 &#94; pred b , pred 2 &#94; b ) main :: IO () main = void . genRndPrime . read . head =<< getArgs -- NOTE: Simplefied implementation 禁断の unsafePerformIO を使っているが, Haskell によるミラーラビン法の実装をいくつか見たところ, 乱択部分を除いてしまうか, unsafePerformIO でむりやり剥がすかのどちらかであるものが多かったため, 今回は unsafePerformIO を使った. 取り敢えず, \\(512\\) ビットの素数(厳密には, ミラーラビン法をパスした整数値)を \\(500\\) 個生成して, \\(1\\) 個毎の平均タイムを取ってみる(Intel Core i5 2.3 GHz). $ ghc -O2 miller.hs $ function test () { c = $(( $1 )) ; sum = 0 ; for (( i = 0 ; i<c ; i++ )) ; do t = ` ( time $2 $3 ) 2 > & 1 | cut -d ' ' -f 3 | sed -e 's/s//' ` ; sum = $(( $sum + $t )) ; done ; echo $(( $sum / $c )) } $ test 500 ./miller 512 0 .15404000000000001 続いて, \\(128, 256, 512, 1024, 2048, 4096\\) ビットの素数(厳密には(略))を出力してみる. Prelude> :l miller.hs [ 1 of 1 ] Compiling Main ( miller.hs, interpreted ) Ok, one module loaded. *Main> :m +Control.Monad *Main Control.Monad> mapM_ ( print < = < genRndPrime ) $ takeWhile ( < = 4096 ) $ iterate ( *2 ) 128 30152684759236306360759189014885017501 17615060719467184202036409862717012145510462718555435021180440677751843010823 4961148527316039571648091952671338492606036840037640470424610573222347642611462698736307409917945445030462370397146417013342380935544024541068881582286519 25584768656119199916533897521508744971267476837365238305752308490292510217984396186262212951588772839265133033518832638176737141863211711861885101826309901436466476910363387059212888058245199487348290889532831748995252985064885609741672898559944700898752387615008473235044774735893904621136647403330417312059 9697176354766878597400959392092693913441120648813644414460016213663985294414931715402479614583881054693029546415327047217815927381224240226473707682349775659198547518238881984785480308932024810985466973637700641819036921605772405440708981576721445103440573178324949184257202763509431134454852179958292647936221069441068206326565638462179605127956309699241768323894074914089121556488610751882542364864592334186293707224875665902283108012729170475600277359162025423140429916611481557282284452570764357791923438513047955145544164761084918980627342758315952165604438369806429356467080379549163687769931548537357143263137 249063954769520791504335518869525636357711675551382844552486591301599804010616669984965046137702990331634027801213287527508276332874010381824423879851102129301619320214358200683875526181170711209609115767952039460200494646156806401006606435356629905145570257996919209012879790948686386135358818589021439012221688336685244502459332857112750109146317838249983592404921237275755397945054535375511514580719834889033600717626042664029019643677615797489694358572078991851764302692237731943089490923440157248660837253585380337652421704176147487644881486339669614376151014612960159779210346160720078183845109588734694671896283469443712214250201417341560450455911188218652929963021457097285664257779489584361468840174197077267520538188995324746759329091599208318255773278559709364894821983283204708493843410191542232134827077779374883928282449194911733594690651507649566828266806932507531936170109029976882137339061468508458205917061060082555112142174457460359680430229131730389715061511723413089333837349054725383074218124443684705492930073805208443422200611436931245986942375223462067885041043866971617179685176389912228173339486617601365377174404775712644963980902603572250337835570653437536036543335033071576503380289418724779934391260111 というわけで, 任意のビット数の素数(厳(略))が得られるようになった. ところで, これは完全に蛇足なのだが, 同様の実装を C++ で行えば, これより少し早くなるのではないかと思い, Boost.Multiprecision 等を使って, この実装を C++ に移植しようと考えた. ただ, ミラーラビン法で素数を得る機能は, 既に同ライブラリ内で実装済みであったので, 一旦それを用いてタイムを計測して, お茶を濁すこととした. // miller.cpp #include <boost/multiprecision/cpp_int.hpp> #include <boost/multiprecision/miller_rabin.hpp> #include <boost/random/mersenne_twister.hpp> #include <boost/random/uniform_int_distribution.hpp> #include <boost/random/random_device.hpp> constexpr unsigned int check_times ( unsigned int s ) noexcept { return s >= 3072 ? 64 : s >= 2048 ? 56 : 40 ; } int main ( int argc , const char ** const argv ) { namespace bm = boost :: multiprecision ; if ( argc != 2 ) return EXIT_FAILURE ; const unsigned int val = boost :: lexical_cast < unsigned int > ( argv [ 1 ]); boost :: random :: uniform_int_distribution < bm :: cpp_int > dist ( bm :: pow ( bm :: cpp_int ( 2 ), val - 1 ), bm :: pow ( bm :: cpp_int ( 2 ), val )); boost :: random_device seed ; boost :: random :: mt19937 mt ( seed ); for ( bm :: cpp_int candidate = dist ( mt ); ! bm :: miller_rabin_test ( candidate , check_times ( val )); candidate = dist ( mt )); } 若干ではあるが, やはり少しは早くなったようだ. $ g++-8 -std = c++1z -lboost_random miller.cpp -I/usr/local/include -march = native -O3 -Ofast $ test 500 ./a.out 512 0 .13506000000000004 さらに早さを求める場合, 実用途として利用でき, かつお手頃なもので良い選択になるものを考えると, やはり libgmp が思い浮かぶ 17 . ただ, 本エントリの内容のメインは素数生成に関してではないので, 一旦ここまでとしておく. 原始根の生成 次に必要となるのは原始根 \\(g\\) であるが, この生成を簡単にするためには, 安全素数という素数を素数生成の段階で生成しておかなければならない 7 . 安全素数は 安全素数 \\(q=2p+1\\ \\left(p\\ is\\ prime\\right)\\) があって, このとき素数となる \\(q\\) をいう 18 . また, ソフィー・ジェルマン素数 安全素数 \\(q=2p+1\\) の \\(p=(q-1)\\div 2\\) をソフィー・ジェルマン素数という. 例えば, \\(p=11\\) としたとき \\(2\\cdot 11+1=23\\) は素数であるから, \\(q=23\\) を安全素数, また \\(p=11\\) をソフィー・ジェルマン素数という. 素数生成の段階でこの安全素数を要するのは, 原始根 \\(g\\) を求める単純な一般式が知られておらず 7 , 安全素数でない素数に対する原始根 \\(g\\) の確定的な結果を要する場合, 先に求めた ように \\(g\\not\\equiv 1,\\cdots,g&#94;{p-2}\\not\\equiv 1\\pmod{p}\\) といった判定が必要となるからである. \\(q\\) が安全素数であれば, \\(q-1=2p\\) 19 より \\(q-1\\) の素因数は \\(2\\) と \\(p=(q-1)\\div 2\\) しかなく, 圧倒的に計算量を減らすことができる. さて, 安全素数は, \\(p\\) と \\(q\\) がともに素数であれば良いので, このどちらにもミラーラビン法を実行してしまうのが一番簡単である 20 . -- (略) {-# INLINE genRndSafePrime #-} genRndSafePrime :: BitSize -> IO Integer genRndSafePrime b = let t | b > 3071 = 64 | b > 2047 = 56 | otherwise = 40 in fix $ \\ loop -> uncurry ( bool loop ) . first ( return . fst ) . second snd . dupe =<< second ( uncurry ( && ) . first ( millerRabin' t . ( flip shiftR 1 ) . pred ) . second ( millerRabin' t ) . dupe ) . dupe . ( .|. 1 ) <$> randomRIO ( 2 &#94; pred b , pred 2 &#94; b ) これで, 任意のビット数の安全素数が得られるようになった. あとは, この安全素数を利用して, 原始根の定義, 性質 に従い, \\(g&#94;{q-1}\\) で初めて \\(g&#94;{n}\\equiv 1\\pmod{q}\\) となる \\(g\\) を選べば良いわけであるが, その一連の手順としては, いま安全素数 \\(q\\) があって 任意の \\(2\\leq g\\leq q-2\\) を選ぶ(当然, \\(1\\) と \\(p-1\\) は\\(g&#94;2\\equiv 1\\pmod{q}\\) となるから). \\(g&#94;{(q-1)/2}\\not\\equiv 1\\pmod{q}\\) を満たすか判定する. これを満たせば \\(g\\) は \\(q\\) の原始根である. そうでなければ 1 へ戻る. というように探索することができる. このとき, 離散対数に対する耐性, すなわちセキュリティの強度に関して, この \\(g\\) はとくに関与しないため, 通常小さい原始根から探し出せば良いことになる. すると, 次のようにして, 最小の原始根が得られる. Prelude > : m + Data . Bits Prelude Data . Bits > : l miller [ 1 of 1 ] Compiling Main ( miller . hs , interpreted ) Ok , one module loaded. * Main Data . Bits > [ x | x <- [ 2 .. 100 ], millerRabin' 40 x && millerRabin' 40 ( pred x ` shiftR ` 1 )] [ 5 , 7 , 11 , 23 , 47 , 59 , 83 ] * Main Data . Bits > let rootFromSafePrime p = head [ g | g <- [ 2 .. p - 2 ], modExp g ( pred p ` shiftR ` 1 ) p /= 1 ] * Main Data . Bits > map rootFromSafePrime [ x | x <- [ 2 .. 100 ], millerRabin' 40 x && millerRabin' 40 ( pred x ` shiftR ` 1 )] [ 2 , 3 , 2 , 5 , 5 , 2 , 2 ] 鍵と暗号文の生成 上で述べた手順のまま実装できる. type PublicKey = ( Integer , Integer , Integer ) type PrivateKey = Integer type Keys = ( PublicKey , PrivateKey ) type Cryptogram = [ Integer ] genKeys :: Integer -> Integer -> IO Keys genKeys p g = ( \\ ( y , a ) -> (( p , g , y ), a )) . first ( flip ( modExp g ) p ) . dupe <$> randomRIO ( 1 , pred p ) encode :: PublicKey -> String -> IO Cryptogram encode _ [] = return [] encode ( p , g , y ) plain = concat <$> mapM ( \\ c -> uncurry ( : ) . first ( flip ( modExp g ) p ) . second (( :[] ) . flip ( flip modExp 1 ) p . ( toInteger ( ord c ) * ) . flip ( modExp y ) p ) . dupe . toInteger <$> randomRIO ( 1 , maxBound :: Int )) plain 暗号文の復号 復号に関しても, 上の手順のまま実装するだけであるが, モジュラ逆数を得るために拡張ユークリッドの互除法を使うのでそれについて説明する. \\(GF(p)\\) は体の公理より乗法について可換群となっており, 逆元が存在するはずだから, \\(&#94;\\exists n\\in GF(p)\\) に対する逆元を \\(n&#94;{-1}=x\\in GF(p)\\) とおける. \\(GF(p)\\) の単位元を考えれば, この \\(n\\) と \\(x\\) の関係は, \\(nx\\equiv 1\\pmod{m}\\) という式で表せる. この式は勿論, 合同の定義からして, \\(k\\) をある整数としたとき \\(nx-1=mk\\) と等価であることがいえる. これを都合の良い形に移行すると, \\(nx-mk=1\\). いま知りたいのは, 逆数である \\(x\\) だ. ここで, 拡張ユークリッドの互除法を使う. 拡張ユークリッドの互除法は, 拡張ユークリッドの互除法 ユークリッドの互除法 で求まる \\(\\gcd(a,b)\\) に加え, \\[ ax+by=\\gcd(a,b) \\] (ベズーの等式) が成り立つ \\(a,\\ b\\) のベズー係数 \\(x,\\ y\\) をも同時に求める. アルゴリズムである. いまの問題をこの式に当てはめると, \\(nx-mk=\\gcd(n,m)\\) となる. 暗号の生成と解読 の内容のうち例として用いた値, \\(n=10,\\ m=97\\) を入力として, まず一般解を導いてみる. いま \\(n,\\ m\\) に対して ユークリッドの互除法 を行うと, \\begin{eqnarray} 97&=&10\\cdot 9+7&\\Leftrightarrow &7&=&97-10\\cdot 9\\label{eq:ex1}\\tag{6}\\\\\\ 10&=&7+3&\\Leftrightarrow &3&=&10-7\\label{eq:ex2}\\tag{7}\\\\\\ 7&=&3\\cdot 2+1&\\Leftrightarrow &1&=&7-3\\cdot 2\\label{eq:ex3}\\tag{8} \\end{eqnarray} より \\[10x+97(-k)=1\\] と表せる. こうして見るとわかるように, これは単なる \\(1\\) 次不定方程式だ. \\(1\\) 次不定方程式は, \\(\\gcd(a,b)=d\\) としたとき \\(d=1\\) ならば解がある. また, \\(d\\gt 1,\\ d\\mid c\\) でも解がある. なぜならば, \\(d=\\gcd(a,b)\\) のときは ユークリッドの互除法 で解が構成できたし, \\(d\\gt 1,\\ d\\mid c\\) ならば \\(d\\) 倍してやれば良いからだ. 逆に \\(d\\not\\mid c\\) ならば, その \\(1\\) 次不定方程式は不能となる. いま述べた例の場合, 解は存在して, \\begin{array}{lclclcl} 1&=&\\eqref{eq:ex3}&=&7-3\\cdot 2\\\\\\ 1&=&7-\\eqref{eq:ex2}\\cdot 2&=&7-(10-7)\\cdot 2&=&7\\cdot3 - 10\\cdot 2\\\\\\ 1&=&\\eqref{eq:ex1}\\cdot 3-10\\cdot 2&=&(97-10\\cdot 9)\\cdot 3-10\\cdot 2&=&97\\cdot 3-10\\cdot 29 \\end{array} よって, 特別解 \\(x=-29,\\ k=-3\\) が求まった. 次に, この一般解を求める. いま求めた \\(x,\\ k\\) を代入すると \\(10(-29)+97(3)=1\\) . これを元の式から引くと, \\begin{array}{rr} & 10x &+ &97(-k) &= 1 \\\\\\ -)&10(-29) &+ &97(3) &= 1 \\\\\\hline &10(x+29)&+&97(-k-3)&=0 \\end{array} で, 変形すると \\(10(x+29)=-97(-k-3)\\) と表せる. ここで, 先のユークリッドの互除法により \\(\\gcd(10,97)=1\\) であることがわかっているから, \\(x+29=97n\\ (n\\in\\mathbb{Z})\\) と表すことができることがわかる. よって, \\(x=97n-29,\\ k=10n-3\\) である. 実際に \\(n=1\\) とすると, \\(x=68\\) となり, これは 先に示した復号化におけるモジュラ逆数の演算例, \\(q\\equiv \\dfrac{1}{10}\\equiv 68\\pmod{97}\\) と整合であることがわかる. ここで, いまやった一連の作業を一般化しておく. この計算が \\((s+1)\\) 回で終わったとする. \\begin{eqnarray} &r_1&=&a-bq_1\\label{eq:nineth}\\tag{9}\\\\\\ &r_2&=&b-r_1q_2\\label{eq:tenth}\\tag{10}\\\\\\ &r_3&=&r_1-r_2q_3\\label{eq:eleventh}\\tag{11}\\\\\\ &\\cdots & & \\cdots \\\\\\ &r_i&=&r_{i-2}-r_{i-1}q_i\\label{eq:twelveth}\\tag{i}\\\\\\ &\\cdots & & \\cdots \\\\\\ &r_{s-1}&=&r_{s-3}-r_{s-2}q_{s-1}\\\\\\ &d&=&r_{s-2}-r_{s-1}q_s \\end{eqnarray} よって \\(r_i=x_ia+y_ib\\) として \\(x_s,\\ y_s\\) を求めればよいこととなる. まず, \\(r_i=a-bq_i\\) から \\(x_1=1,\\ y_1=-q_1\\) について, \\(\\eqref{eq:nineth}\\) を \\(\\eqref{eq:tenth}\\) に代入し \\[r_2=b-(a-bq_1)q_2=-aq_2+b(1+q_1q_2)\\] とする. ここで \\(x_2=-q_2,\\ y_2=1+q_1 q_2\\) を初期条件とする. 一般に \\(r_i\\) が \\(a,\\ b\\) で表せるとしたとき \\(r_i=x_i a+y_i b\\) と表せるから \\(x_i,\\ y_i\\) の漸化式を次のようにおくことができる. \\begin{array}{lcl} r_{i-2}&=&x_{i-2}a+y_{i-2}b \\\\\\ r_{i-1}&=&x_{i-1}a+y_{i-1}b \\\\\\ r_i&=&x_i a+y_i b \\end{array} これらを \\(\\eqref{eq:twelveth}\\) に代入すると, \\[x_i a+y_i b=x_{i-2}a+y_{i-2}b-(x_{i-1}a+y_{i-1}b)q_i\\] 両辺の \\(a,\\ b\\) の係数を比較すると, \\begin{array}{lcl} x_i&=&x_{i-2}-x_{i-1}q_i\\ \\left(i\\geq 3\\right) \\\\\\ y_{i}&=&y_{i-2} - y_{i-1}q_i \\end{array} よって, いまのように順に \\(x_3,\\ x_4,\\ \\cdots,\\ y_3,\\ y_4,\\cdots\\) と計算していけば \\(d\\) の表示式である \\(d=xa+yb\\) の \\(x\\) と \\(y\\) が求まる. ユークリッドの互除法 の最後では, 必ず \\(r_n-1=r_n+q_{n+1} + 0 = r_n\\) となるから, これを停止条件とし, 次のように実装できる. Prelude > let gcdExt :: Integral a => a -> a -> ( a , a , a ); gcdExt a 0 = ( 1 , 0 , a ); gcdExt a b = let ( q , r ) = a ` quotRem ` b ; ( s , t , g ) = gcdExt b r in ( t , s - q * t , g ) Prelude > gcdExt 10 97 ( - 29 , 3 , 1 ) この実装と同時に, モジュラ逆数の計算関数を次のように実装できる. Prelude > let modInv :: Integral a => a -> a -> Maybe a ; modInv a m = case gcdExt a m of ( x , _ , 1 ) -> Just $ if x < 0 then x + m else x ; _ -> Nothing Prelude > modInv 10 97 Just 68 あとは上の手順に従って, 次のように復号関数が実装できる. decode :: Keys -> Cryptogram -> Maybe String decode _ [] = Just [] decode _ [ _ ] = Nothing decode (( p , g , y ), a ) ( x1 : x2 : xs ) = case modExp x1 a p ` modInv ` p of ( Just q ) -> ( : ) <$> Just ( chr ( fromIntegral ( modExp ( x2 * q ) 1 p ))) <*> decode (( p , g , y ), a ) xs Nothing -> Nothing 実行 最後に, ここまでで作ったモジュールをロードして, 暗号化, 復号化を実行してみる. * Main Lib > : m + System . Environment * Main Lib System . Environment > p <- genRndSafePrime 16 * Main Lib System . Environment > ( pubkey , prikey ) <- genKeys p $ rootFromSafePrime p * Main Lib System . Environment > let f = ( =<< ) ( print . decode ( pubkey , prikey )) . encode pubkey * Main Lib System . Environment > mapM_ f [ \"hoge\" , \"bar\" , \"foo\" , \"roki\" ] Just \"hoge\" Just \"bar\" Just \"foo\" Just \"roki\" うまくいっているようだ. なお, すべての実装やテストコードは, falgon/ElgamalEncryptionHs - The rustic implementation of ElGamal encryption encoder and its decoder. にて公開している. 参考文献 \" Primitive Elements vs. Generators\" 2018 年 7 月 9 日アクセス. 伊東利哉, 辻井 重男 (1989)「 有限体における原始根の生成アルゴリズム 」 2018 年 7 月 9 日アクセス. von zur Gathen, Joachim; Shparlinski, Igor (1998), \"Orders of Gauss periods in finite fields\" , Applicable Algebra in Engineering, Communication and Computing Robbins, Neville (2006), Beginning Number Theory , Jones & Bartlett Learning, ISBN 978-0-7637-3768-9. 「 有限体（ガロア体）の基本的な話 」 2018 年 6 月 29 日アクセス. 「 オイラーのファイ関数のイメージと性質 」 2018 年 7 月 9 日アクセス. Andreas V. Meier (2005), \" The ElGamal Cryptosystem \" 2018 年 7 月 9 日アクセス. \" FIPS PUB 186-4 Digital Signature Standard ( DSS )\" 2018 年 7 月 9 日アクセス. \" How can I generate large prime numbers for RSA ? \" 2018 年 7 月 9 日アクセス. \" Miller–Rabin primality test \" 2018 年 7 月 9 日アクセス. 「 有限体― 塩田研一覚書帳 ―」 」2018 年 6 月 27 日アクセス. \" Fast Generation of Prime Numbers on Portable Devices: An Update \" 2018 年 7 月 13 日アクセス. 既約多項式を使うと \\(p\\) が素数でなくても( \\(p\\) が位数の素数のべき乗であれば)構成できるが, 本エントリの主題と大きく逸れてしまうため, とくに触れない. ↩ 言葉の 参照 . ↩ これに関しては, 数論的関数の用語と例 で説明している. ↩ 参照 . ↩ エルガマル暗号では素数を扱うこととなるので, 本エントリでは, フェルマーの小定理の一般形であるオイラーの定理( \\(a&#94;{\\phi(n)}\\equiv 1\\pmod{n}\\ \\left(\\gcd(a, n) = 1, a,n \\in \\mathbb{Z}&#94;{+}\\right)\\) )に関しては特に触れていないが, 後に 別のエントリ として取り上げた. ↩ この「位数」という単語にはいくつか用例があるので注意. 「 群には、群の位数と、元の位数の２通りがあります。 群の位数は、体と同じく、要素の個数を表しますが、 元 \\(x\\) の位数とは \\(x&#94;n=単位元 e\\) となる最小の自然数 \\(n\\) のことです。 元 \\(x\\) の位数が \\(n\\) ならば、 \\(x\\) の生成する巡回部分群 \\(< x > = { e, x, x2, ... }\\) の群位数も \\(n\\) になることから同じ用語を使っているようです。 」 有限体― 塩田研一覚書帳 ― ↩ このコード では, 先頭から 100 個の素数 \\(p\\) を位数とした \\(GF(p)\\) の原始元を求めているが, やはり大きな素数 \\(p\\) に対しては, とくに時間がかかる. このような \\(a\\) を法とする原始元を計算する単純な一般式は知られていない(参照1: von zur Gathen & Shparlinski 1998 , pp. 15–24: \"One of the most important unsolved problems in the theory of finite fields is designing a fast algorithm to construct primitive roots.\" 参照2: Robbins 2006, p. 159 : \"There is no convenient formula for computing [the least primitive root].\" )が, より高速に見つけ出す方法として確率的アルゴリズムがいくつか知られている. ↩ ↩ ↩ 図は python, matplotlib 等で 生成 . ↩ しかしながら, 量子フーリエ変換を用いた探索 は, この離散対数問題に対しても有効的な解決手段である. ↩ \" How can I generate large prime numbers for RSA ?\" , \"The standard way to generate big prime numbers is to take a preselected random number of the desired length, apply a Fermat test (best with the base 2 as it can be optimized for speed) and then to apply a certain number of Miller-Rabin tests (depending on the length and the allowed error rate like \\(2&#94;{−100}\\) ) to get a number which is very probably a prime number.\" ↩ この「対偶」は, 全称命題への対偶であることに留意. ↩ 素朴な実装であることに注意. arithmoi パッケージの isFermatPP を使うことも考えたが(これを使うと \\(20\\) 秒ほどで \\(200\\) 個の偽素数が得られた), 計算量を度外視すれば, これは単純に実装できるので書いてしまった. ベキ乗剰余の計算は, 取り敢えず繰り返し二乗法にした. ↩ Miller–Rabin primality test , (snip) then n is not prime. We call a a witness for the compositeness of n (sometimes misleadingly called a strong witness, although it is a certain proof of this fact). Otherwise a is called a strong liar, and n is a strong probable prime to base a. (snip) Note that Miller-Rabin pseudoprimes are called strong pseudoprimes. ↩ Miller-Rabin primality test , (snip) Every odd composite n has many witnesses a, however, no simple way of generating such an a is known. ↩ Miller-Rabin primality test , (snip) When the number n to be tested is small, trying all \\(a \\lt 2\\left(\\ln n\\right)&#94;2\\) is not necessary, as much smaller sets of potential witnesses are known to suffice ↩ この値は, FIPS PUB 186-4 DSS / APPENDIX /C.3 の \"Minimum number of Miller-Rabin iterations for DSA \" を参照. このテーブルに関する裏付けの参考として この回答 を参照. ↩ Haskell のライブラリ, Math.NumberTheory.Primes.Testing の millerRabinV は, 内部で libgmp を呼び出しているようだ. ↩ より一般的には, \\(d\\) 準安全素数というものもあり, その場合素数 \\(p\\) に対して \\(\\left(p-1\\right)\\div 2&#94;d\\) が素数となる. ↩ この場合, \\(2p\\) は準素数といえる. ↩ この方法よりも効率の良い方法として, 参考文献 の \"4.2 Generating safe and quasi-safe primes\" に言及がある. また, 既知の部分群の生成元を探す方法もある. DSA はこの方法を採用しているとのこと: 4 The Digital Signature Algorithm ( DSA ) ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2018/ 7月/13/elgamalEncryption/","tags":"math","url":"posts/2018/ 7月/13/elgamalEncryption/","title":"エルガマル暗号"},{"text":"数論的関数の用語やその関連について整理したかったので書くことにした. 数論的関数 数論的関数は, 定義域が正整数 \\(\\mathbb{Z}&#94;{+}\\) である複素数を値にもつ関数である. すなわち 数論的関数 \\(\\mathbb{Z}&#94;{+}\\) から複素数 \\(\\mathbb{C}\\) への関数 \\(\\mathbb{Z}&#94;{+}\\to\\mathbb{C}\\) をいう. 加法的関数 加法的関数は 加法的関数 \\(m\\in\\mathbb{Z}&#94;{+}, n\\in\\mathbb{Z}&#94;{+}, \\gcd(m,n)=1\\) について \\(f(mn)=f(m)+f(n)\\) を満たす数論的関数 \\(f(x)\\) をいう. e.g.: \\(n\\) の異なる素因数の総数 \\(:= \\omega (n)\\). \\(\\omega(4)=1, \\omega(20)=\\omega(2&#94;2\\cdot 5)=2, \\omega(2018)=\\omega(2\\cdot 1009)=2\\) \\(n\\) の異なる素因数の和 \\(:= \\text{sopf}(n)\\). \\(\\text{sopf}(1)=0,\\text{sopf}(4)=2,\\text{sopf}(20)=2+5=7,\\text{sopf}(2018)=1011\\) また 完全加法的関数 \\(&#94;\\forall m\\in\\mathbb{Z}&#94;{+}, &#94;\\forall n\\in\\mathbb{Z}&#94;{+}\\) について \\(f(mn)=f(m)+f(n)\\) を満たす加法的関数 \\(f(x)\\) を完全加法的関数という. e.g.: \\(n\\) の重複も含めた素因数の総数 \\(:= \\Omega(n)\\). \\(\\Omega(1)=0, \\Omega(20)=\\Omega(2\\cdot 2\\cdot 5)=3, \\Omega(2018)=\\Omega(2\\cdot 1009)=2\\) \\(n\\) の重複も含めた素因数の和 \\(:= \\text{sopfr}(n)\\). \\(\\text{sopfr}(4)=2+2=4,\\text{sopfr}(20)=\\text{sopfr}(2&#94;2\\cdot 5)=2+2+5=9,\\ \\text{sopfr}(2018)=\\text{sopfr}(2\\cdot 1009)=2+1009=1011\\) 乗法的関数 乗法的関数は 乗法的関数 \\(m\\in\\mathbb{Z}&#94;{+}, n\\in\\mathbb{Z}&#94;{+}, \\gcd(m,n)=1\\) について \\(f(mn)=f(m)f(n)\\) を満たす数論的関数 \\(f(x)\\) をいう. 乗法的関数は, 任意の加法的関数 \\(f(n)\\) を用いて簡単に構成することができる. たとえば, 乗法的関数 \\(g(n)\\) を指数法則より \\(g(n)=2&#94;{f(n)}\\) とおくことができる. また, \\(2\\) つの乗法的関数 \\(f(n)\\) と \\(g(n)\\) をつかって, \\(h(n)=f(n)g(n)\\) という乗法的関数をおくことができる. より一般化すると, 命題1 \\(f(n)\\) が乗法的関数, 和 \\(\\displaystyle\\sum_{d\\mid n}\\) で \\(d\\) が \\(n\\) のすべての約数にわたるとき, \\(\\displaystyle g(n)=\\sum_{d\\mid n}f(d)\\) は乗法的関数であるといえる. 一応これを証明する. 証明1 : \\(n=n_1n_2,\\ \\gcd(n_1,n_2)=1\\) とすると, \\(n\\) の約数 \\(d\\) は \\(n_1\\) の約数 \\(d_1\\) と, \\(n_2\\) の約数 \\(d_2\\) との積で尽くされる. すなわち \\(\\gcd(d_1, d_2)=1\\) だから \\begin{align}\\displaystyle g(n)&=\\sum_{d\\mid n}f(d) \\\\&=\\sum_{d_1\\mid n_1,\\ d_2\\mid n_2}f(d_1,d_2) \\\\&=\\sum_{d_1\\mid n_1,\\ d_2\\mid n_2}f(d_1)f(d_2) \\\\&=\\sum_{d_1\\mid n_1}f(d_1)\\sum_{d_2\\mid n_2}f(d_2) \\\\&=g(n_1)g(n_2) \\end{align} \\(\\square\\) e.g.: \\(f(n):=\\gcd(n,k)\\) . \\(k=2\\) としたとき, \\(f(15)=f(3)f(5)=1,\\ f(24)=f(3)f(8)=2\\) 指数法則: \\(k\\in\\mathbb{Z}\\) に対する \\(n&#94;k\\) メビウス関数 \\(:= \\mu(n)\\). \\(\\mu(18)=\\mu(2\\cdot 3&#94;2)=0,\\ \\mu(6)=\\mu(2\\cdot 3)=1, \\mu(7)=-1\\). オイラーのトーシェント関数 \\(:= \\phi(n)\\). \\(\\phi(6)=\\phi(3)\\cdot\\phi(2)=2,\\ \\phi(28)=\\phi(4)\\cdot\\phi(7)=12\\). また 完全乗法的関数 \\(&#94;\\forall m\\in\\mathbb{Z}&#94;{+}, &#94;\\forall n\\in\\mathbb{Z}&#94;{+}\\) について \\(f(mn)=f(m)f(n)\\) を満たす乗法的関数 \\(f(x)\\) を完全乗法的関数という 1 . e.g.: ディリクレ級数 \\(a(n)\\) におけるディリクレの L 関数: \\(\\displaystyle L(s,a)=\\sum_{n=1}&#94;{\\infty}\\dfrac{a(n)}{n&#94;s}=\\prod_{p}\\left(1-\\dfrac{a(p)}{p&#94;s}\\right)&#94;{-1},\\). 自然数全体の総和が素数全体の積に等しい. 参考文献 Completely multiplicative function 2018 年 7 月 9 日アクセス. 代数学的な定義でいえば, モノイド( \\(\\mathbb{Z}&#94;{+},\\cdot\\) )から他のモノイドまでの準同型写像である. ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2018/ 7月/09/arithmeticFunction/","tags":"math","url":"posts/2018/ 7月/09/arithmeticFunction/","title":"数論的関数の用語と例"},{"text":"ついこの間に golang を初めて触り 1 , 大学の授業過程で AWS EC2 を使っていて, そのタグ機能を色々機械的に操作できれば便利だななどと思い, golang でなにか作る良い機会であるような気がしたので, 取り敢えず AWS EC2 のタグ機能に関する操作一式をそれなりに揃えたコマンドラインツールを作ってみた. 実装部分にかかった時間は 30 分程度であった. golang に慣れない身でも, API , 標準ライブラリ, ドキュメントが整備されているおかげでサクサクと動くところまで持っていくことができた. falgon/goec2tag: Instant CLI tool for mechanically manipulating AWS EC2 tags ほぼリポジトリにおいてある README のままであるが. $ ./dst/main --help Usage of ./dst/q3: -addT Give the tag to the instance. -endpoint string Endpoint. -filter string This flag is used in conjunction with the showtags flag to filter tags by describing filter statements. [ Example ] : ... -filter 'name:resource-id,values:i-xxxxxxxx i-yyyyyyyy' -instances string Instance id or instance tag name. -region string Region name ( default \"ap-northeast-1\" ) -rmT Remove tag from instance. -showtags DescribeTags API operation for EC2. Describes one or more of the tags for your EC2 resources. filter = ... -tags string Tag Key ( Use Key =) and Tag Value ( Use Value =) [ Example ] : ... -tags = 'Key=foo,Value=bar Key=hoge,Value=piyo...' $ ./dst/main -showtags ... $ ./dst/main -showtags -filter \"name:resource-id,values:i-xxxxxxxxxxxxxxxxx\" # filtering ... $ ./dst/main -instances = i-xxxxxxxxxxxxxxxxx -tags = 'Key=test,Value=hoge' -addT # adding tag ... $ ./dst/q3 -instances = i-xxxxxxxxxxxxxxxxx -tags = 'Key=test,Value=hoge' -rmT # remove tag ... まあ, これは言ってしまえば AWS SDK for go から単に API を叩いただけで, 実際に使うのであれば正直 awscli で事足りるから, 存在意義は全くないと思う. 個人的な収穫としては, 使い慣れていない言語のパラダイムをいくつか知ることはできた. とくに golang 標準の flags パッケージ, これは中々便利に感じた. 自分はもともと C++ ばかり書いていたので, こういうことを C++ で書きたいときは, Boost.Program_options とかの非標準ライブラリを使うことになるか, 自作するかになるだろうなあなどと思った. C++20 に期待(?). roki (2018) 「roki (2018)「golang 始めたてメモ」 https://falgon.github.io/roki.log/posts/2018/%206月/17/golangtrial/ ↩","loc":"posts/2018/ 7月/08/awsec2tag/","tags":"golang","url":"posts/2018/ 7月/08/awsec2tag/","title":"EC2 のタグを SDK で操作"},{"text":"以前のエントリ 1 では, AWS の API を golang から叩くために golang の言語機能を一通り触った. 自分は元々よく C++ を書いていたので golang で叩く前にまず C++ から適当に叩いてみていたのだが, ふと Haskell 用の AWS のライブラリの存在を知り, ひとまず触ってみたので, 記録と紹介を兼ねて書き残してみる. 執筆時現時点では, 公式が提供する AWS SDK は awscli を除き C++, Go, Java, javascript, . NET , PHP , Python, Ruby 2 となっており, amazonka 3 は非公式の Haskell 用 AWS SDK である. 基本的には, まず amazonka を導入した後, 必要となる AWS サービスに該当する amazonka-** を導入する. 今回は, ec2 インスタンスの立ち上げ, 停止を行なったので, amazonka-ec2 4 を利用した. amazonka は全体のデータのやり取りに Lens を多様しており, 利用者はこの恩恵を傍受できる. 早速であるが, くだらないサンプルを次に示す. とくにいま ec2 インスタンス上で何かしたいことはないので, 東京リージョンでインスタンスを立ち上げて, その直後に落とすこととする 5 . module Main where import qualified Network.AWS as AWS import qualified Network.AWS.Data as AWSD import qualified Network.AWS.EC2 as EC2 import System.IO ( stdout ) import Control.Lens instanceIds :: String instanceIds = \"i-********\" main :: IO () main = do let t0 = EC2 . startInstances & EC2 . sInstanceIds .~ [ AWSD . toText instanceIds ] let t1 = EC2 . stopInstances & EC2 . siInstanceIds .~ [ AWSD . toText instanceIds ] env <- AWS . newEnv ( AWS . FromFile ( AWSD . toText \"default\" ) \"/path/to/credentials\" ) lgr <- AWS . newLogger AWS . Debug stdout res0 <- AWS . runResourceT $ AWS . runAWS ( env & AWS . envLogger .~ lgr ) $ AWS . within AWS . Tokyo $ AWS . send t0 res1 <- AWS . runResourceT $ AWS . runAWS ( env & AWS . envLogger .~ lgr ) $ AWS . within AWS . Tokyo $ AWS . send t1 print res0 print res1 本家の各 SDK と同じように, 必要なサービスごとにライブラリがそれぞれ独立しているので, 基本的にまずは AWS CLI Command Reference をみてから, その操作を行うのに必要とするライブラリを amazonka から選んで導入することで, 実際に動くまでを円滑に進めることができるだろう. 参照 \" amazonka: Comprehensive Amazon Web Services SDK .\" http://hackage.Haskell.org/package/amazonka 2018 年 6 月 24 日アクセス. \" amazonka-ec2: Amazon Elastic Compute Cloud SDK .\" http://hackage.Haskell.org/package/amazonka-ec2-1.6.0 2018 年 6 月 24 日アクセス. \" Network. AWS \" http://hackage.Haskell.org/package/amazonka-1.6.0/docs/Network- AWS .html 2018 年 6 月 24 日アクセス \" Network. AWS . EC2 \" http://hackage.Haskell.org/package/amazonka-ec2-1.6.0/docs/Network- AWS - EC2 .html 2018 年 6 月 24 日アクセス roki (2018)「golang 始めたてメモ」 https://falgon.github.io/roki.log/posts/2018/%206月/17/golangtrial/ ↩ 「 AWS SDK とツール」 https://aws.amazon.com/en/getting-started/tools-sdks/ 2018 年 6 月 24 日アクセス. ↩ 参照 . ↩ 参照 . ↩ 前提として, AWS IAM の設定およびアクセスキーの設定が済んでいること. ↩","loc":"posts/2018/ 6月/24/amazonka/","tags":"Haskell","url":"posts/2018/ 6月/24/amazonka/","title":"amazonka で EC2 インスタンスの操作"},{"text":"大学のレポート内で De Bruijn Sequence について書く機会があった. これまた 以前と同じく , 折角なのでこちらのブログにも, 若干内容を変えつつ載せておくことにした. De Bruijn Sequence は, オランダ人の数学者 Nicolaas de Bruijn に因んで命名された系列で, 特定の長さのすべての組み合わせを含む系列である. 次数 \\(n\\) の \\(k\\) 種類に関する De Bruijn Sequence \\(B\\left(k, n\\right)\\) は, 長さ \\(n\\) で表現可能なすべての部分列によって構成される. 次元数 \\(2\\) (すなわちバイナリ) の De Bruijn Sequence は \\(B\\left(2, n\\right)\\) であり, \\(n\\) ビットの固有な部分系列から成る \\(2&#94;n\\) ビット長の系列である. 例えば, \\(B\\left(2, 3\\right)\\) は \\(00011101_{(2)}\\) であり \\(n\\) に対する有向グラフが下図 1 のように示される. この系列から \\(3\\) ビットずつ取る, または図 1 の有向グラフから \\(B(2, 3)\\) を再構築していくと, 次の表で示す部分系列を構成することがわかる. \\[B(2,3)\\] \\[10\\ {\\rm進値}\\] \\(B(2,3)\\) の部分系列 \\[\\overbrace{000}&#94;{sub\\ seq}11101_{(2)}\\] \\[0_{(10)}\\] \\[0\\overbrace{001}&#94;{sub\\ seq}1101_{(2)}\\] \\[1_{(10)}\\] \\[00\\overbrace{011}&#94;{sub\\ seq}101_{(2)}\\] \\[3_{(10)}\\] \\[000\\overbrace{111}&#94;{sub\\ seq}01_{(2)}\\] \\[7_{(10)}\\] \\[0001\\overbrace{110}&#94;{sub\\ seq}1_{(2)}\\] \\[6_{(10)}\\] \\[{00011\\overbrace{101}&#94;{sub\\ seq}}_{(2)}\\] \\[5_{(10)}\\] \\[{000111\\overbrace{01\\underbrace{0}_{cir}}&#94;{sub\\ seq}}_{(2)}\\] \\[2_{(10)}\\] \\[{0001110\\overbrace{1\\underbrace{00}_{cir}}&#94;{sub\\ seq}}_{(2)}\\] \\[4_{(10)}\\] 最後の \\(2\\) つの部分系列は \\(00011101_{(2)}\\) から \\(3\\) ビットずつとって構成できないが, 系列の初めへ循環していると考えることで, これが成り立つ. De Bruijn Sequence は, いくつかのコンピュータアルゴリズムで応用でき, 例えば Number of Training Zero を求める問題も, よく知られた応用例の 1 つである. これは ntz と呼ばれる. 以降, \\(m=n-1\\) , \\(x\\) を \\(8\\) ビットの値, \\(x_i\\ \\ \\left(\\left\\{i \\in \\mathbb{Z}\\mid 0 < i < 9\\right\\}\\right)\\) を lsb 見た値 \\(x\\) の \\(i\\) 番目のビット値, Number of Training Zero を ntz とする. 例えば \\(x=192_{(10)}\\) は $$x=1\\overbrace{\\overbrace{1}&#94;{x_7}\\underbrace{\\overbrace{0}&#94;{x_6}00000}_{m}}&#94;{n}$$ であり, \\(m=6\\) が解である. ntz をプログラムで解こうとしたとき, 例えば次のような実装がよく知られる. module Main where import Control.Monad ( void ) import Data.Bits (( .&. ), shiftR ) import Data.Word ( Word8 ) import Data.Tuple.Extra ( first , second , dupe ) import Test.HUnit ( runTestText , putTextToHandle , Test ( TestList ), ( ~: ), ( ~?= )) import System.IO ( stderr ) -- | pop counting 8 bit popcnt8 :: Word8 -> Word8 popcnt8 = let fol m s = uncurry ( + ) . first ( .&. m ) . second (( .&. m ) . (` shiftR ` s )) . dupe in flip ( foldr id ) [ fol ( 0x0f :: Word8 ) 4 , fol ( 0x33 :: Word8 ) 2 , fol ( 0x55 :: Word8 ) 1 ] -- | ntz 8 bit version 1 ntz81 :: Word8 -> Word8 ntz81 = uncurry id . first ( bool ( popcnt8 . pred . uncurry ( .&. ) . second negate . dupe ) ( \\ _ -> 8 :: Word8 ) . ( == 0 )) . dupe main :: IO () main = void . runTestText ( putTextToHandle stderr False ) $ TestList [ \"ntz81 192: \" ~: ntz81 ( 192 :: Word8 ) ~?= 6 ] popcnt8 は, 各ビットそのものがその桁で立っているビット数と捉え, 畳み込んでいくことで最終的に立っている全体のビット数を得る関数である. ntz81 は, まず lsb から見て一番端で立っているビットを倒し, それまでのビット列を全て立てておく. これを popcnt8 に渡すことで ntz としての役割を果せる. これはとても有名な方法で, よく最適化された手法であるといえるのだが, De Bruijn Sequence を利用すると, より少ない演算回数で ntz が解ける. De Bruijn Sequence を利用して ntz を解く方法は, 随分前に このブログさん で丁寧に解説されているので, 特別ここで改めて詳しく述べる必要はないとは思うが, 一応レポート内で書いた内容を載せておく. \\(B(2, n)\\) から成る部分系列を元とした集合 \\(X\\) と, 「系列全体からみて, その部分系列を得るにいくつスライドしたか」を元とする集合 \\(Y\\) の写像 \\(f\\) を定める(例: \\(f(000_{(2)}) = 0, f(001_{(2)}) = 1, f(011_{(2)}) = 2, \\cdots f(100_{(2)}) = 7\\) ). \\(x\\) のうち一番右端に立っているビットのみを残し, 他を全て倒す( x & -x ). この値は必ず \\(2&#94;i\\) である. これを \\(y\\) とする. \\(B(2, n)\\) と \\(y\\) の積を得る( \\(y = 2&#94;i\\) であるから, この演算は系列に対する \\(i\\) ビットの左シフト演算である). これを \\(z_0\\) とする. いま, ここまでの演算を \\(s\\ (\\{s \\in \\mathbb{Z}\\mid s > n, s は 2 の累乗数\\})\\) ビットの領域上で行なったとしたとき, \\(z_0\\) に対して \\(s-n\\) ビット左にシフトする( \\(z_0\\) を msb から数えて \\(n\\) ビット分のみが必要であるから, それ以外を除去する). これを \\(z_1\\) とする. \\(f(z_1)\\) の値が ntz の解である. 要するに, De Bruijn Sequence の特徴を生かして, ユニークなビット列に紐づく各値をマッピングしておき, 積がシフト演算と同等となるように調節, いらない値を省いた後にテーブルを引くのである 2 . module Main where import Data.Array ( Array , listArray , ( ! ), elems ) import Data.Tuple.Extra ( dupe , first ) import Data.Bits (( .&. ), shiftR ) import Data.Word ( Word8 ) import Test.HUnit ( runTestText , putTextToHandle , Test ( TestList ), ( ~: ), ( ~?= )) import System.IO ( stderr ) import Control.Monad ( void ) -- | ntz 8 bit version 2 ntz82 :: Word8 -> Word8 ntz82 = ( tb ! ) . (` shiftR ` 4 ) . fromIntegral . (( 0x1d :: Word8 ) * ) . uncurry ( .&. ) . first negate . dupe where tb = listArray ( 0 , 14 ) [ 8 , 0 , 0 , 1 , 6 , 0 , 0 , 2 , 7 , 0 , 5 , 0 , 0 , 4 , 3 ] :: Array Int Word8 main :: IO () main = void . runTestText ( putTextToHandle stderr False ) $ TestList [ \"192 ntz: \" ~: ntz82 ( 192 :: Word8 ) ~?= 6 ] ここまでは \\(x\\) が \\(8\\) ビットである前提を置いて述べてきたが, 任意の \\(B(2, n)\\) が求まれば, どのようなビット長のデータに対しても同様にして計算できることがわかる. これをどのように得るかであるが, ここでは Prefer One algorithm 3 という比較的単純なアルゴリズムを用いて \\(B(2, n)\\) を得ることとする. このアルゴリズムに関する詳細と証明は原文を読んでほしいが, その大雑把な概要だけをここでは述べる. 任意の正整数 \\(n\\geq 1\\) について, まず \\(n\\) 個の \\(0\\) を置く. 次に, 最後の \\(n\\) ビットによって形成された部分系列が以前に系列内で生成されていなかった場合, その次のビットに対して \\(1\\) を, そうでない場合 \\(0\\) を置く. \\(0\\) または \\(1\\) のどちらを置いても, 以前に生成していた部分系列と一致するならば停止する. 下記に示す同アルゴリズムの実装例は, \\(2&#94;3\\) から \\(2&#94;6\\) に対応する De Bruijn Sequence を得ている. module Main where import Data.Array ( listArray , ( ! )) import Data.Tuple.Extra ( dupe , first ) import Control.Monad ( mapM_ ) import Numeric ( showHex ) preferOne :: Int -> [ Int ] preferOne n = let s = 2 &#94; n in let ar = listArray ( 1 , s ) $ replicate n False ++ map ( not . yet ) [ n + 1 .. s ] yet i = or [ map ( ar ! ) [ i - n + 1 .. i - 1 ] ++ [ True ] == map ( ar ! ) [ i1 .. i1 + n - 1 ] | i1 <- [ 1 .. i - n ]] in cycle $ map fromEnum $ elems ar bin2dec :: [ Int ] -> Int bin2dec = sum . uncurry ( zipWith ( * )) . first ( map ( 2 &#94; ) . takeWhile ( >= 0 ) . iterate ( subtract 1 ) . subtract 1 . length ) . dupe somebases :: Int -> IO () somebases n = let d = take ( 2 &#94; n ) $ L . preferOne n in print ( d , bin2dec d , showHex ( bin2dec d ) \"\" ) main :: IO () main = mapM_ somebases [ 3 .. 6 ] 各 \\(B(2, n)\\) が次のように得られる. ([ 0 ,0,0,1,1,1,0,1 ] ,29,1d ) ([ 0 ,0,0,0,1,1,1,1,0,1,1,0,0,1,0,1 ] ,3941,f65 ) ([ 0 ,0,0,0,0,1,1,1,1,1,0,1,1,1,0,0,1,1,0,1,0,1,1,0,0,0,1,0,1,0,0,1 ] ,131913257,7dcd629 ) ([ 0 ,0,0,0,0,0,1,1,1,1,1,1,0,1,1,1,1,0,0,1,1,1,0,1,0,1,1,1,0,0,0,1,1,0,1,1,0,1,0,0,1,1,0,0,1,0,1,1,0,0,0,0,1,0,1,0,1,0,0,0,1,0,0,1 ] ,285870213051386505,3f79d71b4cb0a89 ) Python, networkx, pyplot で 生成 . ↩ 本エントリでは Haskell による実装を示しているが, だいぶ以前に C++ で同様の ntz を実装した のであった. この実装は, この Qiita 投稿 の内容と殆ど同じ. C++ では, 簡単なテンプレートメタプログラミングにより, ビット長ごとに必要となるビットマスクや演算を, 同じ関数呼び出しから型ごとに適切に分岐するよう実装できる(Haskell でも, 似たようなことはできる). ↩ Abbas Alhakim, \"A SIMPLE COMBINATORIAL ALGORITHM FOR DE BRUIJN SEQUENCES \" https://www.mimuw.edu.pl/~rytter/ TEACHING / TEKSTY /PreferOpposite.pdf 2018-06-21 アクセス. ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2018/ 6月/22/debruijnseq/","tags":"math","url":"posts/2018/ 6月/22/debruijnseq/","title":"De Bruijn Sequence"},{"text":"大学の授業で AWS の API を触る機会があり, その際に golang を使うようなので( API 一覧には, C++ 版もあるようなので, 個人的には C++ が良かった), 特に意義のないコードを取り敢えずいくつか書いてみている. ある程度文法がわかったら, まずはとにかくクイックソートを書くよ. 初めは append とスライスを乱用すれば, 関数型言語っぽく再帰が書けてスッキリするので, reverse を func reverse ( ar [] int ) [] int { var rev func ([] int , [] int ) [] int rev = func ( a , b [] int ) [] int { if len ( a ) == 0 { return b } return rev ( a [ 1 :], append ([] int { a [ 0 ]}, b ... )) } return rev ( ar , make ([] int , 0 )) } というように書いてみていたのだが, golang は現在のところ, TCO が効かない 1 ようなのでやめた. そして一通り A Tour of Go の Exercise をやってみた. LoopsandFunctions Slices Maps FibonacciClosure Stringers Erros Readors rot13Reader Images Equivalent Binary Trees Web Crawler 最後の Web Crawler の問題には他と比べて時間がかかってしまったが, 比較的楽しみながらできたので良かったのではないだろうか. 参考: \"proposal: Go 2: add become statement to support tail calls #22624\" https://github.com/golang/go/issues/22624 2018 年 6 月 17 日アクセス. \"The Go Programming Language - Release History\" https://golang.org/doc/devel/release.html 2018 年 6 月 17 日アクセス. ↩","loc":"posts/2018/ 6月/17/golangtrial/","tags":"golang","url":"posts/2018/ 6月/17/golangtrial/","title":"golang 始めたてメモ"},{"text":"ふと, C++ でもこんなような記述, 普通に出来るべきなんじゃないかなぁと思った. Prelude > : m + Data . Tuple . Extra Prelude Data . Tuple . Extra > uncurry ( + ) $ first ( * 2 ) $ dupe 42 126 Prelude Data . Tuple . Extra > uncurry ( + ) $ ( + 42 ) &&& ( * 2 ) $ 42 168 取り敢えず, 似たような構文で同じような処理となるように 作ってみた . C++11 以降では, Variadic templates が使えるので, Data.Tuple.Extra ( Control.Arrow ) の first , second 関数のように, タプルの 1 番目, 2 番目に作用させるといった関数をそれぞれ別個作る必要はない. 従って, これを作用させるタプルのインデックス値で指定できるようにしてみた( srook::tuple::utility::nth ). 他のものも同様, なんとなく似た感じになるように, なんとなくやってみた(?). 結局, 関数を次々と呼び出す構文をすっきりと見せるために, Range TS のように operator| をオーバーロードした. C++14 以降では Return type deduction が使えるが, やはり型を明示的に書きたかったので, そのあたりでいくらかテンプレートメタプログラミングをした. 個人的には久しぶりに C++ を書く上で, これが一番 C++ らしさを感じたし, 最も楽しい部分であった. このブログに移行してきて, 初の日記っぽい内容の投稿となった気がする.","loc":"posts/2018/ 6月/14/DTExstdtuple/","tags":"C++","url":"posts/2018/ 6月/14/DTExstdtuple/","title":"C++ で Data.Tuple.Extra っぽいもの"},{"text":"お題自由な学校のレポート課題 1 内で, ショアのアルゴリズムを説明するために QFT の概要について示したのだが, 折角なのでその内容の一部を抜粋し, こちらのブログのほうにも載せておくことにした. ショアのアルゴリズムについては, 調べればいくらでも出てくるし, 学会誌, 書籍等で分かり易く述べられていることも多いので, 本エントリで特別取り上げることはしないが, その大体は以下のアクティビティ図の手順の通りである 2 . なお, 私自身は量子力学, 量子コンピュータ分野における専門家ではないため, 注意してください. 間違った箇所, 不自然な箇所等ございましたら, ご報告いただけると幸いです. まず, DFT を次のようにおく 3 . \\[\\displaystyle F(t) = \\sum_{x = 0}&#94;{n-1} f(x)\\exp\\left(-j\\dfrac{2\\pi tx}{n}\\tag{1}\\label{eq:third}\\right)\\] ここで, \\(f(x)\\) は入力の関数, \\(j\\) は虚数単位である. QFT は, 正規化係数を \\(\\dfrac{1}{\\sqrt{n}}\\) とした有限次元内積空間内における正規直交基底 \\(|0\\rangle, \\cdots, |n-1\\rangle\\) 上の状態, \\(\\displaystyle \\sum_{x=0}&#94;{n-1} f(x)|x\\rangle\\) の各係数となる複素関数の値を離散フーリエ変換したものであるといえる. すなわち, 式 \\(\\eqref{eq:third}\\) の定義をふまえて, \\[\\displaystyle \\sum_{x = 0}&#94;{n-1} f(x)|x\\rangle \\mapsto \\sum_{i = 0}&#94;{n-1}F(i) |i\\rangle\\] または, \\[\\displaystyle |x\\rangle \\mapsto \\dfrac{1}{\\sqrt{n}}\\sum_{k=0}&#94;{n-1}\\exp\\left(-j\\dfrac{2\\pi xk}{n}\\right) |k\\rangle\\] と表すことができ, いま \\(m\\) Qubit があるならば, 扱えるデータ数は \\(2&#94;m\\) となるため \\[\\displaystyle |x\\rangle \\mapsto \\dfrac{1}{\\sqrt{2&#94;m}}\\sum_{k=0}&#94;{2&#94;m-1}\\exp\\left(-j\\dfrac{2\\pi xk}{2&#94;m}\\right) |k\\rangle\\] と表せる. これを量子回路として実装していく. 結論から言うと, この量子回路は, アダマールゲートと, 制御ビットが \\(1\\) のときのみ, 信号量子ビットの位相を \\(\\exp\\left(\\dfrac{j2\\pi}{2&#94;{k+1}}\\right)\\) だけシフトする 制御位相シフトゲートを利用することで実現できる. 次に, 2 Qubit を用いた QFT の量子回路図を示す 4 . ここで \\(|q_1\\rangle\\) は \\[|0\\rangle + \\exp\\left(j\\pi q_{1}\\right)|1\\rangle \\to |0\\rangle + \\exp\\left(\\dfrac{j\\pi}{2}(2q_1+q_0)\\right)|1\\rangle \\tag{2}\\label{eq:fourth}\\] と変化し, \\(|q_0\\rangle\\) は \\[|0\\rangle + \\exp\\left(j\\pi q_{0}\\right)|1\\rangle \\tag{3}\\label{eq:fifth}\\] と変化することがいえる. いま, 式 \\(\\eqref{eq:fourth}\\) の結果を \\(|a_0\\rangle\\), 式 \\(\\eqref{eq:fifth}\\) の結果を \\(|a_1\\rangle\\) としたとき $$|a_1\\rangle |a_0\\rangle = \\left\\{|0\\rangle + \\exp(j\\pi q_0)|1\\rangle\\right\\}\\left\\{|0\\rangle + \\exp\\left(j\\pi q_1 + \\dfrac{j\\pi q_0}{2}\\right)|1\\rangle\\right\\}\\tag{4}\\label{eq:sixth}$$ がいえる. ここで, \\(q\\) および \\(a\\) の値の \\(2\\) 進表記をそれぞれ \\([q_1, q_0],\\ [a_1, a_0]\\) とすると, \\(q = 2q_1 + q_0,\\ a = 2a_1+a_0\\) であるので式 \\(\\eqref{eq:sixth}\\) は, $$ |a\\rangle = |0\\rangle + \\exp\\left(\\dfrac{j\\pi}{2}q\\right)|1\\rangle + \\exp\\left(\\dfrac{j\\pi}{2}q\\times 2\\right)|2\\rangle + \\exp\\left(\\dfrac{j\\pi}{2}q\\times 3\\right)|3\\rangle $$ と展開できる. \\(|a\\rangle\\) の各状態の係数が \\(|q\\rangle\\) の各状態の係数のフーリエ変換になっていることがわかる. 内容の全コンテンツを リポジトリ にまとめているのでもし良ければ. ↩ 図は plantuml で生成: コード . この画像もレポート用に生成したものだが, 折角なのでこちらにも貼っておくことにした. ↩ 単純にコードに落とし込むだけであるので大したことはないのだが, レポート内で説明するために Haskell で DFT と IDFT を 実装してある ので, 一例としてもし良ければ. 一応 テスト済み . ↩ 図は qasm2circ で生成: コード . ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2018/ 6月/08/qft/","tags":"Quantum mechanics","url":"posts/2018/ 6月/08/qft/","title":"QFTのメモ"},{"text":"以前の投稿, ARPパケットに対する挙動からネットワーク上の盗聴者を特定する にて, 実験を行うにあたりリンクレイヤー上のパケットの受信と送信を行なった. このパケットを別のネットワークインタフェースから送出するようにすればブリッジになるし, MAC アドレステーブルと照合して転送すれば L2 スイッチにもなるとのことで, 一応 Linux 上で動くものを作ってみた. toybridge - The simply Linux network bridge implementation for learning 2 枚の NIC が必要であるが, Virtual Box の仮想アダプタを利用すれば良い. 実装の本質的な部分は, 異なるディスクリプタへの書き込みのみである. これを応用して, 複数個のネットワークインタフェースにも対応してみたい. 余談 以下, ブリッジそのものの話題とは少しずれるが, 先に述べた以前の記事での実装と, そのコードのスタイルについて少し触れる. C++ 言語とそのコミュニティにおいては, エラー/例外をどのように扱うべきなのか, そのベストプラクティスは何かという問いの答えについて, 複数の回答, 派閥が存在する 1 . 個人的には, どれもあまり都合の良くないときもあれば, 都合の良いときもあり, 一概にこれが最も良いと断言することはナンセンスであると思っている. 先に述べた以前の記事での実装もそうだが, 今回のこの実装でも, 自作ライブラリの srook::optional をふんだんに利用している. その中でも Haskell の IO モナドを意識して定義/オーバーロードした演算子, >>= , >> を用いたスタイルで記述している. 通常のこのようなディスクリプタを取り回すようなプログラムでは, エラーチェックが顕著となりやすく, 本質的な処理と紛れてしまうことがある. 特に, C のライブラリや API を用いる場合は, 戻り値にエラーの状態を持たせることが多いので, 単純に記述すれば if 文のネストになる. そこで, 実験的に C++ に Haskell の IO モナドのようなパラダイムの一部を持ち込んで使ってみたのが, 前回と今回の実装である. なお, Haskell の IO モナドのようなパラダイムを C++ に持ち込もうという発想は, 特別目新しいものではなく 2 , 以前から一部で取り上げられていた話題である. 個人的には, if 文でエラーハンドリングを随時行うよりも, 本質的な処理のみが視覚内に収まってくることから, このスタイルは好みであるが, C++ の標準ライブラリにおける入出力の表現—シフト演算子のオーバーロードが, C++ コミュニティ内であまり好評ではない一面もある 3 . そのような側面から見れば, あまり良いとは言えないのかもしれない. 参考文献 小俣光之 (2011) 『ルーター自作でわかるパケットの流れ』技術評論社. ISBN978 -4-7741-4745-1 これに関する詳しい言及は, Herb Sutter 氏による新しい例外機構の提案文書を参照. [ P0709R0 ] Herb Sutter. \"Zero-overhead deterministic exceptions: Throwing values\" ( WG21 paper, 2018-05-02) ↩ 以前旧ブログにて取り上げた記事: モナドの概念をC++に導入して冗長なエラーハンドリングを回避する ↩ この話題に関する言及: Stackoverflow , <iostream> のデザインに関する言及: Quora ↩","loc":"posts/2018/ 5月/29/createToybridge/","tags":"C++","url":"posts/2018/ 5月/29/createToybridge/","title":"シンプルなブリッジのソフトウェア実装"},{"text":"フィボナッチ数列の漸化式を次のように置く. \\[f_{n+2} = f_{n+1} + f_n\\ (n\\geq 0)\\] ここで, 初項と第二項をそれぞれ \\(a_1=1, a_2=1\\) とする. 各項を \\(f_{n+2}\\rightarrow c&#94;2、f_{n+1}\\rightarrow c、f_n\\rightarrow 1\\) と置き換えると \\[c&#94;2=c+1\\tag{1}\\] が得られる. この解は \\(c=\\dfrac{1\\pm{\\sqrt{5}}}{2}\\) となる. ここで, \\(\\psi = \\dfrac{1-\\sqrt{5}}{2}, \\phi = \\dfrac{1+\\sqrt{5}}{2}\\) と置く. フィボナッチ数列の漸化式の特性方程式の解は \\((1)\\) の解より \\(\\psi, \\phi\\) であるから $$f_{n+2}=f_{n+1}+f_{n}\\Leftrightarrow\\begin{cases}f_{n+2}-\\psi f_{n+1}=\\phi(f_{n+1}-\\psi f_n) \\\\f_{n+2}-\\phi f_{n+1}=\\psi(f_{n+1}-\\phi f_n)\\end{cases}$$ と変形できる. いま \\(b_n=f_{n+1}-\\psi f_n, c_n=f_{n+1}-\\phi f_n\\) と置くと次の漸化式が得られる. $$\\begin{cases}b_{n+1}=\\phi b_n\\\\c_{n+1}=\\psi c_n\\end{cases}$$ また \\(f_1=1, f_2=1\\) より $$\\begin{cases}b_1=f_2-\\psi f_1=1-\\psi\\\\ c_1=f_2-\\phi f_1=1-\\phi\\end{cases}$$ として, 数列 \\(\\{b_n\\}\\) と数列 \\(\\{c_n\\}\\) の初項が求まる. 故に, 数列 \\(\\{b_n\\}\\) は初項 \\(1-\\psi\\), 公比 \\(\\phi\\) の等比数列であるから, \\(b_n = (1-\\psi)\\phi&#94;{n-1}\\), 数列 \\(\\{c_n\\}\\) は初項 \\(1-\\phi\\), 公比 \\(\\psi\\) の等比数列であるから, \\(c_n = (1-\\phi)\\psi&#94;{n-1}\\) といえる. さらに \\(b_n, c_n\\) を上記の定義より代入すると, $$\\begin{cases} \\phi&#94;n=b_n=f_{n+1}-\\psi f_n\\\\\\psi&#94;n=c_n=f_{n+1}-\\phi f_n\\end{cases}$$ が得られる. 上の式から下の式を引くと \\(\\phi&#94;n-\\psi&#94;n=-\\psi f_n+\\phi f_n=(\\phi-\\psi)f_n\\) であるから, 一般項 \\(f_n\\) は \\[f_n=\\dfrac{1}{\\phi-\\psi}\\left( \\phi&#94;n-\\psi&#94;n\\right)\\] \\(\\therefore\\) \\(\\psi, \\phi\\) を上記の定義より代入すると, フィボナッチ数列の一般項 \\[f_n=\\dfrac{1}{\\sqrt{5}}\\left\\{\\left(\\dfrac{1+\\sqrt{5}}{2}\\right)&#94;{n}-\\left(\\dfrac{1-\\sqrt{5}}{2}\\right)&#94;{n} \\right\\}\\] となり, フィボナッチ数列の一般項が求まった. 確認. {-# OPTIONS_GHC -Wall #-} import System.Random ( getStdRandom , randomR ) import System.IO ( stderr ) import Test.HUnit ( Test ( TestList ), ( ~: ), ( ~?= ), runTestText , putTextToHandle ) import Control.Monad ( void ) fibGeneralTerm :: Int -> Integer fibGeneralTerm = let phi = ( 1 + sqrt 5 ) / 2 :: Double in floor . ( + 0.5 ) . ( / sqrt 5 ) . ( phi &#94;&#94; ) fib :: [ Integer ] fib = 0 : 1 : zipWith ( + ) fib ( tail fib ) mkTestList :: Int -> Int -> Int -> IO Test mkTestList b l times = TestList <$> loop 1 where loop i | i <= times = do r <- getStdRandom $ randomR ( b , l ) ( : ) ( \"fib test: \" ++ show i ++ \", value: \" ++ show r ~: fibGeneralTerm r ~?= fib !! r ) <$> loop ( succ i ) | otherwise = return [] main :: IO () main = mkTestList 0 50 5 >>= void . runTestText ( putTextToHandle stderr False ) cases : 5 Tried : 5 Errors : 0 Failures : 0 上で導出した式の第二項の最大値は \\(\\displaystyle \\dfrac{1}{\\sqrt{5}} \\approx 0.447\\) が最大であることから, 正確な整数値を求めるのには第二項を略してしまって \\(0.5\\) を加え, 床関数を作用させれば十分である 1 . 上のコードでもそれを利用している. $$f_n=\\left\\lfloor \\dfrac{\\phi&#94;{n}}{\\sqrt{5}}+\\dfrac{1}{2} \\right\\rfloor$$ ただし, 計算処理内で浮動小数点数による加算を用いていることから, 大きな値になればなるほど絶対誤差が生じていくことになる. 今回の実行結果も, たまたまその誤差が埋もれただけであって fibGeneralTerm の実行結果に対する厳密な信憑性はない. 参考: ウィキペディア - フィボナッチ数 ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2018/ 5月/18/fibGeneralTerm/","tags":"math","url":"posts/2018/ 5月/18/fibGeneralTerm/","title":"フィボナッチ数列の一般項の導出"},{"text":"通信が暗号化されていればまだ良いが, 自分の送受信しているパケットを同一ネットワーク上の信用できない者/物に 無断で見られるのはやはり気持ちの良いものではない. 本エントリではそのような不届き者の存在を仮定して, その不届き者を比較的簡単に特定するといった試みを行う. お断り 一応お断りを明記する. 本エントリでの試行は当然ながら私個人のローカル LAN 上で行なっており, 同様の試行を公衆回線上などで行うと迷惑/法に抵触する可能性があるのでやめること. 本エントリに起因する直接的又は間接的な損害に関して, その理由及び原因を問わず著者(Roki) は一切の責任を負わない. ネットワーク盗聴を検出する原理 [ 2018/5/6 追記 : 本セクションの内容に関する追記は、末尾セクション追記にて参照. — 追記ここまで ] ネットワークに接続するためには, 大抵コンピュータに NIC を装着して TCP / IP の設定を済まし, ハブに接続する. 同プロトコルにおける各コンピュータの通信では, IP アドレスと MAC アドレスによる論理情報と物理情報の組み合わせを利用して, 目的のコンピュータに対するパケットの送信を実現する. 通常, その過程で NIC は自分とは無関係であるパケットを破棄する. しかし NIC をプロミスキャスモードにすると, 自分とは無関係であるパケットを破棄せずに取り込むようになる. 盗聴者はこれを利用して, 同一ネットワーク上を流れる他人のパケットを取得できる. IP アドレスと MAC アドレスを関連付けるためには ARP / RARP パケットを送信する. ARP パケットは, アドレス解決を必要とするノードによってブロードキャスト送信され, 要求に対応するノードが応答を行う. ブロードキャストは同一セグメント内にしか到達しないため, 他のセグメントと通信する際はルーターに依頼する. このとき, 要求に対応しない非プロミスキャスモードであるノードはその ARP 要求を破棄する. これに対して, プロミスキャスモードのノードは, 先に述べた通り全てのパケットを取り込む. しかし, プロミスキャスモードであっても, 通常この取り込まれた ARP 要求に対する応答を返すことはしない. なぜならば NIC のモードに関わらずソフトウェアによるフィルタが通常 OS 内部で働いている 1 からである. ただ, このソフトウェアによるフィルタの実装は甘い 場合がある . ブロードキャストを判定するときに, 正確には FF : FF : FF : FF : FF : FF の 6 バイトを比較しなければならないところを, 最初の 1 バイトだけで判定するなどの実装が 有りうる のである. 例えば, そのような実装となっているソフトウェアを積んだコンピュータが, 同一 LAN 上にプロミスキャスモードで稼働しているとする. 宛先を FF : xx:xx:xx:xx:xx としてそのコンピュータの MAC アドレスを目的とする 2 ARP パケットを送ると, NIC が Ethernet の仕様に忠実に従っていた場合, 送られてきた宛先は FF : FF : FF : FF : FF : FF ではないためブロードキャストではないと判断する. よってプロミスキャスモードで稼働していない場合, この ARP 要求は NIC によって破棄される. しかし, プロミスキャスモードである場合はこれを取り込む. 取り込んだ先に待っているのはソフトウェアによるフィルタであるが, これが甘い場合, それをブロードキャストアドレスとして認識し, ARP 応答を返すのである. ここで重要なのは, NIC とソフトウェアそれぞれでブロードキャストに対する判断が異なっている ということである. これにより, プロミスキャスモードとなっているノードのみが, いま送信した ARP パケットに応答してしまうため, 特定ができるかもしれない. 試行 実験環境は次のとおり. / 盗聴側 検出側 OS Ubuntu 16.04 LTS (4.13.0-37-generic) Ubuntu 17.04 (4.13.0-37-generic) NIC プロミスキャスモード(enp4s0f2) 通常モード(enp19s0) MAC アドレス 80:fa:5b:xx:xx:xx 24:b6:fd:xx:xx:xx IP アドレス 192.168.12.4 192.168.12.3 盗聴側の MAC アドレスが検出側で得られれば良い. 実験には, 宛先を少し弄って ARP パケットを送信できるソフトウェアが必要である. nping や arping などを少し見て見たが, 宛先 MAC アドレスを弄れるような機能は特になかった( FF : FF : FF : FF : FF : FF でない ARP パケットを送る用途は殆どないだろうし, 当然だ)ので, 自分で作った. ついでに, 超簡易 ARP パケットキャプチャも作ってみた. これらは 上記の OS で動作を確認している. 動作テストには tcpdump を用いた 3 . ARP experiment - This ia project for learning to detect computers operation in promiscuous mode on the same network using ARP packet and broadcast mechanism 特に何も指定せずに make すると, 通常の ARP パケットを送信するバイナリが /dst/sendarp としてビルドされ, -f Makefile_bogus を指定すると宛先 MAC アドレスを FF : FF : FF : FF : FF : FE とした ARP パケットを送信するバイナリが同様にしてビルドされる. どちらの場合においても, /dst/dump_arp がビルドされ, これが超簡易 ARP パケットキャプチャだ. コマンドラインオプションに -p を指定すると, NIC をプロミスキャスモードにして動作する. これを上記で示した環境それぞれでビルドし, その挙動を見てみる. なお本実験では直接盗聴側の IP アドレスを指定しているが, 実際では総当たりすることになるだろう 2 . また検出側では自身の本当の IP アドレスと MAC アドレスを利用して試行しているが, 実際ではこれらを何かしら偽装することも考えられるだろう. まずは, 通常通り ARP を送信してみる. 検出側$ sudo ./dst/dump_arp enp19s0 & 検出側$ sudo ./dst/sendarp enp19s0 192 .168.12.4 ether_header ------------------------- dhost = 24 :b6:fd:xx:xx:xx shost = 80 :fa:5b:xx:xx:xx type = 806 ( ARP ) 盗聴側$ sudo ./dst/dump_arp enp4s0f2 # 非プロミスキャスモード dhost = ff:ff:ff:ff:ff:ff shost = 24 :b6:fd:xx:xx:xx type = 806 ( ARP ) 正常にやりとりができているようだ. 続いて, 盗聴側は非プロミスキャスモードのまま, 検出側から FF : FF : FF : FF : FF : FE 宛てに ARP パケットを送信してみる. 検出側$ make -f Makefile_bogus 検出側$ sudo ./dst/dump_arp enp19s0 & 検出側$ sudo ./dst/sendarp enp19s0 192 .168.12.4 # 宛先 FF:FF:FF:FF:FF:FE の ARP パケット # ... 対応する出力なし 盗聴側$ sudo ./dst/dump_arp enp4s0f2 # 非プロミスキャスモード # ... 対応する出力なし NIC のフィルタリングによって, このパケットは省かれるため応答が返ってくることはない. つまり, 192.168.12.4 は盗聴していないということがわかる. 次に, 盗聴側をプロミスキャスモードにして FF : FF : FF : FF : FF : FE 宛てに ARP パケットを送信してみる. 検出側$ sudo ./dst/dump_arp enp19s0 & 検出側$ sudo ./dst/sendarp enp19s0 192 .168.12.4 # 宛先 FF:FF:FF:FF:FF:FE の ARP パケット dhost = 24 :b6:fd:xx:xx:xx shost = 80 :fa:5b:xx:xx:xx type = 806 ( ARP ) 盗聴側$ sudo ./dst/dump_arp enp4s0f2 -p # プロミスキャスモード dhost = ff:ff:ff:ff:ff:fe shost = 24 :b6:fd:xx:xx:xx type = 806 ( ARP ) 応答が返ってきた. つまり, 192.168.12.4 はプロミスキャスモードであり, 盗聴している可能性を特定できた. 当然ながら OUI を調べればメーカーがわかるので, 結果から盗聴者の目星をつけることができる. $ curl -s -D - http://standards-oui.ieee.org/oui.txt | grep 80FA5B -A 4 80FA5B ( base 16 ) CLEVO CO. NO. 129 , XINGDE ROAD New TAIPEI CITY 241 TW 追記 [ 2018/5/6 追記 : 某大学授業のネットワークを専門とする講師にこの件について訪ねたところ, Linux におけるプロトコルスタックの実装に関して詳しい言及が頂けたため, それについてと, 新たにそこから考えられる知見等をここに追記する. 情報を提供/ご教示して下さいました先生に, この場を借りて改めて感謝いたします. 上記内容のネットワーク盗聴を検出する原理の中で, 取り込んだ先に待っているのはソフトウェアによるフィルタであるが, これが甘い場合, それをブロードキャストアドレスとして認識し, ARP 応答を返す と述べているが, これは厳密に, Linux カーネル v4.13 においては, マルチキャスト MAC アドレスと誤認し ARP 応答を返す. また, その処理として 6 byte 全てをチェックしていないというわけではない . そもそもブロードキャストアドレスはマルチキャストアドレスの特殊形であるから, Linux の実装においても, それがまず広義のマルチキャストアドレスであるかどうかを判定する 4 . このとき宛先 MAC アドレス FF : FF : FF : FF : FF : FE は広義のマルチキャストアドレスとして認識し, 次にそれがブロードキャストアドレスであるかどうか 6 byte 全てをみて判定する 5 . 結果的に, これをブロードキャストアドレスではないと判定し, 狭議のマルチキャストアドレスとして扱う . なお, Linux では以下のように ARP そのものを無効化することができる. 同様の設定であるマシンに対しては, 本エントリの方法で検出することはできない. $ sudo ip link set dev <interface name> arp off また, ここまで述べてきたプロトコルスタックによる宛先 MAC アドレスのフィルタリング処理は, ネットワークインタフェース層で規定されるものである から, Linux におけるプロトコルスタックの実装は, その実装定義の一種であるというように捉えることが最も妥当である. RFC 826 では, 同理由によりプロミスキャスモードによって発生しうるあらゆる振る舞いに関して定義しない 6 . — 追記ここまで ] 参照 ARPを利用してプロミスキャスモードの盗聴ホストを特定してみた ＠network Cisco・アライド実機で学ぶ ◆ARPとは Address Resolution Protocol - Wikipedia Linux kernel v4.13 (実験環境と同じ)の場合 ↩ つまり盗聴ノードの IP アドレスを指定する. 実際の状況では IP アドレスも当然わかっていないので, 一定範囲内の IP アドレスに関連する ARP 要求を総当たりで送ることになるだろう. ↩ ↩ -vvv が非常に便利だ. ↩ net/ethernet/eth.c:168 , include/linux/etherdevice.h:112~144 がこれに該当する. これを見ると, MACアドレスの先頭 1 オクテットのユニキャスト/マルチキャストフラグをチェックしていることがわかる. ↩ include/linux/etherdevice.h:309~361 ↩ というより, プロトコルスイート各種の規定は, その各レイヤーごとの規定を定めるものであって, 各レイヤーごとがどのように連携するかについて規定することが本質ではない. ↩","loc":"posts/2018/ 5月/01/detectPromiscuous/","tags":"C++","url":"posts/2018/ 5月/01/detectPromiscuous/","title":"ARPパケットに対する挙動からネットワーク上の盗聴者を特定する"},{"text":"典型的なパラメトリック曲線の一種である, ベジェ曲線(Bézier curve)についての学習メモ. パラメトリック曲線とその一種であるエルミート曲線に関しては, 前回の記事 を参照. ベジェ曲線は, パラメータ \\(t\\ (0 \\leq t \\leq 1)\\) と複数の制御点 \\(P_i\\) から構成されるパラメトリック曲線の一種である 1 . 始点と終点の線分から成る, 次数 \\(n\\) のベジェ曲線は \\(n+1\\) の制御点をもち( \\(= P_0, P_1, \\cdots, P_n\\) の制御点があるベジェ曲線を \\(n-1\\) 次ベジェ曲線という), この内分点を繰り返し取ることによって, 曲線を得ることができる. この始点と終点の線分を, セグメントといい, これが得られる曲線そのものになる 2 . まず, ここでは 2 次ベジェ曲線を描くとして, そのイメージをつけるために, 図 3 を用いてその概要を見る. なお, 2 次ベジェ曲線は true type フォントなどで使われている. 図で示されている各変数について取り上げる. 上図 \\(P_0, P_1, P_2\\) は平面 \\(\\mathbb{R}&#94;2\\) 上に取った 3 点である. \\(t\\) は \\(0 \\leq t \\leq 1, t \\in \\mathbb{R}\\) であり, \\(P_0\\) から \\(P_1\\) , また \\(P_1\\) から \\(P_2\\) の間で \\(0\\) から \\(1\\) に増加する. このとき, \\(t\\) に対して変化する \\(P_0\\) と \\(P_1\\) の線分上の一点を \\(Q_0\\) , \\(P_1\\) と \\(P_2\\) の線分上の一点を \\(Q_1\\) とする. 上図では, \\(t=0.25\\) であるから \\(Q_0\\) は \\(P_0\\) と \\(P_1\\) の線分上の \\(\\displaystyle\\dfrac{1}{4}\\) の地点にあることがいえる. このとき \\(Q_1\\) は, \\(P_2\\) から見て \\(P_1\\) と \\(P_2\\) の線分上の \\(\\displaystyle\\dfrac{3}{4}\\) の地点にあることがいえる. これは, \\(Q_0 : Q_1 = t : 1 - t\\) という対比で表すことができる(つまり, \\(Q_0 = (1-t)P_0 + tP_1, Q_1 = (1-t)P_1 + tP_2\\) ). そして, \\(Q_0\\) と \\(Q_1\\) の線分上を \\(t : 1-t\\) の比率となる 1 点をとり, これを \\(B\\) とする(つまり, \\(B=(1-t)Q_0+tQ_1\\) ). これが, 2 次ベジェ曲線の 1 点となるのである. \\(t\\) の増加によって, \\(t : 1-t\\) の比率が変化していくから, それを繰り返し取ることで放物線(曲線)が得られるのである. 4 \\(Q_0, Q_1\\) を \\(B\\) に代入すると, \\(B\\) は, \\(2\\) 次ベジェ曲線 \\[B = \\left(1-t\\right)&#94;2 P_0 + 2t(1-t)P_1+t&#94;2 P_2\\] という 2 次式となる. \\(P_0, P_1, P_2\\) の各係数に着目すると, 結果的に 2 次バーンスタイン基底関数が得られたことがわかる 5 . 以下に, 2 次ベジェ曲線を描画していく様子を示す 6 . 「動かす」をクリックすると, 二次ベジェ曲線を描くアニメーションが描画される. 各制御点をドラッグして操作できる. やめるをクリックすると, 描画を隠す. この放物線の構成法を一般化したものが, ド・カステリョのアルゴリズムである. ド・カステリョのアルゴリズム 平面 \\(\\mathbb{R}&#94;2\\) の \\(n+1\\) 個の点 \\(P_0, P_1, \\cdots, P_n\\) と実数 \\(t\\in\\mathbb{R}\\) に対し \\(\\displaystyle P&#94;0_i(t) = P_i\\) としたとき,\\[ P&#94;r_i(t) = (1-t)P&#94;{r-1}\\_i(t)+ tP&#94;{r-1}_{i+1}(t), (r=1, \\cdots, n; i = 0, 1, \\cdots, n - r) \\] ここで, 特にこれを再度書く意味は全くないが, 前回の記事 では曲線描画に関して Haskell で書いたので, こちらもなんとなく載せて置く. -- | A function that generates a coordinate list of quadratic Bezier curves according to -- -- the three control points, them density and the range of @t@ (@bt <= t <= et@). quadraticBezier :: ( Float' , Float' ) -> ( Float' , Float' ) -> ( Float' , Float' ) -> Float' -> Int -> Int -> [( Float , Float )] quadraticBezier p0 p1 p2 = (( map ( bx &&& by ) . ) . ) . linspaceWithDensity where b20 t = ( 1 - t ) &#94; 2 b21 t = 2 * ( 1 - t ) * t b22 t = t &#94; 2 bezier t v1 v2 v3 = b20 t * v1 + b21 t * v2 + b22 t * v3 bx t = bezier t ( fst p0 ) ( fst p1 ) ( fst p2 ) by t = bezier t ( snd p0 ) ( snd p1 ) ( snd p2 ) quadraticBezier (-1.0, -1.66) (1.10, -1.88) (0.04, 0.86) 0.001 0 1 とし, 前回の記事 のように GLUT を使って出力すると, 次のような曲線が得られる. また, 3 次ベジェ曲線は, 冒頭で述べた通り, 次数 \\(n\\) に対して \\(+1\\) した制御点を持つので, \\(4\\) つの制御点を持つ 3 . 考え方は 2 次ベジェ曲線のときと同様で, 最終的に 3 次ベジェ曲線における \\(B\\) は \\(3\\) 次ベジェ曲線 \\[B = \\left(1-t\\right)&#94;3 P_0 + 3\\left(1-t\\right)&#94;2 P_1 + 3\\left(1-t\\right)t&#94;2 P_2 + t&#94;3 P_3 \\] という 3 次式になる. なお, 3 次ベジェ曲線は, アドビ社のポストスクリプトフォントや画像編集ソフトなどで使用されている. -- | A function that generates a coordinate list of cubic bezier curves according to -- -- the four control points, them density and the range of @t@ (@bt <= t <= et@). cubicBezier :: ( Float' , Float' ) -> ( Float' , Float' ) -> ( Float' , Float' ) -> ( Float' , Float' ) -> Float' -> Int -> Int -> [( Float' , Float' )] cubicBezier p0 p1 p2 p3 = (( map ( bx &&& by ) . ) . ) . linspaceWithDensity where b30 t = ( 1 - t ) &#94; 3 b31 t = 3 * ( 1 - t ) &#94; 2 * t b32 t = 3 * ( 1 - t ) * t &#94; 2 b33 t = t &#94; 3 bezier t v1 v2 v3 v4 = b30 t * v1 + b31 t * v2 + b32 t * v3 + b33 t * v4 bx t = bezier t ( fst p0 ) ( fst p1 ) ( fst p2 ) ( fst p3 ) by t = bezier t ( snd p0 ) ( snd p1 ) ( snd p2 ) ( snd p3 ) 同様に cubicBezier (1, 0) (1, 1) (-1, 1) (-1, 0) 0.001 0 1 とすると, 次のような曲線が得られる. ベジェ曲線はフランスの自動車メーカーシトロエン社のド・カステリョ (de Casteljau) とルノー社のベジェ (Bézier) によって独立に考案されたものの, 企業秘密として 1960 年代の後半になるまで公表されなかった. ド・カステリョによる研究はベジェよりも先んじていたが, その論文が公知とならなかったために, これらの理論にはベジェの名前がついているとのこと. 参照: 鳥谷 浩志; 千代倉 弘明 (1991). 3次元CADの基礎と応用. 共立出版. ISBN 9784320025394. ↩ 用語に関する参照: 曲線・図形の書き方(ベジェ曲線) ↩ 図は Wikipedia Commmons (パブリックドメイン) から. ↩ ↩ 参考: ド・カステリョのアルゴリズム. ↩ 2 次バーンスタイン基底関数によるベジェ曲線は, 一様 2 次 B スプライン曲線と全く同じ. ここでいう「一様」とは, パラメータ \\(t(\\{t_0, t_1, t_2, \\cdots\\})\\) を等間隔にとることをいう. ↩ このアニメーションは, d3.js を使って 実装した . ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2018/ 4月/20/Bezier-curve/","tags":"math","url":"posts/2018/ 4月/20/Bezier-curve/","title":"ベジェ曲線"},{"text":"典型的なパラメトリック曲線の一種である, エルミート曲線についてのメモ. パラメトリック曲線 そもそもパラメトリック曲線とは, 任意のパラメータから各々の座標を陽関数形式で表現できる曲線のことをいう. このとき定義できる関数 \\(f\\) がパラメータ \\(t\\) 1 の多項式である場合, それを多項式曲線といい, 有理式である場合, それを有理曲線という. 例えば, 直線の方程式 \\(y = m(x-a)+b\\) は, \\begin{cases} x=t \\\\ y=m(t-a)+b \\end{cases} とパラメタライズできる. この方程式では, パラメタライズせずとも, \\(x\\) に 1 つの実数を代入すれば, 必ず \\(y\\) が求まる(逆も言える)ことは明らかである. 次に, 3 次曲線 \\(y&#94;{2} = x&#94;{3} + x&#94;{2} \\) について考える. \\(x\\) に 1 つの実数を代入すると, \\(y\\) は, \\(x&#94;{3} + x&#94;{2} \\gt 0\\) のとき \\(\\pm{\\sqrt{x&#94;{3} + x&#94;{2}}}\\), \\(x&#94;{3} + x&#94;{2} = 0\\) のとき \\(0\\), \\(x&#94;{3} + x&#94;{2} \\lt 0\\) のとき複素数 となり, \\(x\\) の値によっては, グラフが存在しない. これを \\begin{cases} x=t&#94;{2}-1 \\\\ y=t&#94;{3}-t \\end{cases} とパラメタライズすることで, 任意の実数 \\(t\\) に対するグラフ上の一点を定めることができる 2 . エルミート曲線 エルミート曲線は, 始点\\((x_{0}, y_{0})\\)とその速度ベクトル\\((v_{0}, w_{0})\\), 終点\\((x_{1}, y_{1})\\)とその速度ベクトル\\((v_{1}, w_{1})\\) を与えたときに, 始点と終点の間をつなぐ 3 次パラメトリック曲線である. 3 次パラメトリック曲線と言うからには, これを一般の 3 次多項式で表現できるはずである.\\[ f(t) = At&#94;{3} + Bt&#94;{2} + Ct + D \\] パラメトリック曲線は \\(x\\) と \\(y\\) をそれぞれ別々に扱えるので, まず \\(x\\) について考える. \\[x(t) = At&#94;{3} + Bt&#94;{2} + Ct + D \\tag{1}\\] 4 つの係数, \\(A, B, C, D\\) が得られれば, 任意の \\(t\\) に対するエルミート曲線の \\(x\\) が得られるはずである. まず, 始点の座標を求める. \\(t = 0\\) のときを始点, \\(t = 1\\) のときを終点としたとき, \\(t = 0\\) のときに始点の座標, \\(t = 1\\) のときに終点の座標が得られることは明らかなので, \\(t\\) に \\(0\\), および \\(t\\) に \\(1\\) を代入して次の二式が得られる.\\[x(0) = D = x_{0} \\tag{2}\\] \\[x(1) = A + B + C + D = x_{1} \\tag{3}\\] ここで, ある地点 \\(t\\) での曲線の傾きを求めるために, 一階微分した次の式を得る. \\[\\displaystyle \\dfrac{d}{dt}x(t)=3At&#94;{2} + 2Bt + C \\tag{4}\\] 始点(\\(0\\))と終点(\\(1\\))をそれぞれ式 \\((4)\\) の \\(t\\) に代入し, 始点における曲線の傾きと, 終点における曲線の傾きが得られる. \\[\\displaystyle \\dfrac{dx}{dt}(0) = C = v_{0} \\tag{5}\\] \\[\\displaystyle \\dfrac{dx}{dt}(1) = 3A + 2B + C = v_{1} \\tag{6}\\] 式 \\((3)\\) に式 \\((2)\\), \\((5)\\) を, 式 \\((6)\\) に式 \\((5)\\) を代入すると, 次の二式が得られる. \\[A+B+v_{0}+x_{0} = x_{1} \\tag{7}\\] \\[3A + 2B + v_{0} = v_{1} \\tag{8}\\] 式 \\((7)\\), \\((8)\\) の連立方程式を解くと, \\[A = 2x_{0} - 2x_{1} + v_{0} + v_{1} \\tag{9} \\] \\[B = -3x_{0}+3x_{1} - 2v_{0} - v_{1} \\tag{10} \\] となる. 式 \\((2), (5), (9), (10)\\) を式 \\((1)\\) に代入すると\\[ x(t) = (2x_{0} - 2x_{1} + v_{0} + v_{1})t&#94;{3} + (-3x_{0} + 3x_{1} - 2v_{0} - v_{1})t&#94;{2} + v_{0}t + x_{0} \\tag{11} \\] であるから, 式 \\((11)\\) から \\(t\\) に対するエルミート曲線の \\(x\\) が取れることがわかった. \\(y\\) についても, \\(x\\) を \\(y\\) に, \\(v\\) を \\(w\\) にすると, 同様にして得られるから \\begin{align} \\begin{cases} x(t) &= (2x_{0} - 2x_{1} + v_{0} + v_{1})t&#94;{3} + (-3x_{0} + 3x_{1} - 2v_{0} - v_{1})t&#94;{2} + v_{0}t + x_{0} \\\\ y(t) &= (2y_{0} - 2y_{1} + w_{0} + w_{1})t&#94;{3} + (-3y_{0} + 3y_{1} - 2w_{0} - w_{1})t&#94;{2} + w_{0}t + y_{0} \\end{cases} \\end{align} がいえる. さらに, \\(x(t)\\) から \\(x_{0}, x_{1}, v_{0}, v_{1}\\)(\\(y_{0}, y_{1}, w_{0}, w_{1}\\) についても同様) の係数にそれぞれ着目して, 次のように定義する. \\(x_{0}\\) の係数に着目し, \\(2t&#94;3-3t&#94;2+1=(2t+1)(1-t)&#94;2 \\), これを \\(H&#94;3_{0}(t)\\) とする \\(v_{0}\\) の係数に着目し, \\(t&#94;3-2t&#94;2+t=t(1-t)&#94;2\\), これを \\(H&#94;3_{1}(t)\\) とする \\(v_{1}\\) の係数に着目し, \\(t&#94;3-t&#94;2=-t&#94;2(1-t)\\), これを \\(H&#94;3_{2}(t)\\) とする \\(x_{1}\\) の係数に着目し, \\(3t&#94;2-2t&#94;3=t&#94;2(3-2t)\\), これを \\(H&#94;3_{3}(t)\\) とする すると, 先ほど導出した\\(x(t), y(t)\\) の式は次のように定義できる. エルミート曲線 \\begin{align} \\begin{cases} x(t) &= x_{0}H&#94;3_{0}(t) + v_{0}H&#94;3_{1} + v_{1}H&#94;3_{2}(t) + x_{1}H&#94;3_{3}(t) \\\\ y(t) &= y_{0}H&#94;3_{0}(t) + w_{0}H&#94;3_{1} + w_{1}H&#94;3_{2}(t) + y_{1}H&#94;3_{3}(t) \\end{cases} \\end{align} これは, 3 次エルミート多項式によるエルミート曲線の定義と同義である. 実際に描く 始点 \\((1, 0)\\) での速度ベクトルを \\((0, 1)\\), 終点 \\((-1, 0)\\) での速度ベクトルを \\((0, -1)\\) として, 上記に導いたエルミート曲線に従い, 点を打ってみた 3 . {-# OPTIONS_GHC -Wall #-} module Main where import Graphics.Rendering.OpenGL import Graphics.UI.GLUT import Control.Monad ( forM_ ) import Control.Arrow (( &&& )) type Float' = GLfloat linspaceWithDensity :: Float' -> Int -> Int -> [ Float' ] linspaceWithDensity density bt et = let distance = round ( realToFrac ( abs et + abs bt ) / density ) in take distance $ iterate ( + density ) ( realToFrac bt :: Float' ) -- | The function that generates a coordinate list of Hermite curve according to -- -- the start point, the velocity vector of the start point, the end point, the velocity vector of the end point, -- the density of the points and the range of @t@ (@bt <= t <= et@). hermite :: ( Float' , Float' ) -> ( Float' , Float' ) -> ( Float' , Float' ) -> ( Float' , Float' ) -> Float' -> Int -> Int -> [( Float' , Float' )] hermite st stVec ed edVec = (( map ( herX &&& herY ) . ) . ) . linspaceWithDensity where h30 t = ( 2 * t + 1 ) * ( 1 - t ) &#94; 2 h31 t = t * ( 1 - t ) &#94; 2 h32 t = - t &#94; 2 * ( 1 - t ) h33 t = t &#94; 2 * ( 3 - 2 * t ) hermite' t v1 v2 v3 v4 = h30 t * v1 + h31 t * v2 + h32 t * v3 + h33 t * v4 herX t = hermite' t ( fst st ) ( fst stVec ) ( fst edVec ) ( fst ed ) herY t = hermite' t ( snd st ) ( snd stVec ) ( snd edVec ) ( snd ed ) resize :: Size -> IO () resize s @ ( Size w h ) = do viewport $= ( Position 0 0 , s ) loadIdentity ortho ( - w' ) w' ( - h' ) h' ( - 1.0 ) 1.0 where w' = realToFrac w / 200.0 h' = realToFrac h / 200.0 disp :: IO () disp = do clear [ ColorBuffer ] color ( Color3 0 0 0 :: Color3 GLdouble ) pointSize $= 1.0 renderPrimitive Points $ forM_ hcurve ( vertex . ( uncurry Vertex2 )) flush where hcurve = hermite ( 1 , 0 ) ( 0 , 1 ) ( - 1 , 0 ) ( 0 , - 1 ) 0.001 ( - 2 ) 2 main :: IO () main = do ( progname , _ ) <- getArgsAndInitialize initialDisplayMode $= [ RGBAMode ] _ <- createWindow progname clearColor $= Color4 1 1 1 1 windowTitle $= \"Hermite curve\" displayCallback $= disp reshapeCallback $= Just resize mainLoop 次のような曲線を得た. \\(t\\) は time からくる. ↩ グラフ描画の ソースコード . ↩ 浮動小数点数の絶対誤差が気になる演算だが, そのような観点において上記コードでは手抜きをした. ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2018/ 4月/15/hermite-curve/","tags":"math","url":"posts/2018/ 4月/15/hermite-curve/","title":"エルミート曲線"},{"text":"reddit で見かけて, ふと気になったのでメモ. GCC で C/C++ コードの switch 文および case 節をコンパイルするとき, case 節の数が一定以上を超えると, ジャンプテーブルを利用したアセンブリが吐き出される 1 . 同様にして, ghc はパターンマッチで ジャンプテーブルが用いられる場合がある . 以下, メーリングリスト 2 から, パターンマッチの時間計算量に関する言及について一部引用. (snip) To answer you question, O(1) for simple patterns, but it really depends on the complexity of the pattern-matching expression and the Core-to-Core transformations that GHC applies. To truly understand the complexity, you need take a look at the Core/ STG dump (I prefer STG since it's simple). If you have any particular code samples you'd like me to help you analyze, I'd be happy to do so. A basic example: data Color = Red | Blue | Green isRed Red = True isRed _ = False GHC will transform this to isRed x = case x of { Red -True; DEFAULT -False } You can think of a case as a switch expression in your standard imperative languages. A case expression will evaluate the thunk ‘x' and perform a switch on the tag of the result. Each data constructor has an integer tag associated with it which will be the target of the switch. So the time complexity of `isRed` will be the time complexity of thunk evaluation which is impossible to predict because a thunk can be incredibly complex. Lazy evaluation is not so easy to analyze. It is highly context-sensitive. (snip) The way you're measuring algorithmic complexity does carry over to the lazy setting provided it's single-threaded because the order of execution is purely determined by the STG Code. In the concurrent lazy setting, it's a bit trickier since lightweight locking mechanisms occur when multiple threads evaluate the same thunk, making it non-deterministic. 関連URL: GHCのこと A Term Pattern-Match Compiler Inspired by Finite Automata Theory OLD DESIGN DOCUMENT : The semi-tagging optimisation Implementing Lazy Functional Languages on Stock Hardware: The Spineless Tagless G-machine Compiling pattern matching (有料) godbolt , gcc-mirror , gcc-mirror , ↩ time complexity of pattern matching - mail.Haskell , time complexity of pattern matching - mail.Haskell ↩","loc":"posts/2018/ 4月/07/hs_pattern_match_complexity/","tags":"Haskell","url":"posts/2018/ 4月/07/hs_pattern_match_complexity/","title":"ghc パターンマッチの時間計算量"},{"text":"[ 2018/4/16 追記 : 本エントリは, 元々 P0355R5 を参考にまとめを行った記事であるが, その後 P0355R7 で sun といった曜日を表すリテラルが全て Sunday , may といった月を表すリテラルが全て May といった形式に変更され, またこれらと std::chrono::last_spec 型の last 12 が std::literals::chrono_literals 名前空間下から std::chrono 名前空間下に移動された. system_clock::to_time_t と system_clock::from_time_t を Deprecated としていたが, Deprecated でなくなった. といった他に, 細かい文面の改修や, constexpr がつけられるなどの変更が加えられたため, 本エントリにおいても, それに従い該当箇所を改変している(差分を示すことも考えたが, ただ見難くなるように感じたため, そのようなことはしなかった). これらの変更には対応したつもりだが, 細かい厳密な記述に関しては, やはり P0355 の最新リビジョンを追って確かめてほしい(そして, 間違った箇所があれば指摘くださると嬉しい). — 追記ここまで ] 要旨 先週, 米国フロリダ州ジャクソンビルで ISO C++ 委員会によって, C++技術仕様( TS , 実験的機能ブランチ) と次の国際標準( IS ) C++20 に関する作業が行われた. 同会議で Reddit で紹介されているように , C++20 にいくつかの機能が追加された. そのうちの 1 つである, Calender and timezone library に関する新機能, 概要のメモ. 全機能の網羅性を主軸としたエントリではない(が, 独断と偏見により重要に感じた内容は結果的に網羅してしまっている部分もある)ため注意 以下, 特に断らない限り, 全てのコード片において using namespace std::chrono; , using namespace std::chrono_literals; がされているとする. 以下, 特に断らない限り, 各コードブロック以外で言及される 内容 といった記述については, 名前空間 std::chrono を省略する. 設計 以下の内容が追加される. <chrono> に対するカレンダーおよびタイムゾーンライブラリをサポートするための最小限の拡張 Proleptic Gregorian calendar(civil calendar) IANA Time Zone Database を基にしたタイムゾーンライブラリ 分数秒, タイムゾーンの略語, UTC オフセットの完全サポートおよび strftime のようなフォーマッティング機能 IANA Time Zone Database でサポートされている, 閏秒を計算するための複数のクロック カレンダー 本ライブラリ機能によって, 例えば 2016 年を次のように表現することができる. auto y = std :: chrono :: year { 2016 }; auto y = 2016 y ; このとき, year は partial-calendar-type (部分カレンダー型) である. 他の部分カレンダー型と組み合わせることで, year_month_day などの full-calendar-type (フルカレンダー型) を生成することができる. フルカレンダー型は, 1 日の制度を持つタイムポイントであり, 部分カレンダー型である year , month , day で構成される. これらから year_month_day が構築されると, 内部で計算は一切起きず, 唯一起きることは, year_month_day が内部でそれらを格納するということだけである. std :: chrono :: year_month_day ymd1 { 2016 y , month { 5 }, day { 29 }}; この場合, すべての入力がコンパイル時定数であるので, constexpr にすることができる. さらに, operator/ がオーバーロードされているため, 従来の日付の構文が利用できる. constexpr std :: chrono :: year_month_day ymd1 { 2016 y , month { 5 }, day { 29 }}; constexpr auto ymd2 = 2016 y / May / 29 d ; constexpr auto ymd3 = May / 29 d / 2016 y ; constexpr auto ymd4 = 29 d / May / 2016 y ; static_assert ( ymd1 == ymd2 ); static_assert ( ymd2 == ymd3 ); static_assert ( ymd3 == ymd4 ); static_assert ( ymd1 . year () == 2016 y ); static_assert ( ymd1 . month () == May ); static_assert ( ymd1 . day () == 29 d ); ここで, May は月を表現する month 型のオブジェクトであり, 他に Jan , Feb , Mar , Apr , Jun , Jul , Aug , Sep , Oct , Nov , Dec が, 次のように定義される(クリックで展開). namespace std :: chrono { inline constexpr chrono :: month January { 1 }; inline constexpr chrono :: month February { 2 }; inline constexpr chrono :: month March { 3 }; inline constexpr chrono :: month April { 4 }; inline constexpr chrono :: month May { 5 }; inline constexpr chrono :: month June { 6 }; inline constexpr chrono :: month July { 7 }; inline constexpr chrono :: month August { 8 }; inline constexpr chrono :: month September { 9 }; inline constexpr chrono :: month October { 10 }; inline constexpr chrono :: month November { 11 }; inline constexpr chrono :: month December { 12 }; } カレンダーライブラリは, 例えばスカラ型で直接日付を指定するといったことはなく, 明示的な型指定による表現によって実現する. なお, 部分カレンダー型( year , month に加えて day 型)は, すべて Strong ordering 1 を満たし, 加えて以下のメンバ関数をもつ. デフォルトコンストラクタ, unsigned 型( year 型のみ int 型)の値を受け付けるコンストラクタ 各型の単位においてそれを前後に進める, {前|後}置{イン|デ}クリメント演算子 各型の単位で計算を行う + , - の二項演算子 二項演算子と同様の計算を行い自身に代入する += , -= の複合代入演算子 unsigned 型( year 型のみ int 型)の値への明示的な変換( constexpr explicit operator unsigned() const noexcept; ) 指定された日付が各単位で適切であるかどうかをチェックする ok year 型は, これに加えて, is_leap , min , max メンバ関数をもつ. is_leap は, 指定された年が閏年であるか判定できる. min , max は内部型の最小値と最大値を返す. また, 上記の通り y といったリテラル接尾語が定義される. また day 型は, d といったリテラル接尾語が定義される. フルカレンダー型は, sys_days という型へ変換できる. これは, 次のように定義されている. constexpr year_month_day :: operator sys_days () const noexcept ; フルカレンダー型は, sys_days 型に変換することで, system_clock::time_point ファミリとの間で変換でき, これにより完全な相互運用が可能である. sys_days は 次のように定義される(クリックで展開). using days = duration < int32_t , ratio_multiply < ratio < 24 > , hours :: period >> ; template < class Duration > using sys_time = time_point < system_clock , Duration > ; using sys_days = sys_time < days > ; 加えて, sys_days には次の特性がある. sys_days は, system_clock::time_point がマイクロ秒, またはナノ秒のカウントだけであるのと同様に, system_clock の基点(エポック)からの日数を示す. sys_days は, 切り捨てエラーなしで暗黙的に system_clock::time_point に変換される. system_clock::time_point は, 切り捨てエラーが含まれるため, 暗黙的に sys_days に変換されない. system_clock::time_point_cast または floor を使用した明示的な変換によって system_clock::time_point から sys_days へ変換することができる. 内部で保持する部分カレンダー型 year , month , day をそれぞれ y_ , m_ , d_ としたとき, year_month_day から sys_days への変換時には(すなわち上記の operator sys_days() の呼び出し), year_month_day::ok() が true の場合, sys_days の基点から *this までの日数を保持する sys_days を返す そうでない場合, y_.ok() && m_.ok() == true ならば sys_days{y_/m_/last} から days ( duration<int32_t, ratio_multiply<ratio<24>, hours::period>> ) の数だけ sys_days{y_,m_,last}.day() からオフセットされた sys_days を返す そうでない場合, 未規定である ここで year_month_day::ok は, y_.ok() && m_.ok() == true \\(\\land\\) 1d \\(\\leq\\) d_ \\(\\leq\\) (y_/m_/last).day() であるとき true を, そうでない場合, false を返すメンバ関数である. constexpr std :: chrono :: system_clock :: time_point tp = std :: chrono :: sys_days { 2016 y / May / 29 d }; // Convert date to time_point static_assert ( tp . time_since_epoch () == 1 ' 464 ' 480 ' 000 ' 000 ' 000u s ); constexpr auto ymd = std :: chrono :: year_month_day { std :: chrono :: floor < days > ( tp )}; // Convert time_point to date static_assert ( ymd == 2016 y / May / 29 d ); constexpr auto tp = std :: chrono :: sys_days { 2016 y / May / 29 d } + 7 h + 30 min ; // 2016-05-29 07:30 UTC static_assert ( year_month_day { sys_days { 2017 y / January / 0 }} == 2016 y / December / 31 ); static_assert ( year_month_day { sys_days { 2017 y / January / 31 }} == 2017 y / January / 31 ); static_assert ( year_month_day { sys_days { 2017 y / January / 32 }} == 2017 y / February / 1 ); 上述した, days の他に, weeks , months , years が 次のように定義される(クリックで展開). using weeks = duration < /* signed integer type of at least 22 bits */ , ratio_multiply < ratio < 7 > , days :: period >> ; using years = duration < /* signed integer type of at least 17 bits */ , ratio_multiply < ratio < 146097 , 400 > , days :: period >> ; using months = duration < /* signed integer type of at least 20 bits */ , ratio_divide < years :: period , ratio < 12 >>> ; days , weeks , months , years 型は, それぞれ少なくとも \\(\\pm\\) 40000 年の範囲をカバーする. hours のリテラル接尾語が h , minutes のリテラル接尾語が min , というように, 今までのリテラル接尾語は duration 型へ対応していたが, 新規に追加される y , d といったリテラル接尾語は, years , days に対応するリテラル接尾語ではなく, 上述したように, year , day の部分カレンダー型に対応するリテラル接尾語である. 1 年を, 365.2425 日(グレゴリオ暦の平均長)と定義し, 1 月を, 30.436875 日 \\(\\left(\\dfrac{1}{12}\\right)\\) と定義するため, システム時刻( time_point )を利用した算出結果と, year_month_day を利用した算出結果は異なる. constexpr auto date1 = sys_days { 1997 y / May / 30 d } - months { 5 }; // 1996-12-28 19:34:30 constexpr auto date2 = sys_days { 1997 y / December / 29 d } - years { 1 }; // 1996-12-28 18:10:48 現実のカレンダーの利用方法として, たとえば「2016 年の 5 月 29 日」を, 「2016 年の 5 月第 5 日曜日」ということもよくあり, これを表現することもできる. constexpr std :: chrono :: system_clock :: time_point tp = std :: chrono :: sys_days { Sunday [ 5 ] / May / 2016 }; // Convert date to time_point static_assert ( tp . time_since_epoch () == 1 ' 464 ' 480 ' 000 ' 000 ' 000u s ); constexpr auto ymd = std :: chrono :: year_month_weekday { std :: chrono :: floor < days > ( tp )}; // Convert time_point to date static_assert ( ymd == Sunday [ 5 ] / std :: chrono :: May / 2016 ); static_assert ( 2016 y / May / 29 d == std :: chrono :: year_month_day { Sunday [ 5 ] / May / 2016 }); constexpr auto wdi = Sunday [ 5 ]; // wdi is the 5th Sunday of an as yet unspecified month static_assert ( wdi . weekday () == Sunday ); static_assert ( wdi . index () == 5 ); static_assert ( std :: is_same < decltype ( Sunday ), std :: chrono :: weekday >:: value ); static_assert ( std :: is_same < decltype ( wdi . index ()), std :: chrono :: weekday_indexed >:: value ); ここで, Sunday は weekday 型であり, 日曜日を表現するリテラルとして定義され, 他にも Monday , Tuesday , Wednesday , Thursday , Friday , Saturday が 次のように定義される(クリックで展開). namespace std :: chrono { inline constexpr chrono :: weekday Sunday { 0 }; inline constexpr chrono :: weekday Monday { 1 }; inline constexpr chrono :: weekday Tuesday { 2 }; inline constexpr chrono :: weekday Wednesday { 3 }; inline constexpr chrono :: weekday Thursday { 4 }; inline constexpr chrono :: weekday Friday { 5 }; inline constexpr chrono :: weekday Saturday { 6 }; } weekday 型は, Strong equality 1 を満たし, 加えて, 次のメンバ関数を持つ. デフォルトコンストラクタ, unsigned , sys_days , 後に取り上げている local_days 型のオブジェクトを受け付けるコンストラクタ 曜日を前後に進める{前|後}置{イン|デ}クリメント演算子 weekday , days 型のオブジェクトを受け付けて曜日の計算を行う + , - の二項演算子 二項演算子と同様の計算を行い自身に代入する += , -= の複合代入演算子 指定された曜日が適切であるかどうかをチェックする ok operator [] operator [] は, unsigned 型を引数として呼び出すと, weekday_indexed 型のオブジェクトが返され, last_spec 型のオブジェクトを引数として呼び出すと, weekday_last 型のオブジェクトが返される. weekday_indexed 型は, 月の第 1, 第 2, 第 3, 第 4 または第 5 曜日を表すために使用され, 上記の通り, weekday メンバ関数, index メンバ関数を持つ他, ok メンバ関数を持つ. weekday_last 型は, 月の最後の weekday を表すために使用され, weekday メンバ関数, ok メンバ関数を持つ, last_spec 型は, 最終日を表すために使用され, 同型のオブジェクト last が chrono 名前空間下に定義される. 例えば次のようにして, ある月の最終日, 最終 \\(X\\) 曜日などを表現することができる. auto today = std :: chrono :: year_month_day { std :: chrono :: floor < std :: chrono :: days > ( std :: chrono :: system_clock :: now ())}; auto last_day = today . year () / today . month () / last ; // last day of this month auto last_Sunday = today . year () / today . month () / Sunday [ last ]; // last Sundayday of this month static_assert ( std :: is_same < decltype ( Sunday [ 5 ]), std :: chrono :: weekday_indexed >:: value ); static_assert ( std :: is_same < decltype ( Sunday [ last ]), std :: chrono :: weekday_last >:: value ); 他に, 年を未指定とし, 特定の月日を表す, month_day , 月の最終日を表す month_day_last , \\(N\\) 番目の曜日を表す month_weekday , 月の最終曜日を表す month_weekday_last と, 日を未指定とし, 特定の年月を表す, year_month , 前述した year_month_day , 特定の年月の最終日を表す year_month_day_last , 特定の年月の \\(N\\) 番目の曜日を表す year_month_weekday , 特定の年月の最終曜日を表す year_month_weekday_last が提供される. constexpr auto md = February / 1 d ; static_assert ( std :: is_same < decltype ( md ), std :: chrono :: month_day >:: value ); constexpr auto mdl = February / last ; // mdl is the last day of February of an as yet unspecified year static_assert ( mdl . month () == February ); static_assert ( std :: is_same < decltype ( mdl ), std :: chrono :: month_day_last >:: value ); constxpr auto mw = February / Sunday [ 5 ]; static_assert ( std :: is_same < decltype ( mw ), std :: chrono :: month_weekday >:: value ); constexpr auto mwl = February / Sunday [ last ]; static_assert ( std :: is_same < decltype ( mwl ), std :: chrono :: month_weekday_last >:: value ); constexpr auto ym = 2016 y / February ; static_assert ( std :: is_same < decltype ( ym ), std :: chrono :: year_month >:: value ); constexpr auto ymd = 2016 y / February / 1 d ; static_assert ( std :: is_same < decltype ( ymd ), std :: chrono :: year_month_day >:: value ); constexpr auto ymdl = 2016 y / February / last ; static_assert ( std :: is_same < decltype ( ymdl ), std :: chrono :: year_month_day_last >:: value ); constexpr auto ymw = 2016 y / February / Sunday [ 1 ]; static_assert ( std :: is_same < decltype ( ymw ), std :: chrono :: year_month_weekday >:: value ); constexpr auto ymwl = 2016 y / February / last ; static_assert ( std :: is_same < decltype ( ymwl ), std :: chrono :: year_month_day_last >:: value ); フルカレンダー型, 部分カレンダー型, sys_days 型の全てで, operator << のオーバーロードによる IO ストリームへの出力機能が提供される他, 非メンバ関数として, to_stream , from_stream が提供される. これらはそれぞれ, 指定されたフォーマットの通りに出力する機能と, 指定されたフォーマットを使用して入力ストリームから解析する機能を持つ. std :: cout << std :: chrono :: sys_days { Sunday [ 5 ] / May / 2016 } << std :: endl ; // 2016-05-29 std :: chrono :: to_stream ( std :: cout , \"%b/%d/%Y %A %T\" , std :: chrono :: sys_days { 2016 y / May / 29 d } + 30 min ); // May/29/2016 Sunday 00:30:00 auto is = std :: istringstream { \"2016-5-26\" }; auto tp = std :: chrono :: sys_days {}; std :: chrono :: from_stream ( in , \"%F\" , tp ); if ( ! is . fail ()) std :: cout << tp << std :: endl ; // 2016-05-26 また, time_of_day クラスが提供される. これは, hours , minutes , seconds , duration<Rep, Period> の 4 つに対する特殊化が行われており, それぞれ午前 0 時からの時間, 時間:分, 時間:分:秒, 時間:分:秒: \\(X\\) といった書式設定ができる. std :: chrono :: time_of_day < std :: chrono :: hours > todh ( 1 h ); todh . make12 (); std :: cout << todh << '\\n' ; // 1am todh . make24 (); std :: cout << todh << '\\n' ; // 0100 std :: chrono :: time_of_day < std :: chrono :: minutes > todm ( 1 h + 30 min ); todm . make12 (); std :: cout << todm << '\\n' ; // 1:30am todm . make24 (); std :: cout << todm << '\\n' ; // 01:30 std :: chrono :: time_of_day < std :: chrono :: seconds > tods ( 1 h + 30 min + 30 s ); tods . make12 (); std :: cout << tods << '\\n' ; // 1:30:30am tods . make24 (); std :: cout << tods << '\\n' ; // 01:30:30 std :: chdono :: time_of_day < std :: chrono :: milliseconds > todms ( 1 h + 30 min + 30 s + 30 ms ); todms . make12 (); std :: cout << todms << '\\n' ; // 1:30:30.030am todms . make24 (); std :: cout << todms << '\\n' ; // 01:30:30.030 タイムゾーン タイムゾーンライブラリは, IANA Time Zone Database のパーサーとして提供される 2 . IANA Time Zone Database には, UTC からのオフセットと地域の省略名 3 が含まれており, さらに該当する場合, 夏時間(サマータイム)のルールも含まれる. これを表現した, tzdb , またバージョンごとの tzdb のリストとなっている tzdb_list を介して, 任意の tzdb にアクセスすることができる. tzdb_list はシングルトンであり, 非メンバ関数 get_tzdb_list からその参照を得て利用する. 関連する宣言を下記に抜粋する(クリックで展開). namespace std { namespace chrono { struct local_t {}; template < class Duration > using local_time = time_point < local_t , Duration > ; using local_seconds = local_time < seconds > ; using local_days = local_time < days > ; struct sys_info { sys_seconds begin ; sys_seconds end ; seconds offset ; minutes save ; string abbrev ; }; struct local_info { enum { unique , nonexistent , ambiguous } result ; sys_info first ; sys_info second ; }; enum class choose { earliest , latest }; class time_zone { public : time_zone ( const time_zone & ) = delete ; time_zone & operator = ( const time_zone & ) = delete ; const string & name () const noexcept ; template < class Duration > sys_info get_info ( sys_time < Duration > st ) const ; template < class Duration > local_info get_info ( local_time < Duration > tp ) const ; template < class Duration > sys_time < typename common_type < Duration , seconds >:: type > to_sys ( local_time < Duration > tp ) const ; template < class Duration > sys_time < typename common_type < Duration , seconds >:: type > to_sys ( local_time < Duration > tp , choose z ) const ; template < class Duration > local_time < typename common_type < Duration , seconds >:: type > to_local ( sys_time < Duration > tp ) const ; }; struct tzdb { string version ; vector < time_zone > zones ; vector < link > links ; vector < leap > leaps ; const time_zone * locate_zone ( string_view tz_name ) const ; const time_zone * current_zone () const ; }; class tzdb_list { atomic < tzdb *> head_ { nullptr }; // exposition only public : class const_iterator ; const tzdb & front () const noexcept ; const_iterator erase_after ( const_iterator p ) noexcept ; const_iterator begin () const noexcept ; const_iterator end () const noexcept ; const_iterator cbegin () const noexcept ; const_iterator cend () const noexcept ; }; } } local_time は local_t という空の擬似クロック型が指定されており, これは当然 C++ の Clock ライブラリコンセプトを満たしていないが, 未定義のタイムゾーンに関するローカル時刻であることを示す. sys_info 構造体は, time_zone と sys_time , または local_time の組み合わせ, および zoned_time から取得することができる. 実質的には, time_zone と sys_time のペアであり, 低レベル API を表現する. sys_time から local_time への通常の変換では, 暗黙的にこの構造体が使用される. begin , end フィールドは, time_zone および time_point について offset と abbrev が \\([\\) begin , end \\()\\) であることを示す. offset フィールドは, 関連する time_zone および time_point に有効な UTC オフセットを示す( offset = local_time - sys_time ). save フィールドは, 通常 local_time と sys_time の変換では必要のない\"余分な\"情報であるが, サマータイムの対応で必要となる. save != 0min の場合, この sys_info はサマータイムの時間帯にあると判断する. offset - save によって, この time_zone がサマータイムに対応できていない可能性を導出できる. しかし, この情報は正式なものではなく, そのような情報を確実に取得する唯一の方法は, save == 0min である sys_info を返す time_point と, 確認したい time_zone を照会することである. abbrev フィールドは, 関連する time_zone および time_point に使用される現在の略語を示す. 略語は, time_zone 間で一意でないため, 略語を time_zone と UTC のオフセットに確実にマッピングすることはできない IO ストリームに対応している. zoned_time zt = { \"Asia/Tokyo\", system_clock::now() }; std::cout << zt.get_info() << '\\n'; local_info 構造体は, 低レベル API を表す. local_time から sys_time への通常の変換では, 暗黙的にこの構造体が使用される. local_time から sys_time への変換が唯一(サマータイムでない)で, result == unique である場合, first が正しい sys_info がセットされ, second が 0 で初期化される. 変換が存在しない( result == noexistent ) 6 場合, first は local_time の直前で終了する sys_info がセットされ, second は local_time の直後に開始する sys_info がセットされる. 変換が曖昧( result == ambiguous ) 6 な場合, first は local_time の直後に終了する sys_info がセットされ, second は local_time の直前で開始する sys_info がセットされる. IO ストリームに対応している. std::cout << get_tzdb().current_zone()->get_info(local_days{2016y/May/29d}) << '\\n'; time_zone 構造体は, 特定の地域の全てのタイムゾーン遷移を表現する. データベースの初期化の過程で, 現在地のタイムゾーン, およびタイムゾーンの情報をなんらかの方法 4 5 で構築する. Strong ordering 1 を満たす. name メンバ関数によって, time_zone の名前 3 を取得できる. get_info メンバ関数によって, sys_info , local_info を取得できる. to_sys メンバ関数によって, sys_time , local_time を取得できる. time_zone::to_sys(local_time<Duration> tp) const; : 少なくとも seconds と同じぐらいの sys_time であり, 引数の精度がさらに高ければそれに合わせられる. tp から sys_time への変換が曖昧 6 である場合, ambiguous_local_time 例外をスローする 7 . tp から sys_time への変換が存在しない 6 場合, nonexistent_local_time 例外をスローする 8 . time_zone::to_sys(local_time<Duration> tp, choose z) const; : 少なくとも seconds と同じぐらいの sys_time であり, 引数の精度がさらに高ければそれに合わせられる. tp から sys_time への変換が曖昧 6 があいまいである場合, z == choose::earliest の場合は, サマータイム以前の sys_time を返し, z == choose::latest の場合は, サマータイム以後の sys_time を返す. tp が 2 つの UTC time_point の間に存在しない時間を表す場合, 2 つの UTC time_point は同じになり, UTC time_point が返される. time_zone::to_local(sys_time<Duration> tp) const; : tp と自身の time_zone に関連づけられた local_time を返す. tzdb は, 前述した通り, タイムゾーンデータベースを表現する. version は, そのデータベースバージョンを表す. zones , links , leaps は, 検索の高速化のために, 構築時に昇順ソートされる. locate_zone メンバ関数から, 与えられた string_view オブジェクトと name() が等価である time_zone が見つかった場合, その time_zone へのポインタを取得できる. そうでない場合, 与えられた string_view と link.name() (ここで, link は後述している time_zone の代替名を表現するクラスである)が等価である link が見つかった場合, zone.name() == link.target() の time_zone ポインタが取得できる. そうでない場合, runtime_error 例外を送出する. 例外送出以外でこの関数から処理が返るとき, 返される戻り値は必ず有効な time_zone へのポインタである. current_zone メンバ関数から, コンピューターに設定されたローカルタイムゾーンを取得できる. tzdb_list は, tzdb のアトミックポインターをもつ, tzdb のシングルトンリストである. 複数のバージョンのデータベースを, 同リストを介して一度に使用することができる. 例: for (auto&& v : get_tzdb_list()) { std::cout << v << '\\n'; } front メンバ関数によって, 先頭 tzdb の参照を得ることができる. これは, reload_tzdb 非メンバ関数に対してスレッドセーフである. erase_after メンバ関数によって, 与えられたイテレータの後に参照する tzdb を消去する. 消去された要素の次の要素を指すイテレータが返される. そのような要素が存在しない場合, メンバ関数 end を呼び出し, その結果を返す. なお, ここで消去された tzdb を参照することを除いて, ポインター, 参照, イテレータは無効にならない. また, メンバ関数 begin を呼び出し, それによって参照される tzdb を消去することはできない. begin メンバ関数によって, コンテナ内の最初の tzdb を参照するイテレータ取得できる. cbegin メンバ関数は begin メンバ関数の const 版である. end メンバ関数によって, コンテナ内の最後の tzdb より 1 つ後ろの位置を参照するイテレータを取得できる. cend メンバ関数は end メンバ関数の const 版である. get_tzdb_list 非メンバ関数によって, 同リストの参照を得ることができる. 同メンバ関数への呼び出しがデータベースへの最初のアクセスである場合, データベースを初期化する. この呼び出しによってデータベースが初期化された場合, tzdb を一つ持つ tzdb_list が構築される. 同メンバ関数を一度に複数のスレッドから呼び出しても競合せず, スレッドセーフである. 何らかの理由で有効なリストの参照を返せず, 1 つ以上の有効な tzdb を含む場合, runtime_error 例外を送出する. get_tzdb 非メンバ関数によって, 同リストの先頭 tzdb の参照を得ることができる( get_tzdb_list().front() ). locate_zone 非メンバ関数によって, 次の値を得ることができる. なお, これがデータベースへの最初のアクセスである場合, データベースを初期化する. get_tzdb().locate_zone(tz_name); current_zone 非メンバ関数によって, 次の値を得ることができる. get_tzdb().current_zone(); ローカル タイムゾーンデータベースは、アプリケーションがデータベースに最初にアクセスするとき, たとえば current_zone() を介して実装によって提供される. アプリケーションが実行されている間, 実装はタイムゾーンデータベースの更新を選択することがある. このアップデートは, アプリケーションによって次に挙げる関数を呼び出さない限り, アプリケーションに影響を与えることはない. この潜在的に更新されたタイムゾーンデータベースは, リモート タイムゾーンデータベースと呼ぶ. 次のように定義される(クリックで展開). namespace std { namespace chrono { const tzdb & reload_tzdb (); string remote_version (); } } reload_tzdb 非メンバ関数は, 最初にリモートタイムゾーンデータベースのチェックを行い, ローカルデータベースとリモートデータベースのバージョンが同じである場合はなにもしない. それ以外の場合, リモートデータベースは, get_tzdb_list 非メンバ関数によってアクセスされる tzdb_list の先頭にプッシュされる. いずれの場合も, get_tzdb_list().front() が返される. この関数は, get_tzdb_list().front() と get_tzdb_list().erase_after() に対してスレッドセーフである. 何らかの理由で有効な tzdb の参照が戻されない場合, runtime_error 例外が送出される. remote_version 非メンバ関数は, 最新のリモートデータベースバージョンの文字列( std::string )を返す. リモートバージョンが利用できない場合, 空の文字列が返される. 空でない場合, これを get_tzdb_list().version と比較して, ローカルデータベースとリモートデータベースが同等かどうかをチェックできる. zoned_traits , zoned_time を利用することで, sys_days , local_days といった time_point を tzdb データベースと関連付けることができる. 次のように定義される(クリックで展開). namespace std { namespace chrono { template < class T > struct zoned_traits {}; template <> struct zoned_traits < const time_zone *> { static const time_zone * default_zone (); static const time_zone * locate_zone ( string_view name ); }; } } zoned_traits によって, zoned_time のデフォルトコンストラクタの動作をカスタマイズすることができる. zoned_traits<const time_zone*>::default_zone(); は, std::chrono::locate_zone(\"UTC\") を返す. zoned_traits<const time_zone*>::locate_zone(string_view name); は, std::chrono::locate_zone(name) を返す. zoned_time は, Duration の精度で, time_zone と time_point の論理区切りを表す. Strong equality 1 を満たす. 次のように定義される(クリックで展開). template < class Duration , class TimeZonePtr = const time_zone *> class zoned_time { public : using duration = common_type_t < Duration , seconds > ; private : TimeZonePtr zone_ ; // exposition only sys_time < duration > tp_ ; // exposition only public : zoned_time (); zoned_time ( const zoned_time & ) = default ; zoned_time & operator = ( const zoned_time & ) = default ; zoned_time ( const sys_time < Duration >& st ); explicit zoned_time ( TimeZonePtr z ); explicit zoned_time ( string_view name ); template < class Duration2 > zoned_time ( const zoned_time < Duration2 >& zt ) noexcept ; zoned_time ( TimeZonePtr z , const sys_time < Duration >& st ); zoned_time ( string_view name , const sys_time < Duration >& st ); zoned_time ( TimeZonePtr z , const local_time < Duration >& tp ); zoned_time ( string_view name , const local_time < Duration >& tp ); zoned_time ( TimeZonePtr z , const local_time < Duration >& tp , choose c ); zoned_time ( string_view name , const local_time < Duration >& tp , choose c ); template < class Duration2 , class TimeZonePtr2 > zoned_time ( TimeZonePtr z , const zoned_time < Duration2 , TimeZonePtr2 >& zt ); template < class Duration2 , class TimeZonePtr2 > zoned_time ( TimeZonePtr z , const zoned_time < Duration2 , TimeZonePtr2 >& zt , choose ); zoned_time ( string_view name , const zoned_time < Duration >& zt ); zoned_time ( string_view name , const zoned_time < Duration >& zt , choose ); zoned_time & operator = ( const sys_time < Duration >& st ); zoned_time & operator = ( const local_time < Duration >& ut ); operator sys_time < duration > () const ; explicit operator local_time < duration > () const ; TimeZonePtr get_time_zone () const ; local_time < duration > get_local_time () const ; sys_time < duration > get_sys_time () const ; sys_info get_info () const ; }; invariant な zoned_time<Duration> は常に有効な time_zone を参照し, 曖昧でない時間を表す. デフォルコンストラクタは, zone_ を zoned_traits::default_zone() で初期化し, tp_ をデフォルト構築して zoned_time を構築する. コピーコンストラクタは, 関連する time_zone を転送する. Duration が noexcept コピーコンストラクタである場合, zoned_time<Duration> は noexcept コピーコンストラクタである. zoned_time(const sys_time<Duration>& st) : zone_ を zoned_traits::default_zone で初期化し, tp_ を st で初期化して zoned_time を構築する. zoned_time(TimeZonePtr z) : std::move(z) で zone_ を初期化し, zoned_time を構築する. このとき, z は有効な time_zone を指していなければならない. zoned_time(string_view name) : zoned_traits::locate_zone(name) で zone_ を初期化し, tp_ をデフォルト構築して zoned_time を構築する. zoned_time(const zoned_time<Duration2, TimeZonePtr>& y) noexcept : x == y となる zoned_time , x を構築する. zoned_time(TimeZonePtr z, const sys_time<Duration>& st) : zone_ を std::move(z) で初期化し, tp_ を st で初期化して zoned_time を構築する. このとき, z は有効な time_zone を指していなければならない. zoned_time(string_view name, const sys_time<Duration>& st) : {zoned_traits<TimeZonePtr>::locate_zone(name), st} と同等の構築を行う. zoned_time(TimeZonePtr z, const local_time<Duration>& tp) : zone_ を std::move(z) で初期化し, tp_ を zone_->to_sys(t) で初期化して zoned_time を構築する. このとき, z は有効な time_zone を指していなければならない. zoned_time(string_view name, const local_time<Duration>& tp) : {zoned_traits<TimeZonePtr>::locate_zone(name), tp} と同等の構築を行う. zoned_time(TimeZonePtr z, const local_time<Duration>& tp, choose c) : zoned_ を std::moev(z) で初期化し, tp を zone_->to_sys(t, c) で初期化して zoned_time を構築する. このとき, z は有効な time_zone を指していなければならない. zoned_time(string_view name, const local_time<Duration>& tp, choose c) : {zoned_traits<TimeZonePtr>::locate_zone(name), tp, c} と同等の構築を行う. zoned_time(TimeZonePtr z, const zoned_time<Duration2, TimeZonePtr2>& y) : zone_ を std::move(z) で初期化し, tp_ を z.tp_ で初期化して zoned_time を構築する. このとき, z は有効な time_zone を指していなければならない. zoned_time(TimeZonePtr z, const zoned_time<Duration2, TimeZonePtr2>& y, choose) : {z, y} と同等の構築を行う. このとき, z は有効な time_zone を指していなければならない. choose パラメータを渡すことができるが, これによって挙動が変わることはない. zoned_time(string_view name, const zoned_time<Duration>& y) : {zoned_traits<TimeZonePtr>::locate_zone(name), y} と同等の構築を行う. zoned_time(string_view name, const zoned_time<Duration>& y, choose c) : {locate_zone(name), y, c} と同等の構築を行う. choose パラメータを渡すことができるが, これによって挙動が変わることはない. operator=(const local_time<Duration>& lt) : 代入後, get_local_time() == lt となるよう代入し *this を返す. この代入は, get_time_zone の戻り値には影響しない. operator sys_time<duration>() const : get_sys_time() を返す. operator local_time<duration>() const : get_local_time() を返す. get_time_zone メンバ関数によって, zone_ のポインタを取得できる. get_local_time メンバ関数によって, 構築時に設定されたタイムゾーンでの local_time オブジェクトを取得できる( retunr zone_->to_local(tp_); ). get_sys_time メンバ関数によって, 構築時に設定されたタイムゾーンでの sys_time オブジェクトを取得できる( return tp_; ). get_info メンバ関数によって, 構築時に設定されたタイムゾーンでの sys_info オブジェクトを取得できる( return zone_->get_info(tp_); ). 同ライブラリを利用して, 例えば次のように, ある日時の東京の時間帯を得ることができる 5 . auto tp1 = std :: chrono :: sys_days { 2016 y / May / 29 d } + 7 h + 30 min + 6 s + 153 ms ; // 2016-05-29 07:30:06.153 UTC std :: chrono :: zoned_time zt1 = { \"Asia/Tokyo\" , tp1 }; std :: cout << zt1 << '\\n' ; // 2016-05-29 16:30:06.153 JST auto tp2 = std :: chrono :: local_days { 2016 y / May / 29 d } + 7 h + 30 min + 6 s + 153 ms ; // 2016-05-29 07:30:06.153 JTC auto zt2 = std :: chrono :: zoned_time { \"Asia/Tokyo\" , tp2 }; std :: cout << zt << '\\n' ; // 2016-05-29 07:30:06.153 JST leap は, タイムゾーンデータベースの初期化時に構築され, タイムゾーンデータベースに格納されるクラスであり, 主に閏秒を扱うクラスである. 同クラスは, Strong ordering 1 を満たす. 次のように定義される(クリックで展開). class leap { sys_seconds date_ ; // exposition only public : leap ( const leap & ) = default ; leap & operator = ( const leap & ) = default ; // Undocumented constructors sys_seconds date () const ; }; date メンバ関数によって, date_ を取得できる. date_ には閏秒挿入の日付が格納されている. 閏秒挿入の全ての日付を for (auto& l : get_tzdb().leaps) std::cout << l.date() << '\\n'; で確認できる. またタイムゾーンデータベースの構築時に作成される, time_zone の代替名を表現する link というクラスも提供される. Clock 新たに utc_clock , tai_clock , gps_clock , file_clock の 4 つのクロック, また, その time_point 型のエイリアス( utc_time , utc_seconds , tai_time , tai_seconds , gps_time , gps_seconds ) が提供される. utc_clock は, 協定世界時( UTC )を表現するクロックであり, 1970 年 1 月 1 日木曜日午後 00:00:00 分からの時間を測定する. これには, 閏秒が含まれる. tai_clock は, 国際原始時計( TAI )を表現するクロックであり, 1958 年 1 月 1 日 00:00:00 からの時間を測定し, この日の UTC (1957-12-31 23:59:50 UTC )よりも 10 秒前にオフセットされている. これには, 閏秒が含まれない 9 . gps_clock は GPS 時刻を表現するクロックであり, UTC 1980 年 1 月 6 日 00:00:00 からの時間を測定する. 閏秒は含まれない 10 . file_clock は, C++20 で追加されたエイリアス, using file_time_type = std::chrono::time_point<std::chrono::file_clock>; で利用されるファイルクロックである 11 . 試用 同ライブラリを利用した任意月のカレンダーを出力するプログラムは, 既にあった のだが, 特別何か別のものは思いつかないので, とりあえず, 任意年の全ての月のカレンダーを出力するプログラムを書いて試用. #include <algorithm> #include <array> #include <chrono> #include <iostream> #include <iomanip> #include <utility> namespace ns { template < class > struct weeks_init ; template < std :: size_t ... s > struct weeks_init < std :: index_sequence < s ... >> { constexpr weeks_init () = default ; constexpr std :: array < std :: chrono :: weekday , sizeof ...( s ) > operator ()() const noexcept { return {{ std :: chrono :: weekday { s }... }}; } }; constexpr auto weeks = weeks_init < std :: make_index_sequence < 7 >> ()(); inline void print_weeks ( std :: ostream & os ) { namespace sc = std :: chrono ; std :: copy ( std :: begin ( weeks ), std :: end ( weeks ), std :: ostream_iterator < sc :: weekday > ( os , \" \" )); os << '\\n' ; } } // namespace ns struct print_calendar_year { explicit constexpr print_calendar_year ( std :: chrono :: year y ) noexcept : y_ ( y ) {} friend std :: ostream & operator << ( std :: ostream & os , const print_calendar_year & this_ ) { using namespace std :: chrono_literals ; namespace sc = std :: chrono ; constexpr int width = 5 ; for ( unsigned i = 1u , uweek = static_cast < unsigned > ( sc :: weekday { sc :: sys_days { this_ . y_ / sc :: January / 1 d }}); i <= 12u ; ++ i ) { auto lastday = ( this_ . y_ / sc :: month { i } / sc :: last ). day (); os << std :: setw ( ns :: weeks . size () * width / 2 ) << sc :: month { i } << '\\n' ; ns :: print_weeks ( os << std :: setw ( width )); unsigned k = 0 ; for (; k < uweek ; ++ k ) os << std :: setw ( width ) << \" \" ; for ( sc :: day d { 1 }; d <= lastday ; ++ d ) { os << std :: setw ( width ) << static_cast < unsigned > ( d ); if ( ++ k > 6 ) { k = 0 ; os << '\\n' ; } } if ( k ) os << '\\n' ; uweek = k ; } return os ; } private : std :: chrono :: year y_ ; }; int main () { std :: cout << print_calendar_year { std :: chrono :: year { 2000 }} << std :: endl ; } 実行結果 . タイムゾーンに関するサンプルは, 元の実装のドキュメント で多く取り上げられている. フライトタイムの計算や, IANA タイムゾーンデータベースを利用しないカスタムタイムゾーンを作成する例などが掲示されている. 感想 とてもよく作り込まれていて, 使いやすそうに感じる. C++ にこのような高レベル API が導入されるのは, 少し新鮮. この一つ前の ISO C++ 委員会による国際会議で C++20 に追加された P0515 Consistent comparison で挙げられている comparison category types での呼称を用いている. 参照: Consistent/three-way comparison ↩ ↩ ↩ ↩ ↩ タイムゾーンライブラリの型とその関係性を示した 図 を, 作者のドキュメントページから見ることができる. ↩ List of tz database time zones ↩ ↩ 元の実装 を見ると, 現在地のタイムゾーン取得においては, Linux および Mac では特定ファイル(/usr/share/zoneinfo, /usr/share/zoneinfo/uclibc) を読み込み , Windows ではレジストリ値を読み込んでいる . レジストリ値から取得されたネイティブな現在のタイムゾーン名が標準のものと一致する保証はなく, 特に Windows の場合, 得られる名前は必ず標準と異なるものであるため, 標準の名前と関連づけるマッピングが行われる. 元の実装では, Windows の場合ではタイムゾーンデータベースの取得の際に, xml ファイル を 取得している . ↩ 元の実装 を見ると, OS のタイムゾーンデータベースを利用せず, リモート API があるときは OS 依存またはサードパーティ製のライブラリを利用してデータを取得 し, そうでないとき OS のタイムゾーンデータベースを利用する. 元の実装 で OS のタイムゾーンデータベースを試用する際には, DUSE_OS_TZDB=1 をセットしてビルドする. Windows 環境がないので筆者にはわからないが, Windows では OS のタイムゾーンデータベースを利用できないようだ . ↩ ↩ サマータイムの開始と終了で, 存在しないローカル時間( nonexistent_local_time )と重複するローカル時間( ambiguous_local_time )という概念が生じる. ↩ ↩ ↩ ↩ ↩ 2016-11-06 01:30:00 EDT は, 2016-11-06 05:30:00 UTC と 2016-11-06 06:30:00 UTC になりうる. try { auto zt = zoned_time{\"America/New_York\", local_days{Sunday[1]/November/2016} + 1h + 30min}; } catch (const ambiguous_local_time&) { } ↩ 2016-03-13 02:30:00 EDT は, 2016-03-13 02:00:00 EST と 2016-03-13 03:00:00 EDT の間にあるため存在しない. どちらも, 2016-03-13 07:00:00 UTC と等価である. try { auto zt = zoned_time{\"America/New_York\", local_days{Sunday[2]/March/2016} + 2h + 30min}; } catch (const noexistent_local_time&) {} ↩ 閏秒が UTC に挿入される度に, UTC は TAI の 1 秒遅れとなる. 1961 年発祥の旧 UTC , 1972 年の特別調整, 1972 年から 2017 年 1 月まで行われた27 回の閏秒調整の過程を踏み, UTC は現在 TAI に対して 37 秒遅れている. 参考: http://jjy.nict.go.jp/mission/page1.html ↩ tai_clock 同様, UTC に閏秒が挿入されるたびに UTC の 1 秒後を表現することとなる. 2017 年時点で, UTC は GPS の 18 秒前 にある. 余談: GPS が UTC との差分を計算する方法に関して . ↩ file_time_type は C++17 時点で既にエイリアスとして追加されているが, using file_time_type = std::chrono::time_point</*trivial-clock*/>; と記されており, 具体的なクロック型は明記されていなかった. ↩ yohhoy さんに last の属する名前空間に関する追加情報を頂いた. ありがとうございます. ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2018/ 3月/26/cxx20_calender_and_timezone_library/","tags":"C++","url":"posts/2018/ 3月/26/cxx20_calender_and_timezone_library/","title":"C++20 Calender and timezone library"},{"text":"ブログを移転した これまでは約二年ほど はてブロ に, メモや学習ログなどを投稿し, 利用させて頂いていたが, \\({\\rm\\LaTeX}\\) の記述においてはてブロ固有の独特な記法を必要とされることがあり, これらの点で 少し不便に感じていたので, 新たにブログを立ち上げこちらに移転することとした. このブログは github pages でホスティングされており, Pelican という Static site generator によって成り立っている. またテーマは, nikhil-theme を フォークして 利用させて頂いている. 移転で行った作業 流れとしては, 通常通り, pip で Pelican を導入し, pelican-quickstart によって必要なディレクトリ階層と, 最低限のファイル構成を得て, そこから諸々の設定を行った. Pelican + github pages でブログを管理する事例はとても多く, また ドキュメント も充実しており, 特別困ることはなかったが, いくつかテーマの修正, 機能追加などを行った. 本ブログ構造や管理に関する変更の記録は, 本エントリにて随時更新している . HTTP コンテンツが入り混じっていたため, これを 修正した . Pelican の 3.7.0 から PAGES という context variable が pages に変更されており , そのままでは正常にレンダリングされないためこれを 修正した . favicon の生成を ImageMagick で行い, これを Wiki 通りに設定した. コメント機能となる DISQUS を追加した. CC ライセンスを追加した. 検索機能を追加した. 404 ページを追加した. pelican_dynamic プラグインを fork し, 少し修正して導入して d3.js が動くようにした. テーマ内臓のシンタックスハイライトのスタイルシートが Mathjax の利用するスタイルシートと衝突しており( 該当部分 ), 数式が緑色でレンダリングされてしまっていた. これを, ワークアラウンドとして Mathjax の使うクラスに対して color: inherit; を指定 し, 修正した 1 . python-livereload を用いて記事のライブビューができるようにした. バックグラウンドで立ち上がって欲しいので, それら諸々をシェルスクリプトで書いた(以下の gist をサブモジュールとしてマスターブランチに登録している). live_preview.py live_preview.sh ローカルマシンでのサイト生成をやめ, 特定ブランチへのプッシュをトリガーに Bitbucket Pipeline によってサイト生成, デプロイを行うこととした. 構造 フォークしたテーマと pelican-plugins をマスターブランチのサブモジュールとして置いた. マスターブランチには, ブログ記事の下書きなども貯めようと思っていたため, 特別これを公開する意味はない. そこで, マスターブランチは private リポジトリとして bitbucket に, gh-pages ブランチは github にホスティングして頂くこととした 2 . master (非公開なのでここに貼っても特別意味はないが) gh-pages gh-pages への反映は, ghp-import を利用している. 記事を公開しようとするたびに毎度ブランチをチェックアウトするのは面倒なので, Makefile にコマンドを書いておき, そのコマンド一発で記事の生成と gh-pages へのプッシュを行えるようにした. また, bitbucket には標準搭載の CI (bitbucket Pipelines) があるので, master ブランチへのプッシュをトリガーに, 自動で記事の生成テストを行うようにしている. おそらく #349 の問題も, この関係なのではないかと思われる. ↩ 2019/1/7, The GitHub Blog でアナウンスされた通り, マイクロソフトに買収された GitHub はプライベートリポジトリの機能を一般ユーザへ無償で公開した. 従って, プライベートリポジトリの機能を使うために, GitHub 以外のサービスを用いるということの必然性はなくなったわけであるが, なんとなくベンダーロックインしてしまうことに抵抗があるので, この構成で運用を続けていく予定. ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (true) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','enclose.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: false,\" + \" messageStyle: 'None',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"posts/2018/ 3月/22/my_first_post/","tags":"Uncategorized","url":"posts/2018/ 3月/22/my_first_post/","title":"ハローワールド"}]};